{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"video_suwha.ipynb의 사본","provenance":[],"machine_shape":"hm","collapsed_sections":[],"mount_file_id":"1aJmPuNDUYN2GPYzcUXPIHbr5AP-SM3qi","authorship_tag":"ABX9TyNImdGIE/C8kpJ/V+Rn8jF4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Jv4Nz0IIW9yi","executionInfo":{"status":"ok","timestamp":1653625183958,"user_tz":-540,"elapsed":19397,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"91f038a3-22be-403e-f1c7-111c586c9d08"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q git+https://github.com/tensorflow/docs"]},{"cell_type":"code","source":[""],"metadata":{"id":"fsT35ViVXAfk","executionInfo":{"status":"ok","timestamp":1653625183960,"user_tz":-540,"elapsed":57,"user":{"displayName":"정민수","userId":"04604353163343298236"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from tensorflow_docs.vis import embed\n","from tensorflow import keras\n","from imutils import paths\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import imageio\n","import cv2\n","import os"],"metadata":{"id":"FMLfRnvfXAiB","executionInfo":{"status":"ok","timestamp":1653625185608,"user_tz":-540,"elapsed":1696,"user":{"displayName":"정민수","userId":"04604353163343298236"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install mediapipe opencv-python\n","import mediapipe as mp\n","import cv2\n","mp_drawing = mp.solutions.drawing_utils\n","mp_holistic = mp.solutions.holistic\n","\n","# skeleton styling\n","mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpOXccOpy_wI","executionInfo":{"status":"ok","timestamp":1653625192740,"user_tz":-540,"elapsed":7141,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"996b60fd-4b3b-4570-b2f0-f2aa853a5150"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.8 MB)\n","\u001b[K     |████████████████████████████████| 32.8 MB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.0.0)\n","Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.2.0)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.10\n"]},{"output_type":"execute_result","data":{"text/plain":["DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["IMG_SIZE = 224\n","BATCH_SIZE = 64\n","EPOCHS = 1000\n","\n","MAX_SEQ_LENGTH = 500\n","NUM_FEATURES = 2048\n"],"metadata":{"id":"eByvw2MbXAkg","executionInfo":{"status":"ok","timestamp":1653625192742,"user_tz":-540,"elapsed":57,"user":{"displayName":"정민수","userId":"04604353163343298236"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dirpath = \"/content/drive/MyDrive/yunghab/suwha/\"\n","video_list  = os.listdir(\"/content/drive/MyDrive/yunghab/suwha\")\n","video_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gC4SrN4pEEoM","executionInfo":{"status":"ok","timestamp":1653625193259,"user_tz":-540,"elapsed":554,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"dd83d758-ad14-4687-e0d2-deac57930956"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['0000_뻐기다.mp4',\n"," '0001_답.mp4',\n"," '0002_그냥,그저.mp4',\n"," '0003_대립.mp4',\n"," '0004_신선하다,새롭다.mp4',\n"," '0005_오세아니아.mp4',\n"," '0006_황홀,휘황하다,휘황찬란하다.mp4',\n"," '0007_못생기다,못나다,추하다,밉다.mp4',\n"," '0008_잃어버리다,분실,잃다.mp4',\n"," '0009_식장.mp4',\n"," '0010_홍콩.mp4',\n"," '0011_대답.mp4',\n"," '0012_신호등.mp4',\n"," '0013_보물,보석,보화.mp4',\n"," '0014_전달,전갈,전하다.mp4',\n"," '0015_터뜨리다,폭발,폭파.mp4',\n"," '0016_레바논.mp4',\n"," '0017_화산.mp4',\n"," '0018_보석상.mp4',\n"," '0019_겹치다.mp4',\n"," '0020_장군.mp4',\n"," '0021_축사.mp4',\n"," '0022_원래.mp4',\n"," '0023_식,축하.mp4',\n"," '0024_(화학)실험.mp4',\n"," '0025_기금.mp4',\n"," '0026_유행.mp4',\n"," '0027_신문사.mp4',\n"," '0028_신문.mp4',\n"," '0029_오해.mp4',\n"," '0030_반짝.mp4',\n"," '0031_세례.mp4',\n"," '0032_원금,자금,원가.mp4',\n"," '0033_전과.mp4',\n"," '0034_고백,고해.mp4',\n"," '0035_맥주.mp4',\n"," '0036_전통.mp4',\n"," '0037_등대.mp4',\n"," '0038_빵.mp4',\n"," '0039_선전.mp4',\n"," '0040_대화,대담.mp4',\n"," '0041_별.mp4',\n"," '0042_불평.mp4',\n"," '0043_신기록.mp4',\n"," '0044_행사장.mp4',\n"," '0045_새해.mp4',\n"," '0046_본질,본성.mp4',\n"," '0047_고발,고자질,일러바치다.mp4',\n"," '0048_날리다.mp4',\n"," '0049_근본,기반,기본,기초,바탕,뿌리.mp4',\n"," '0050_새어머니.mp4',\n"," '0051_새아버지.mp4',\n"," '0052_빵집.mp4',\n"," '0053_광,광선,라이트,빛,조명,비추다,비치다.mp4',\n"," '0054_신도시.mp4',\n"," '0055_혁신.mp4',\n"," '0056_게우다,구토,토하다.mp4']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["video_name = [ list.split(\"_\")[1] for list in video_list]\n","video_name1 = video_list[:]\n","video_name2 = video_list[50:]\n","tag = [ list.split(\".\")[0] for list in video_name]\n","tag1 = tag[:]\n","tag2 = tag[50:]\n","train_df = pd.DataFrame(data = {\n","    'video_name':video_name1,\n","    'tag': tag1\n","})\n","test_df = pd.DataFrame(data = {\n","    'video_name':video_name2,\n","    'tag': tag2\n","})\n","\n","train_df.head(10)\n","test_df.head(10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"8I89yxngEgA-","executionInfo":{"status":"ok","timestamp":1653625193260,"user_tz":-540,"elapsed":24,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"86f69340-6225-421e-ba25-e5f79fb75aba"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          video_name  \\\n","0                                  0050_새어머니.mp4   \n","1                                  0051_새아버지.mp4   \n","2                                    0052_빵집.mp4   \n","3  0053_광,광선,라이트,빛,조명,비추다,비치다...   \n","4                                   0054_신도시.mp4   \n","5                                    0055_혁신.mp4   \n","6                        0056_게우다,구토,토하다.mp4   \n","\n","                                         tag  \n","0                                   새어머니  \n","1                                   새아버지  \n","2                                     빵집  \n","3  광,광선,라이트,빛,조명,비추다,비치다  \n","4                                    신도시  \n","5                                     혁신  \n","6                         게우다,구토,토하다  "],"text/html":["\n","  <div id=\"df-15260473-563f-4232-9e5b-b85c1ba556c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>video_name</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0050_새어머니.mp4</td>\n","      <td>새어머니</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0051_새아버지.mp4</td>\n","      <td>새아버지</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0052_빵집.mp4</td>\n","      <td>빵집</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0053_광,광선,라이트,빛,조명,비추다,비치다...</td>\n","      <td>광,광선,라이트,빛,조명,비추다,비치다</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0054_신도시.mp4</td>\n","      <td>신도시</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0055_혁신.mp4</td>\n","      <td>혁신</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0056_게우다,구토,토하다.mp4</td>\n","      <td>게우다,구토,토하다</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15260473-563f-4232-9e5b-b85c1ba556c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-15260473-563f-4232-9e5b-b85c1ba556c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-15260473-563f-4232-9e5b-b85c1ba556c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["\n","\n","print(f\"Total videos for training: {len(train_df)}\")\n","print(f\"Total videos for testing: {len(test_df)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viGQ-qP2XAnI","executionInfo":{"status":"ok","timestamp":1653625193260,"user_tz":-540,"elapsed":20,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"bcca29ca-a64e-487f-9987-07e45e77405b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Total videos for training: 57\n","Total videos for testing: 7\n"]}]},{"cell_type":"code","source":["test_df.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDeemmt5MG7i","executionInfo":{"status":"ok","timestamp":1653625193548,"user_tz":-540,"elapsed":305,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"5810aa0c-20d8-4e97-f822-e6c6d6716bc4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7, 2)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["\n","def crop_center_square(frame):\n","    y, x = frame.shape[0:2]\n","    min_dim = min(y, x)\n","    start_x = (x // 2) - (min_dim // 2)\n","    start_y = (y // 2) - (min_dim // 2)\n","    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n","\n","'''\n","# 원본\n","def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n","    print(\"load_video path : \", path)\n","    cap = cv2.VideoCapture(path)\n","    \n","    frames = []\n","    frame_count = 0\n","    try:\n","        while True:\n","            \n","            ret, frame = cap.read()\n","            frame_count += 1\n","            if frame_count < 40 : continue\n","\n","            if not ret:\n","                break\n","            frame = crop_center_square(frame)\n","            frame = cv2.resize(frame, resize)\n","            frame = frame[:, :, [2, 1, 0]]\n","            frames.append(frame)\n","            if len(frames) == max_frames:\n","                break\n","    finally:\n","        cap.release()\n","    return np.array(frames)\n","'''\n","\n","# skeleton 추가\n","def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n","    print(\"load_video path : \", path)\n","    cap = cv2.VideoCapture(path)\n","    \n","    frames = []\n","    frame_count = 0\n","    \n","    try:\n","\n","        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","          while True:\n","                \n","              ret, frame = cap.read()\n","              frame_count += 1\n","              if frame_count < 40 : continue\n","\n","              if not ret:\n","                  break\n","              \n","              # Recolor Feed\n","              image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","              # Make Detections\n","              results = holistic.process(image)\n","              # print(results.face_landmarks)\n","              \n","              # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n","              \n","              # Recolor image back to BGR for rendering\n","              image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","              # 2. Right hand\n","              mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                      mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n","                                      mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n","                                      )\n","\n","              # 3. Left Hand\n","              mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                                      mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n","                                      mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n","                                      )\n","\n","              # 4. Pose Detections\n","              mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n","                                      mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n","                                      mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n","                                      )\n","\n","\n","              frame = crop_center_square(image)\n","              frame = cv2.resize(frame, resize)\n","              frame = frame[:, :, [2, 1, 0]]\n","              frames.append(frame)\n","              if len(frames) == max_frames:\n","                  break\n","    finally:\n","        cap.release()\n","    return np.array(frames)"],"metadata":{"id":"TLuiyf_xXAqY","executionInfo":{"status":"ok","timestamp":1653625193549,"user_tz":-540,"elapsed":6,"user":{"displayName":"정민수","userId":"04604353163343298236"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def build_feature_extractor():\n","    feature_extractor = keras.applications.InceptionV3(\n","        weights=\"imagenet\",\n","        include_top=False,\n","        pooling=\"avg\",\n","        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","    )\n","    preprocess_input = keras.applications.inception_v3.preprocess_input\n","\n","    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n","    preprocessed = preprocess_input(inputs)\n","\n","    outputs = feature_extractor(preprocessed)\n","    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n","\n","\n","feature_extractor = build_feature_extractor()"],"metadata":{"id":"S0zg9ufeXAr_","executionInfo":{"status":"ok","timestamp":1653625203377,"user_tz":-540,"elapsed":9833,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"44bd2148-6e54-4b32-ad81-85f6a4691b08"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n","87924736/87910968 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["label_processor = keras.layers.StringLookup(\n","    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",")\n","print(label_processor.get_vocabulary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNYF_xqKXAuu","executionInfo":{"status":"ok","timestamp":1653625203379,"user_tz":-540,"elapsed":26,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"b4542461-a1c9-4511-d7e8-bd8eb1219cad"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['(화학)실험', '게우다,구토,토하다', '겹치다', '고발,고자질,일러바치다', '고백,고해', '광,광선,라이트,빛,조명,비추다,비치다', '그냥,그저', '근본,기반,기본,기초,바탕,뿌리', '기금', '날리다', '답', '대답', '대립', '대화,대담', '등대', '레바논', '맥주', '못생기다,못나다,추하다,밉다', '반짝', '별', '보물,보석,보화', '보석상', '본질,본성', '불평', '빵', '빵집', '뻐기다', '새아버지', '새어머니', '새해', '선전', '세례', '식,축하', '식장', '신기록', '신도시', '신문', '신문사', '신선하다,새롭다', '신호등', '오세아니아', '오해', '원금,자금,원가', '원래', '유행', '잃어버리다,분실,잃다', '장군', '전과', '전달,전갈,전하다', '전통', '축사', '터뜨리다,폭발,폭파', '행사장', '혁신', '홍콩', '화산', '황홀,휘황하다,휘황찬란하다']\n"]}]},{"cell_type":"code","source":["def to_gif(images):\n","    converted_images = images.astype(np.uint8)\n","    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n","    return embed.embed_file(\"animation.gif\")\n","\n","def prepare_all_videos(df):\n","    import time\n","    start = time.time()  # 시작 시간 저장\n"," \n"," \n"," \n","    max_mask = 0\n","    num_samples = len(df)\n","    video_paths = df[\"video_name\"].values.tolist()\n","    video_paths = [\"/content/drive/MyDrive/yunghab/suwha/\"+path for path in video_paths]\n","    print(video_paths)\n","    labels = df[\"tag\"].values\n","    labels = label_processor(labels[..., None]).numpy()\n","\n","    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n","    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n","    # masked with padding or not.\n","    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n","    frame_features = np.zeros(\n","        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","    )\n","    #frame_copy = np.zeros((252, 224, 224, 3))\n","    \n","\n","    # For each video.\n","    for idx, path in enumerate(video_paths):\n","        print(\"진행상황 : \" + str(idx + 1) + \" / \" + str(num_samples))\n","        \n","        # Gather all its frames and add a batch dimension.\n","        frames = load_video(os.path.join(path))\n","        print(\"frames.shape : \", frames.shape)\n","        print(type(frames))\n","        \n","       \n","        frames = frames[None, ...]\n","        \n","        # Initialize placeholders to store the masks and features of the current video.\n","        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n","        temp_frame_features = np.zeros(\n","            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","        )\n","\n","        # Extract features from the frames of the current video.\n","        for i, batch in enumerate(frames):\n","            \n","            video_length = batch.shape[0]\n","            if max_mask < video_length:\n","              max_mask = video_length\n","            video_length\n","            length = min(MAX_SEQ_LENGTH, video_length)\n","            print(\"video_length : \", video_length, \" length : \", length)\n","            for j in range(length):\n","                \n","                temp_frame_features[i, j, :] = feature_extractor.predict(\n","                    batch[None, j, :]\n","                )\n","            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n","            \n","            #print('temp_frame_features : ', temp_frame_features.shape)  # (1, 108, 224, 224, 3) -> (1, 20, 2048) 로 만들어 준다.\n","            #print('temp_frame_mask : ', temp_frame_mask.shape)          # (1, 20)\n","            \n","\n","        #print('temp_frame_features2 : ', temp_frame_features.shape)\n","        #print('temp_frame_mask2 : ', temp_frame_mask.shape)\n","        #print(temp_frame_mask)\n","        frame_features[idx,] = temp_frame_features.squeeze()\n","        frame_masks[idx,] = temp_frame_mask.squeeze()\n","        print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","    print(\"총 걸린시간 time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n","    print(\"max_mask : \", max_mask)\n","    return (frame_features, frame_masks), labels\n","\n","\n","train_data, train_labels = prepare_all_videos(train_df)\n","test_data, test_labels = prepare_all_videos(test_df)\n","\n","print(f\"Frame features in train set: {train_data[0].shape}\")\n","print(f\"Frame masks in train set: {train_data[1].shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Paa_GrsDXAxP","executionInfo":{"status":"ok","timestamp":1653627232865,"user_tz":-540,"elapsed":2029509,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"8a6e91b1-c29c-47af-ca89-7f662c25252a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["['/content/drive/MyDrive/yunghab/suwha/0000_뻐기다.mp4', '/content/drive/MyDrive/yunghab/suwha/0001_답.mp4', '/content/drive/MyDrive/yunghab/suwha/0002_그냥,그저.mp4', '/content/drive/MyDrive/yunghab/suwha/0003_대립.mp4', '/content/drive/MyDrive/yunghab/suwha/0004_신선하다,새롭다.mp4', '/content/drive/MyDrive/yunghab/suwha/0005_오세아니아.mp4', '/content/drive/MyDrive/yunghab/suwha/0006_황홀,휘황하다,휘황찬란하다.mp4', '/content/drive/MyDrive/yunghab/suwha/0007_못생기다,못나다,추하다,밉다.mp4', '/content/drive/MyDrive/yunghab/suwha/0008_잃어버리다,분실,잃다.mp4', '/content/drive/MyDrive/yunghab/suwha/0009_식장.mp4', '/content/drive/MyDrive/yunghab/suwha/0010_홍콩.mp4', '/content/drive/MyDrive/yunghab/suwha/0011_대답.mp4', '/content/drive/MyDrive/yunghab/suwha/0012_신호등.mp4', '/content/drive/MyDrive/yunghab/suwha/0013_보물,보석,보화.mp4', '/content/drive/MyDrive/yunghab/suwha/0014_전달,전갈,전하다.mp4', '/content/drive/MyDrive/yunghab/suwha/0015_터뜨리다,폭발,폭파.mp4', '/content/drive/MyDrive/yunghab/suwha/0016_레바논.mp4', '/content/drive/MyDrive/yunghab/suwha/0017_화산.mp4', '/content/drive/MyDrive/yunghab/suwha/0018_보석상.mp4', '/content/drive/MyDrive/yunghab/suwha/0019_겹치다.mp4', '/content/drive/MyDrive/yunghab/suwha/0020_장군.mp4', '/content/drive/MyDrive/yunghab/suwha/0021_축사.mp4', '/content/drive/MyDrive/yunghab/suwha/0022_원래.mp4', '/content/drive/MyDrive/yunghab/suwha/0023_식,축하.mp4', '/content/drive/MyDrive/yunghab/suwha/0024_(화학)실험.mp4', '/content/drive/MyDrive/yunghab/suwha/0025_기금.mp4', '/content/drive/MyDrive/yunghab/suwha/0026_유행.mp4', '/content/drive/MyDrive/yunghab/suwha/0027_신문사.mp4', '/content/drive/MyDrive/yunghab/suwha/0028_신문.mp4', '/content/drive/MyDrive/yunghab/suwha/0029_오해.mp4', '/content/drive/MyDrive/yunghab/suwha/0030_반짝.mp4', '/content/drive/MyDrive/yunghab/suwha/0031_세례.mp4', '/content/drive/MyDrive/yunghab/suwha/0032_원금,자금,원가.mp4', '/content/drive/MyDrive/yunghab/suwha/0033_전과.mp4', '/content/drive/MyDrive/yunghab/suwha/0034_고백,고해.mp4', '/content/drive/MyDrive/yunghab/suwha/0035_맥주.mp4', '/content/drive/MyDrive/yunghab/suwha/0036_전통.mp4', '/content/drive/MyDrive/yunghab/suwha/0037_등대.mp4', '/content/drive/MyDrive/yunghab/suwha/0038_빵.mp4', '/content/drive/MyDrive/yunghab/suwha/0039_선전.mp4', '/content/drive/MyDrive/yunghab/suwha/0040_대화,대담.mp4', '/content/drive/MyDrive/yunghab/suwha/0041_별.mp4', '/content/drive/MyDrive/yunghab/suwha/0042_불평.mp4', '/content/drive/MyDrive/yunghab/suwha/0043_신기록.mp4', '/content/drive/MyDrive/yunghab/suwha/0044_행사장.mp4', '/content/drive/MyDrive/yunghab/suwha/0045_새해.mp4', '/content/drive/MyDrive/yunghab/suwha/0046_본질,본성.mp4', '/content/drive/MyDrive/yunghab/suwha/0047_고발,고자질,일러바치다.mp4', '/content/drive/MyDrive/yunghab/suwha/0048_날리다.mp4', '/content/drive/MyDrive/yunghab/suwha/0049_근본,기반,기본,기초,바탕,뿌리.mp4', '/content/drive/MyDrive/yunghab/suwha/0050_새어머니.mp4', '/content/drive/MyDrive/yunghab/suwha/0051_새아버지.mp4', '/content/drive/MyDrive/yunghab/suwha/0052_빵집.mp4', '/content/drive/MyDrive/yunghab/suwha/0053_광,광선,라이트,빛,조명,비추다,비치다.mp4', '/content/drive/MyDrive/yunghab/suwha/0054_신도시.mp4', '/content/drive/MyDrive/yunghab/suwha/0055_혁신.mp4', '/content/drive/MyDrive/yunghab/suwha/0056_게우다,구토,토하다.mp4']\n","진행상황 : 1 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0000_뻐기다.mp4\n","frames.shape :  (252, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  252  length :  252\n","time : 53.706743478775024\n","진행상황 : 2 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0001_답.mp4\n","frames.shape :  (119, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  119  length :  119\n","time : 72.82716012001038\n","진행상황 : 3 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0002_그냥,그저.mp4\n","frames.shape :  (69, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  69  length :  69\n","time : 84.03561973571777\n","진행상황 : 4 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0003_대립.mp4\n","frames.shape :  (319, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  319  length :  319\n","time : 134.48836636543274\n","진행상황 : 5 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0004_신선하다,새롭다.mp4\n","frames.shape :  (81, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  81  length :  81\n","time : 147.45555448532104\n","진행상황 : 6 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0005_오세아니아.mp4\n","frames.shape :  (325, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  325  length :  325\n","time : 197.5435049533844\n","진행상황 : 7 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0006_황홀,휘황하다,휘황찬란하다.mp4\n","frames.shape :  (220, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  220  length :  220\n","time : 231.54129910469055\n","진행상황 : 8 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0007_못생기다,못나다,추하다,밉다.mp4\n","frames.shape :  (61, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  61  length :  61\n","time : 241.35338497161865\n","진행상황 : 9 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0008_잃어버리다,분실,잃다.mp4\n","frames.shape :  (190, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  190  length :  190\n","time : 270.99584913253784\n","진행상황 : 10 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0009_식장.mp4\n","frames.shape :  (344, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  344  length :  344\n","time : 324.00199818611145\n","진행상황 : 11 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0010_홍콩.mp4\n","frames.shape :  (401, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  401  length :  401\n","time : 385.4396405220032\n","진행상황 : 12 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0011_대답.mp4\n","frames.shape :  (70, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  70  length :  70\n","time : 396.6481201648712\n","진행상황 : 13 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0012_신호등.mp4\n","frames.shape :  (81, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  81  length :  81\n","time : 410.00014781951904\n","진행상황 : 14 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0013_보물,보석,보화.mp4\n","frames.shape :  (335, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  335  length :  335\n","time : 461.39002799987793\n","진행상황 : 15 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0014_전달,전갈,전하다.mp4\n","frames.shape :  (69, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  69  length :  69\n","time : 472.5600996017456\n","진행상황 : 16 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0015_터뜨리다,폭발,폭파.mp4\n","frames.shape :  (127, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  127  length :  127\n","time : 492.49027943611145\n","진행상황 : 17 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0016_레바논.mp4\n","frames.shape :  (362, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  362  length :  362\n","time : 547.6332902908325\n","진행상황 : 18 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0017_화산.mp4\n","frames.shape :  (176, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  176  length :  176\n","time : 575.196346282959\n","진행상황 : 19 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0018_보석상.mp4\n","frames.shape :  (251, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  251  length :  251\n","time : 614.029322385788\n","진행상황 : 20 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0019_겹치다.mp4\n","frames.shape :  (147, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  147  length :  147\n","time : 636.6677134037018\n","진행상황 : 21 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0020_장군.mp4\n","frames.shape :  (298, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  298  length :  298\n","time : 682.0740149021149\n","진행상황 : 22 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0021_축사.mp4\n","frames.shape :  (223, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  223  length :  223\n","time : 716.7789225578308\n","진행상황 : 23 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0022_원래.mp4\n","frames.shape :  (148, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  148  length :  148\n","time : 739.8840746879578\n","진행상황 : 24 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0023_식,축하.mp4\n","frames.shape :  (71, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  71  length :  71\n","time : 751.2536399364471\n","진행상황 : 25 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0024_(화학)실험.mp4\n","frames.shape :  (202, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  202  length :  202\n","time : 782.5238115787506\n","진행상황 : 26 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0025_기금.mp4\n","frames.shape :  (197, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  197  length :  197\n","time : 812.8541889190674\n","진행상황 : 27 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0026_유행.mp4\n","frames.shape :  (183, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  183  length :  183\n","time : 841.4991607666016\n","진행상황 : 28 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0027_신문사.mp4\n","frames.shape :  (161, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  161  length :  161\n","time : 866.9293491840363\n","진행상황 : 29 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0028_신문.mp4\n","frames.shape :  (166, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  166  length :  166\n","time : 892.5732293128967\n","진행상황 : 30 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0029_오해.mp4\n","frames.shape :  (172, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  172  length :  172\n","time : 919.2225449085236\n","진행상황 : 31 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0030_반짝.mp4\n","frames.shape :  (171, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  171  length :  171\n","time : 945.2499094009399\n","진행상황 : 32 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0031_세례.mp4\n","frames.shape :  (309, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  309  length :  309\n","time : 992.3621423244476\n","진행상황 : 33 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0032_원금,자금,원가.mp4\n","frames.shape :  (109, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  109  length :  109\n","time : 1009.4622147083282\n","진행상황 : 34 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0033_전과.mp4\n","frames.shape :  (268, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  268  length :  268\n","time : 1049.7322030067444\n","진행상황 : 35 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0034_고백,고해.mp4\n","frames.shape :  (188, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  188  length :  188\n","time : 1078.5110166072845\n","진행상황 : 36 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0035_맥주.mp4\n","frames.shape :  (59, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  59  length :  59\n","time : 1087.9036045074463\n","진행상황 : 37 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0036_전통.mp4\n","frames.shape :  (167, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  167  length :  167\n","time : 1113.385537147522\n","진행상황 : 38 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0037_등대.mp4\n","frames.shape :  (155, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  155  length :  155\n","time : 1137.2383630275726\n","진행상황 : 39 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0038_빵.mp4\n","frames.shape :  (71, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  71  length :  71\n","time : 1148.2903413772583\n","진행상황 : 40 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0039_선전.mp4\n","frames.shape :  (142, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  142  length :  142\n","time : 1170.3222448825836\n","진행상황 : 41 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0040_대화,대담.mp4\n","frames.shape :  (74, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  74  length :  74\n","time : 1181.8577032089233\n","진행상황 : 42 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0041_별.mp4\n","frames.shape :  (81, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  81  length :  81\n","time : 1194.3041083812714\n","진행상황 : 43 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0042_불평.mp4\n","frames.shape :  (141, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  141  length :  141\n","time : 1215.5163316726685\n","진행상황 : 44 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0043_신기록.mp4\n","frames.shape :  (349, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  349  length :  349\n","time : 1268.1301455497742\n","진행상황 : 45 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0044_행사장.mp4\n","frames.shape :  (281, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  281  length :  281\n","time : 1310.564945936203\n","진행상황 : 46 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0045_새해.mp4\n","frames.shape :  (81, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  81  length :  81\n","time : 1323.1103301048279\n","진행상황 : 47 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0046_본질,본성.mp4\n","frames.shape :  (201, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  201  length :  201\n","time : 1353.499743461609\n","진행상황 : 48 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0047_고발,고자질,일러바치다.mp4\n","frames.shape :  (127, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  127  length :  127\n","time : 1372.609522819519\n","진행상황 : 49 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0048_날리다.mp4\n","frames.shape :  (173, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  173  length :  173\n","time : 1398.754014492035\n","진행상황 : 50 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0049_근본,기반,기본,기초,바탕,뿌리.mp4\n","frames.shape :  (339, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  339  length :  339\n","time : 1449.5804867744446\n","진행상황 : 51 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0050_새어머니.mp4\n","frames.shape :  (455, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  455  length :  455\n","time : 1517.5717930793762\n","진행상황 : 52 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0051_새아버지.mp4\n","frames.shape :  (305, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  305  length :  305\n","time : 1563.2288904190063\n","진행상황 : 53 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0052_빵집.mp4\n","frames.shape :  (205, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  205  length :  205\n","time : 1594.265413761139\n","진행상황 : 54 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0053_광,광선,라이트,빛,조명,비추다,비치다.mp4\n","frames.shape :  (152, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  152  length :  152\n","time : 1617.1481730937958\n","진행상황 : 55 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0054_신도시.mp4\n","frames.shape :  (288, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  288  length :  288\n","time : 1659.9266350269318\n","진행상황 : 56 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0055_혁신.mp4\n","frames.shape :  (409, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  409  length :  409\n","time : 1721.3293480873108\n","진행상황 : 57 / 57\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0056_게우다,구토,토하다.mp4\n","frames.shape :  (124, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  124  length :  124\n","time : 1740.2001876831055\n","총 걸린시간 time : 1740.2003962993622\n","max_mask :  455\n","['/content/drive/MyDrive/yunghab/suwha/0050_새어머니.mp4', '/content/drive/MyDrive/yunghab/suwha/0051_새아버지.mp4', '/content/drive/MyDrive/yunghab/suwha/0052_빵집.mp4', '/content/drive/MyDrive/yunghab/suwha/0053_광,광선,라이트,빛,조명,비추다,비치다.mp4', '/content/drive/MyDrive/yunghab/suwha/0054_신도시.mp4', '/content/drive/MyDrive/yunghab/suwha/0055_혁신.mp4', '/content/drive/MyDrive/yunghab/suwha/0056_게우다,구토,토하다.mp4']\n","진행상황 : 1 / 7\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0050_새어머니.mp4\n","frames.shape :  (455, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  455  length :  455\n","time : 67.46453523635864\n","진행상황 : 2 / 7\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0051_새아버지.mp4\n","frames.shape :  (305, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  305  length :  305\n","time : 113.17282557487488\n","진행상황 : 3 / 7\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0052_빵집.mp4\n","frames.shape :  (205, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  205  length :  205\n","time : 143.85647678375244\n","진행상황 : 4 / 7\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0053_광,광선,라이트,빛,조명,비추다,비치다.mp4\n","frames.shape :  (152, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  152  length :  152\n","time : 166.34516191482544\n","진행상황 : 5 / 7\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0054_신도시.mp4\n","frames.shape :  (288, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  288  length :  288\n","time : 209.33400702476501\n","진행상황 : 6 / 7\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0055_혁신.mp4\n","frames.shape :  (409, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  409  length :  409\n","time : 270.22818183898926\n","진행상황 : 7 / 7\n","load_video path :  /content/drive/MyDrive/yunghab/suwha/0056_게우다,구토,토하다.mp4\n","frames.shape :  (124, 224, 224, 3)\n","<class 'numpy.ndarray'>\n","video_length :  124  length :  124\n","time : 288.96648955345154\n","총 걸린시간 time : 288.96743845939636\n","max_mask :  455\n","Frame features in train set: (57, 500, 2048)\n","Frame masks in train set: (57, 500)\n"]}]},{"cell_type":"code","source":["# Utility for our sequence model.\n","def get_sequence_model():\n","    class_vocab = label_processor.get_vocabulary()\n","\n","    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n","    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n","\n","    # Refer to the following tutorial to understand the significance of using `mask`:\n","    # https://keras.io/api/layers/recurrent_layers/gru/\n","    x = keras.layers.GRU(16, return_sequences=True)(\n","        frame_features_input, mask=mask_input\n","    )\n","    x = keras.layers.GRU(8)(x)\n","    x = keras.layers.Dropout(0.4)(x)\n","    x = keras.layers.Dense(8, activation=\"relu\")(x)\n","    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n","\n","    rnn_model = keras.Model([frame_features_input, mask_input], output)\n","\n","    rnn_model.compile(\n","        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n","    )\n","    return rnn_model\n","\n","\n","# Utility for running experiments.\n","def run_experiment():\n","    filepath = \"/tmp/video_classifier\"\n","    checkpoint = keras.callbacks.ModelCheckpoint(\n","        filepath, save_weights_only=True, save_best_only=True, verbose=1\n","    )\n","\n","    seq_model = get_sequence_model()\n","    seq_model.summary()\n","    history = seq_model.fit(\n","        [train_data[0], train_data[1]],\n","        train_labels,\n","        validation_split=0.3,\n","        epochs=EPOCHS,\n","        callbacks=[checkpoint],\n","    )\n","\n","    seq_model.load_weights(filepath)\n","    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","    return history, seq_model\n","\n","\n","_, sequence_model = run_experiment()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HQRsP9jXAzr","executionInfo":{"status":"ok","timestamp":1653627439472,"user_tz":-540,"elapsed":206611,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"outputId":"d2c083c8-1805-4ea4-9ad0-e4e1b58e5591"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 500, 2048)]  0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 500)]        0           []                               \n","                                                                                                  \n"," gru (GRU)                      (None, 500, 16)      99168       ['input_3[0][0]',                \n","                                                                  'input_4[0][0]']                \n","                                                                                                  \n"," gru_1 (GRU)                    (None, 8)            624         ['gru[0][0]']                    \n","                                                                                                  \n"," dropout (Dropout)              (None, 8)            0           ['gru_1[0][0]']                  \n","                                                                                                  \n"," dense (Dense)                  (None, 8)            72          ['dropout[0][0]']                \n","                                                                                                  \n"," dense_1 (Dense)                (None, 57)           513         ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 100,377\n","Trainable params: 100,377\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/1000\n","1/2 [==============>...............] - ETA: 10s - loss: 4.1173 - accuracy: 0.0000e+00\n","Epoch 1: val_loss improved from inf to 4.11561, saving model to /tmp/video_classifier\n","2/2 [==============================] - 13s 3s/step - loss: 4.0888 - accuracy: 0.0000e+00 - val_loss: 4.1156 - val_accuracy: 0.0000e+00\n","Epoch 2/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0343 - accuracy: 0.0312\n","Epoch 2: val_loss did not improve from 4.11561\n","2/2 [==============================] - 0s 141ms/step - loss: 4.0511 - accuracy: 0.0256 - val_loss: 4.1184 - val_accuracy: 0.0000e+00\n","Epoch 3/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0269 - accuracy: 0.0312\n","Epoch 3: val_loss improved from 4.11561 to 4.11292, saving model to /tmp/video_classifier\n","2/2 [==============================] - 0s 151ms/step - loss: 4.0411 - accuracy: 0.0256 - val_loss: 4.1129 - val_accuracy: 0.0000e+00\n","Epoch 4/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0166 - accuracy: 0.0000e+00\n","Epoch 4: val_loss improved from 4.11292 to 4.11240, saving model to /tmp/video_classifier\n","2/2 [==============================] - 0s 140ms/step - loss: 4.0344 - accuracy: 0.0000e+00 - val_loss: 4.1124 - val_accuracy: 0.0000e+00\n","Epoch 5/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0454 - accuracy: 0.0312\n","Epoch 5: val_loss improved from 4.11240 to 4.10728, saving model to /tmp/video_classifier\n","2/2 [==============================] - 0s 144ms/step - loss: 4.0543 - accuracy: 0.0256 - val_loss: 4.1073 - val_accuracy: 0.0000e+00\n","Epoch 6/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0654 - accuracy: 0.0312\n","Epoch 6: val_loss improved from 4.10728 to 4.10310, saving model to /tmp/video_classifier\n","2/2 [==============================] - 0s 150ms/step - loss: 4.0538 - accuracy: 0.0256 - val_loss: 4.1031 - val_accuracy: 0.0000e+00\n","Epoch 7/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9985 - accuracy: 0.0625\n","Epoch 7: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 4.0256 - accuracy: 0.0513 - val_loss: 4.1101 - val_accuracy: 0.0000e+00\n","Epoch 8/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0216 - accuracy: 0.0000e+00\n","Epoch 8: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 4.0213 - accuracy: 0.0000e+00 - val_loss: 4.1216 - val_accuracy: 0.0000e+00\n","Epoch 9/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0384 - accuracy: 0.0000e+00\n","Epoch 9: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 4.0174 - accuracy: 0.0000e+00 - val_loss: 4.1314 - val_accuracy: 0.0000e+00\n","Epoch 10/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9960 - accuracy: 0.0312\n","Epoch 10: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 128ms/step - loss: 4.0116 - accuracy: 0.0256 - val_loss: 4.1396 - val_accuracy: 0.0000e+00\n","Epoch 11/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0001 - accuracy: 0.0000e+00\n","Epoch 11: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 4.0111 - accuracy: 0.0000e+00 - val_loss: 4.1423 - val_accuracy: 0.0000e+00\n","Epoch 12/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0297 - accuracy: 0.0312\n","Epoch 12: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 4.0291 - accuracy: 0.0513 - val_loss: 4.1430 - val_accuracy: 0.0000e+00\n","Epoch 13/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0280 - accuracy: 0.0000e+00\n","Epoch 13: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 3.9979 - accuracy: 0.0256 - val_loss: 4.1456 - val_accuracy: 0.0000e+00\n","Epoch 14/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9803 - accuracy: 0.0312\n","Epoch 14: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.9833 - accuracy: 0.0256 - val_loss: 4.1528 - val_accuracy: 0.0000e+00\n","Epoch 15/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9832 - accuracy: 0.0312\n","Epoch 15: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 4.0020 - accuracy: 0.0256 - val_loss: 4.1585 - val_accuracy: 0.0000e+00\n","Epoch 16/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0349 - accuracy: 0.0000e+00\n","Epoch 16: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 4.0156 - accuracy: 0.0000e+00 - val_loss: 4.1595 - val_accuracy: 0.0000e+00\n","Epoch 17/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9811 - accuracy: 0.0312\n","Epoch 17: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.9682 - accuracy: 0.0256 - val_loss: 4.1623 - val_accuracy: 0.0000e+00\n","Epoch 18/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9862 - accuracy: 0.0312\n","Epoch 18: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.9857 - accuracy: 0.0256 - val_loss: 4.1669 - val_accuracy: 0.0000e+00\n","Epoch 19/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0172 - accuracy: 0.0312\n","Epoch 19: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 4.0099 - accuracy: 0.0256 - val_loss: 4.1713 - val_accuracy: 0.0000e+00\n","Epoch 20/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9629 - accuracy: 0.0312\n","Epoch 20: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 3.9852 - accuracy: 0.0513 - val_loss: 4.1788 - val_accuracy: 0.0000e+00\n","Epoch 21/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9966 - accuracy: 0.0000e+00\n","Epoch 21: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.9765 - accuracy: 0.0000e+00 - val_loss: 4.1770 - val_accuracy: 0.0000e+00\n","Epoch 22/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9709 - accuracy: 0.0312\n","Epoch 22: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.9820 - accuracy: 0.0256 - val_loss: 4.1776 - val_accuracy: 0.0000e+00\n","Epoch 23/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9967 - accuracy: 0.0000e+00\n","Epoch 23: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.9957 - accuracy: 0.0000e+00 - val_loss: 4.1506 - val_accuracy: 0.0000e+00\n","Epoch 24/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0040 - accuracy: 0.0625\n","Epoch 24: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.9998 - accuracy: 0.0513 - val_loss: 4.1331 - val_accuracy: 0.0000e+00\n","Epoch 25/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9971 - accuracy: 0.0625\n","Epoch 25: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 4.0045 - accuracy: 0.0513 - val_loss: 4.1386 - val_accuracy: 0.0000e+00\n","Epoch 26/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0179 - accuracy: 0.0938\n","Epoch 26: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 4.0125 - accuracy: 0.0769 - val_loss: 4.1538 - val_accuracy: 0.0000e+00\n","Epoch 27/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9708 - accuracy: 0.0625\n","Epoch 27: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.9888 - accuracy: 0.0513 - val_loss: 4.1693 - val_accuracy: 0.0000e+00\n","Epoch 28/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9920 - accuracy: 0.0000e+00\n","Epoch 28: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.9722 - accuracy: 0.0256 - val_loss: 4.1810 - val_accuracy: 0.0000e+00\n","Epoch 29/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9995 - accuracy: 0.0000e+00\n","Epoch 29: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.9860 - accuracy: 0.0000e+00 - val_loss: 4.1886 - val_accuracy: 0.0000e+00\n","Epoch 30/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9673 - accuracy: 0.0625\n","Epoch 30: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.9740 - accuracy: 0.0513 - val_loss: 4.1911 - val_accuracy: 0.0000e+00\n","Epoch 31/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9514 - accuracy: 0.0312\n","Epoch 31: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.9770 - accuracy: 0.0256 - val_loss: 4.1918 - val_accuracy: 0.0000e+00\n","Epoch 32/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9780 - accuracy: 0.0625\n","Epoch 32: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.9648 - accuracy: 0.0769 - val_loss: 4.1974 - val_accuracy: 0.0000e+00\n","Epoch 33/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9351 - accuracy: 0.0625\n","Epoch 33: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.9482 - accuracy: 0.0513 - val_loss: 4.2059 - val_accuracy: 0.0000e+00\n","Epoch 34/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9468 - accuracy: 0.0312\n","Epoch 34: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.9513 - accuracy: 0.0256 - val_loss: 4.2140 - val_accuracy: 0.0000e+00\n","Epoch 35/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9460 - accuracy: 0.0625\n","Epoch 35: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.9416 - accuracy: 0.0513 - val_loss: 4.2379 - val_accuracy: 0.0000e+00\n","Epoch 36/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9258 - accuracy: 0.0000e+00\n","Epoch 36: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.9415 - accuracy: 0.0000e+00 - val_loss: 4.2616 - val_accuracy: 0.0000e+00\n","Epoch 37/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9825 - accuracy: 0.0312\n","Epoch 37: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.9639 - accuracy: 0.0256 - val_loss: 4.2668 - val_accuracy: 0.0000e+00\n","Epoch 38/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9484 - accuracy: 0.0938\n","Epoch 38: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.9479 - accuracy: 0.0769 - val_loss: 4.2653 - val_accuracy: 0.0000e+00\n","Epoch 39/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9148 - accuracy: 0.0312\n","Epoch 39: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.9304 - accuracy: 0.0256 - val_loss: 4.2411 - val_accuracy: 0.0000e+00\n","Epoch 40/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9050 - accuracy: 0.0312\n","Epoch 40: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.9236 - accuracy: 0.0256 - val_loss: 4.2294 - val_accuracy: 0.0000e+00\n","Epoch 41/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9710 - accuracy: 0.0000e+00\n","Epoch 41: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.9454 - accuracy: 0.0000e+00 - val_loss: 4.2654 - val_accuracy: 0.0000e+00\n","Epoch 42/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9392 - accuracy: 0.0000e+00\n","Epoch 42: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.9509 - accuracy: 0.0256 - val_loss: 4.3019 - val_accuracy: 0.0000e+00\n","Epoch 43/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9305 - accuracy: 0.0000e+00\n","Epoch 43: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.9480 - accuracy: 0.0000e+00 - val_loss: 4.3148 - val_accuracy: 0.0000e+00\n","Epoch 44/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9380 - accuracy: 0.0000e+00\n","Epoch 44: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.9225 - accuracy: 0.0000e+00 - val_loss: 4.3129 - val_accuracy: 0.0000e+00\n","Epoch 45/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9105 - accuracy: 0.0312\n","Epoch 45: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.9394 - accuracy: 0.0256 - val_loss: 4.3105 - val_accuracy: 0.0000e+00\n","Epoch 46/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9431 - accuracy: 0.0625\n","Epoch 46: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.9056 - accuracy: 0.0513 - val_loss: 4.3119 - val_accuracy: 0.0000e+00\n","Epoch 47/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9327 - accuracy: 0.0312\n","Epoch 47: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.9230 - accuracy: 0.0256 - val_loss: 4.3068 - val_accuracy: 0.0000e+00\n","Epoch 48/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9077 - accuracy: 0.0312\n","Epoch 48: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.9095 - accuracy: 0.0256 - val_loss: 4.2857 - val_accuracy: 0.0000e+00\n","Epoch 49/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9091 - accuracy: 0.0312\n","Epoch 49: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.8911 - accuracy: 0.0256 - val_loss: 4.2975 - val_accuracy: 0.0000e+00\n","Epoch 50/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9226 - accuracy: 0.0312\n","Epoch 50: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.8896 - accuracy: 0.0513 - val_loss: 4.3361 - val_accuracy: 0.0000e+00\n","Epoch 51/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9102 - accuracy: 0.1250\n","Epoch 51: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.9047 - accuracy: 0.1282 - val_loss: 4.3723 - val_accuracy: 0.0000e+00\n","Epoch 52/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8983 - accuracy: 0.0312\n","Epoch 52: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.8760 - accuracy: 0.0256 - val_loss: 4.3869 - val_accuracy: 0.0000e+00\n","Epoch 53/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9237 - accuracy: 0.0312\n","Epoch 53: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.9064 - accuracy: 0.0513 - val_loss: 4.3941 - val_accuracy: 0.0000e+00\n","Epoch 54/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8639 - accuracy: 0.0312\n","Epoch 54: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.8735 - accuracy: 0.0256 - val_loss: 4.3848 - val_accuracy: 0.0000e+00\n","Epoch 55/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8460 - accuracy: 0.0000e+00\n","Epoch 55: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.8506 - accuracy: 0.0000e+00 - val_loss: 4.3465 - val_accuracy: 0.0000e+00\n","Epoch 56/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8915 - accuracy: 0.0000e+00\n","Epoch 56: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.8883 - accuracy: 0.0000e+00 - val_loss: 4.3023 - val_accuracy: 0.0000e+00\n","Epoch 57/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8658 - accuracy: 0.0312\n","Epoch 57: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.8951 - accuracy: 0.0513 - val_loss: 4.3320 - val_accuracy: 0.0000e+00\n","Epoch 58/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8799 - accuracy: 0.0000e+00\n","Epoch 58: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.9027 - accuracy: 0.0000e+00 - val_loss: 4.3505 - val_accuracy: 0.0000e+00\n","Epoch 59/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9300 - accuracy: 0.0312\n","Epoch 59: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.9024 - accuracy: 0.0256 - val_loss: 4.3541 - val_accuracy: 0.0000e+00\n","Epoch 60/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8176 - accuracy: 0.0312\n","Epoch 60: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 104ms/step - loss: 3.8359 - accuracy: 0.0256 - val_loss: 4.3649 - val_accuracy: 0.0000e+00\n","Epoch 61/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8521 - accuracy: 0.0312\n","Epoch 61: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.8652 - accuracy: 0.0256 - val_loss: 4.3854 - val_accuracy: 0.0000e+00\n","Epoch 62/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8707 - accuracy: 0.0000e+00\n","Epoch 62: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.8754 - accuracy: 0.0000e+00 - val_loss: 4.4079 - val_accuracy: 0.0000e+00\n","Epoch 63/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8621 - accuracy: 0.0625\n","Epoch 63: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.8379 - accuracy: 0.0513 - val_loss: 4.4215 - val_accuracy: 0.0000e+00\n","Epoch 64/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8520 - accuracy: 0.0625\n","Epoch 64: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.8776 - accuracy: 0.0513 - val_loss: 4.4347 - val_accuracy: 0.0000e+00\n","Epoch 65/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9239 - accuracy: 0.0000e+00\n","Epoch 65: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.8904 - accuracy: 0.0256 - val_loss: 4.4401 - val_accuracy: 0.0000e+00\n","Epoch 66/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8460 - accuracy: 0.0625\n","Epoch 66: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 3.8742 - accuracy: 0.0769 - val_loss: 4.4230 - val_accuracy: 0.0000e+00\n","Epoch 67/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8323 - accuracy: 0.0312\n","Epoch 67: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.8335 - accuracy: 0.0256 - val_loss: 4.3907 - val_accuracy: 0.0000e+00\n","Epoch 68/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9230 - accuracy: 0.0000e+00\n","Epoch 68: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.8985 - accuracy: 0.0000e+00 - val_loss: 4.3713 - val_accuracy: 0.0000e+00\n","Epoch 69/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8392 - accuracy: 0.0625\n","Epoch 69: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.8497 - accuracy: 0.0513 - val_loss: 4.4083 - val_accuracy: 0.0000e+00\n","Epoch 70/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8626 - accuracy: 0.0000e+00\n","Epoch 70: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.8691 - accuracy: 0.0000e+00 - val_loss: 4.4469 - val_accuracy: 0.0000e+00\n","Epoch 71/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8447 - accuracy: 0.0625\n","Epoch 71: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.8676 - accuracy: 0.0513 - val_loss: 4.4787 - val_accuracy: 0.0000e+00\n","Epoch 72/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8828 - accuracy: 0.0625\n","Epoch 72: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 103ms/step - loss: 3.8840 - accuracy: 0.0513 - val_loss: 4.4578 - val_accuracy: 0.0000e+00\n","Epoch 73/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8639 - accuracy: 0.0000e+00\n","Epoch 73: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.8439 - accuracy: 0.0000e+00 - val_loss: 4.3784 - val_accuracy: 0.0000e+00\n","Epoch 74/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8436 - accuracy: 0.0000e+00\n","Epoch 74: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.8361 - accuracy: 0.0000e+00 - val_loss: 4.3412 - val_accuracy: 0.0000e+00\n","Epoch 75/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8680 - accuracy: 0.0000e+00\n","Epoch 75: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.8646 - accuracy: 0.0000e+00 - val_loss: 4.4288 - val_accuracy: 0.0000e+00\n","Epoch 76/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8477 - accuracy: 0.0312\n","Epoch 76: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.8317 - accuracy: 0.0513 - val_loss: 4.5105 - val_accuracy: 0.0000e+00\n","Epoch 77/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7963 - accuracy: 0.0938\n","Epoch 77: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.8045 - accuracy: 0.0769 - val_loss: 4.5470 - val_accuracy: 0.0000e+00\n","Epoch 78/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8219 - accuracy: 0.0312\n","Epoch 78: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.8256 - accuracy: 0.0256 - val_loss: 4.5525 - val_accuracy: 0.0000e+00\n","Epoch 79/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8032 - accuracy: 0.0625\n","Epoch 79: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.8215 - accuracy: 0.0513 - val_loss: 4.5451 - val_accuracy: 0.0000e+00\n","Epoch 80/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8787 - accuracy: 0.0312\n","Epoch 80: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.8255 - accuracy: 0.0256 - val_loss: 4.5337 - val_accuracy: 0.0000e+00\n","Epoch 81/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8000 - accuracy: 0.0625\n","Epoch 81: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.8002 - accuracy: 0.0513 - val_loss: 4.4815 - val_accuracy: 0.0000e+00\n","Epoch 82/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7819 - accuracy: 0.0312\n","Epoch 82: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.7818 - accuracy: 0.0256 - val_loss: 4.3660 - val_accuracy: 0.0000e+00\n","Epoch 83/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8161 - accuracy: 0.0000e+00\n","Epoch 83: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 104ms/step - loss: 3.7984 - accuracy: 0.0256 - val_loss: 4.4308 - val_accuracy: 0.0000e+00\n","Epoch 84/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7550 - accuracy: 0.0938\n","Epoch 84: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.7549 - accuracy: 0.0769 - val_loss: 4.5335 - val_accuracy: 0.0000e+00\n","Epoch 85/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8147 - accuracy: 0.0312\n","Epoch 85: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.8329 - accuracy: 0.0256 - val_loss: 4.5838 - val_accuracy: 0.0000e+00\n","Epoch 86/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7741 - accuracy: 0.0312\n","Epoch 86: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 3.7911 - accuracy: 0.0256 - val_loss: 4.5945 - val_accuracy: 0.0000e+00\n","Epoch 87/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7388 - accuracy: 0.0312\n","Epoch 87: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 3.7748 - accuracy: 0.0256 - val_loss: 4.5826 - val_accuracy: 0.0000e+00\n","Epoch 88/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6938 - accuracy: 0.0938\n","Epoch 88: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.7229 - accuracy: 0.0769 - val_loss: 4.5518 - val_accuracy: 0.0000e+00\n","Epoch 89/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7594 - accuracy: 0.0312\n","Epoch 89: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.7637 - accuracy: 0.0256 - val_loss: 4.4670 - val_accuracy: 0.0000e+00\n","Epoch 90/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7662 - accuracy: 0.0312\n","Epoch 90: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.7509 - accuracy: 0.0256 - val_loss: 4.5154 - val_accuracy: 0.0000e+00\n","Epoch 91/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6553 - accuracy: 0.1250\n","Epoch 91: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.7030 - accuracy: 0.1026 - val_loss: 4.5968 - val_accuracy: 0.0000e+00\n","Epoch 92/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8075 - accuracy: 0.0625\n","Epoch 92: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.7788 - accuracy: 0.0513 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n","Epoch 93/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7219 - accuracy: 0.0625\n","Epoch 93: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.7274 - accuracy: 0.0769 - val_loss: 4.5884 - val_accuracy: 0.0000e+00\n","Epoch 94/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7259 - accuracy: 0.0938\n","Epoch 94: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.7361 - accuracy: 0.0769 - val_loss: 4.5717 - val_accuracy: 0.0000e+00\n","Epoch 95/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6969 - accuracy: 0.0625\n","Epoch 95: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.7062 - accuracy: 0.0769 - val_loss: 4.5280 - val_accuracy: 0.0000e+00\n","Epoch 96/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7255 - accuracy: 0.0625\n","Epoch 96: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.7318 - accuracy: 0.0769 - val_loss: 4.5251 - val_accuracy: 0.0000e+00\n","Epoch 97/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6735 - accuracy: 0.0312\n","Epoch 97: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.6862 - accuracy: 0.0256 - val_loss: 4.6258 - val_accuracy: 0.0000e+00\n","Epoch 98/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7472 - accuracy: 0.0938\n","Epoch 98: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.7533 - accuracy: 0.0769 - val_loss: 4.7033 - val_accuracy: 0.0000e+00\n","Epoch 99/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6912 - accuracy: 0.0938\n","Epoch 99: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.7238 - accuracy: 0.0769 - val_loss: 4.7358 - val_accuracy: 0.0000e+00\n","Epoch 100/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7383 - accuracy: 0.0000e+00\n","Epoch 100: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.7185 - accuracy: 0.0256 - val_loss: 4.7518 - val_accuracy: 0.0000e+00\n","Epoch 101/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7262 - accuracy: 0.0625\n","Epoch 101: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.6919 - accuracy: 0.0513 - val_loss: 4.7525 - val_accuracy: 0.0000e+00\n","Epoch 102/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6668 - accuracy: 0.0000e+00\n","Epoch 102: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.6907 - accuracy: 0.0000e+00 - val_loss: 4.7188 - val_accuracy: 0.0000e+00\n","Epoch 103/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6755 - accuracy: 0.0625\n","Epoch 103: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.6895 - accuracy: 0.0513 - val_loss: 4.5938 - val_accuracy: 0.0000e+00\n","Epoch 104/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6812 - accuracy: 0.0938\n","Epoch 104: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.6956 - accuracy: 0.0769 - val_loss: 4.5441 - val_accuracy: 0.0000e+00\n","Epoch 105/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6752 - accuracy: 0.0938\n","Epoch 105: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 3.6628 - accuracy: 0.0769 - val_loss: 4.6707 - val_accuracy: 0.0000e+00\n","Epoch 106/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6230 - accuracy: 0.0312\n","Epoch 106: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.6554 - accuracy: 0.0513 - val_loss: 4.8108 - val_accuracy: 0.0000e+00\n","Epoch 107/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6263 - accuracy: 0.0312\n","Epoch 107: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.6406 - accuracy: 0.0513 - val_loss: 4.8844 - val_accuracy: 0.0000e+00\n","Epoch 108/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6338 - accuracy: 0.0000e+00\n","Epoch 108: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.6483 - accuracy: 0.0256 - val_loss: 4.9023 - val_accuracy: 0.0000e+00\n","Epoch 109/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5896 - accuracy: 0.0312\n","Epoch 109: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 3.6459 - accuracy: 0.0256 - val_loss: 4.8187 - val_accuracy: 0.0000e+00\n","Epoch 110/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6892 - accuracy: 0.0312\n","Epoch 110: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 3.6639 - accuracy: 0.0256 - val_loss: 4.5893 - val_accuracy: 0.0000e+00\n","Epoch 111/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7664 - accuracy: 0.0312\n","Epoch 111: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.6964 - accuracy: 0.0256 - val_loss: 4.6776 - val_accuracy: 0.0000e+00\n","Epoch 112/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6125 - accuracy: 0.0938\n","Epoch 112: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 3.6378 - accuracy: 0.0769 - val_loss: 4.8290 - val_accuracy: 0.0000e+00\n","Epoch 113/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6526 - accuracy: 0.0312\n","Epoch 113: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.6140 - accuracy: 0.0513 - val_loss: 4.9138 - val_accuracy: 0.0000e+00\n","Epoch 114/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6641 - accuracy: 0.0000e+00\n","Epoch 114: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.6655 - accuracy: 0.0256 - val_loss: 4.9627 - val_accuracy: 0.0000e+00\n","Epoch 115/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5540 - accuracy: 0.1250\n","Epoch 115: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.5948 - accuracy: 0.1026 - val_loss: 4.9795 - val_accuracy: 0.0000e+00\n","Epoch 116/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6374 - accuracy: 0.0625\n","Epoch 116: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.6599 - accuracy: 0.0513 - val_loss: 4.9194 - val_accuracy: 0.0000e+00\n","Epoch 117/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5079 - accuracy: 0.0625\n","Epoch 117: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.5899 - accuracy: 0.0513 - val_loss: 4.6871 - val_accuracy: 0.0000e+00\n","Epoch 118/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6506 - accuracy: 0.0312\n","Epoch 118: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.6604 - accuracy: 0.0513 - val_loss: 4.6710 - val_accuracy: 0.0000e+00\n","Epoch 119/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7273 - accuracy: 0.0625\n","Epoch 119: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.6639 - accuracy: 0.0513 - val_loss: 4.7992 - val_accuracy: 0.0000e+00\n","Epoch 120/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5866 - accuracy: 0.0312\n","Epoch 120: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.6150 - accuracy: 0.0256 - val_loss: 4.9555 - val_accuracy: 0.0000e+00\n","Epoch 121/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5155 - accuracy: 0.0938\n","Epoch 121: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.5449 - accuracy: 0.0769 - val_loss: 5.0099 - val_accuracy: 0.0000e+00\n","Epoch 122/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5146 - accuracy: 0.0312\n","Epoch 122: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.5218 - accuracy: 0.0256 - val_loss: 5.0100 - val_accuracy: 0.0000e+00\n","Epoch 123/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5846 - accuracy: 0.0312\n","Epoch 123: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.5701 - accuracy: 0.0256 - val_loss: 4.9846 - val_accuracy: 0.0000e+00\n","Epoch 124/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6108 - accuracy: 0.0312\n","Epoch 124: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.5831 - accuracy: 0.0256 - val_loss: 4.9070 - val_accuracy: 0.0000e+00\n","Epoch 125/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5834 - accuracy: 0.0312\n","Epoch 125: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.5930 - accuracy: 0.0256 - val_loss: 4.9346 - val_accuracy: 0.0000e+00\n","Epoch 126/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5304 - accuracy: 0.0625\n","Epoch 126: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.5366 - accuracy: 0.0513 - val_loss: 5.0004 - val_accuracy: 0.0000e+00\n","Epoch 127/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4864 - accuracy: 0.1250\n","Epoch 127: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.4857 - accuracy: 0.1026 - val_loss: 5.0305 - val_accuracy: 0.0000e+00\n","Epoch 128/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5775 - accuracy: 0.0625\n","Epoch 128: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.5566 - accuracy: 0.1026 - val_loss: 4.9722 - val_accuracy: 0.0000e+00\n","Epoch 129/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5084 - accuracy: 0.0625\n","Epoch 129: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.5137 - accuracy: 0.1026 - val_loss: 4.9610 - val_accuracy: 0.0000e+00\n","Epoch 130/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4416 - accuracy: 0.0312\n","Epoch 130: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.4994 - accuracy: 0.0256 - val_loss: 5.0360 - val_accuracy: 0.0000e+00\n","Epoch 131/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4911 - accuracy: 0.0625\n","Epoch 131: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.4996 - accuracy: 0.0513 - val_loss: 5.1192 - val_accuracy: 0.0000e+00\n","Epoch 132/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4564 - accuracy: 0.0312\n","Epoch 132: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.4769 - accuracy: 0.0256 - val_loss: 5.1362 - val_accuracy: 0.0000e+00\n","Epoch 133/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5391 - accuracy: 0.0312\n","Epoch 133: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.4978 - accuracy: 0.0256 - val_loss: 5.1451 - val_accuracy: 0.0000e+00\n","Epoch 134/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5644 - accuracy: 0.0000e+00\n","Epoch 134: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.5484 - accuracy: 0.0000e+00 - val_loss: 5.1476 - val_accuracy: 0.0000e+00\n","Epoch 135/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4391 - accuracy: 0.0625\n","Epoch 135: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.4575 - accuracy: 0.0513 - val_loss: 5.1582 - val_accuracy: 0.0000e+00\n","Epoch 136/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5473 - accuracy: 0.0312\n","Epoch 136: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.4948 - accuracy: 0.0769 - val_loss: 5.1820 - val_accuracy: 0.0000e+00\n","Epoch 137/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5272 - accuracy: 0.0938\n","Epoch 137: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.5009 - accuracy: 0.1026 - val_loss: 5.1756 - val_accuracy: 0.0000e+00\n","Epoch 138/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4872 - accuracy: 0.0625\n","Epoch 138: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.4543 - accuracy: 0.0769 - val_loss: 5.1789 - val_accuracy: 0.0000e+00\n","Epoch 139/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4571 - accuracy: 0.0625\n","Epoch 139: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.4377 - accuracy: 0.0513 - val_loss: 5.2009 - val_accuracy: 0.0000e+00\n","Epoch 140/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4711 - accuracy: 0.0625\n","Epoch 140: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.4848 - accuracy: 0.0513 - val_loss: 5.2644 - val_accuracy: 0.0000e+00\n","Epoch 141/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4200 - accuracy: 0.0625\n","Epoch 141: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.4672 - accuracy: 0.0513 - val_loss: 5.3903 - val_accuracy: 0.0000e+00\n","Epoch 142/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4980 - accuracy: 0.0312\n","Epoch 142: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.4729 - accuracy: 0.0769 - val_loss: 5.4693 - val_accuracy: 0.0000e+00\n","Epoch 143/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5721 - accuracy: 0.0312\n","Epoch 143: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.6229 - accuracy: 0.0256 - val_loss: 5.3980 - val_accuracy: 0.0000e+00\n","Epoch 144/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6133 - accuracy: 0.0312\n","Epoch 144: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.5534 - accuracy: 0.0513 - val_loss: 5.1824 - val_accuracy: 0.0000e+00\n","Epoch 145/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4397 - accuracy: 0.0938\n","Epoch 145: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.4185 - accuracy: 0.1026 - val_loss: 5.0325 - val_accuracy: 0.0000e+00\n","Epoch 146/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5403 - accuracy: 0.0625\n","Epoch 146: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.4746 - accuracy: 0.0513 - val_loss: 5.1410 - val_accuracy: 0.0000e+00\n","Epoch 147/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5429 - accuracy: 0.0938\n","Epoch 147: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.4666 - accuracy: 0.0769 - val_loss: 5.4062 - val_accuracy: 0.0000e+00\n","Epoch 148/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4875 - accuracy: 0.0625\n","Epoch 148: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.5018 - accuracy: 0.0513 - val_loss: 5.4953 - val_accuracy: 0.0000e+00\n","Epoch 149/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4428 - accuracy: 0.0312\n","Epoch 149: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.4668 - accuracy: 0.0513 - val_loss: 5.5240 - val_accuracy: 0.0000e+00\n","Epoch 150/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4383 - accuracy: 0.0312\n","Epoch 150: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.4987 - accuracy: 0.0256 - val_loss: 5.5346 - val_accuracy: 0.0000e+00\n","Epoch 151/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4328 - accuracy: 0.0938\n","Epoch 151: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.4371 - accuracy: 0.1026 - val_loss: 5.4089 - val_accuracy: 0.0000e+00\n","Epoch 152/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5421 - accuracy: 0.0312\n","Epoch 152: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.4737 - accuracy: 0.0513 - val_loss: 5.1591 - val_accuracy: 0.0000e+00\n","Epoch 153/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4599 - accuracy: 0.0312\n","Epoch 153: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.4652 - accuracy: 0.0256 - val_loss: 5.1616 - val_accuracy: 0.0000e+00\n","Epoch 154/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4251 - accuracy: 0.0625\n","Epoch 154: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.4144 - accuracy: 0.0769 - val_loss: 5.2927 - val_accuracy: 0.0000e+00\n","Epoch 155/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4591 - accuracy: 0.0312\n","Epoch 155: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.4371 - accuracy: 0.0513 - val_loss: 5.3493 - val_accuracy: 0.0000e+00\n","Epoch 156/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4622 - accuracy: 0.0625\n","Epoch 156: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.4634 - accuracy: 0.0513 - val_loss: 5.4260 - val_accuracy: 0.0000e+00\n","Epoch 157/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3689 - accuracy: 0.0625\n","Epoch 157: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 103ms/step - loss: 3.3989 - accuracy: 0.0513 - val_loss: 5.4804 - val_accuracy: 0.0000e+00\n","Epoch 158/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4111 - accuracy: 0.1250\n","Epoch 158: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.3801 - accuracy: 0.1026 - val_loss: 5.5402 - val_accuracy: 0.0000e+00\n","Epoch 159/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3560 - accuracy: 0.0625\n","Epoch 159: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.3922 - accuracy: 0.0513 - val_loss: 5.5399 - val_accuracy: 0.0000e+00\n","Epoch 160/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4776 - accuracy: 0.0312\n","Epoch 160: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.4697 - accuracy: 0.0256 - val_loss: 5.4862 - val_accuracy: 0.0000e+00\n","Epoch 161/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4216 - accuracy: 0.0000e+00\n","Epoch 161: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.3745 - accuracy: 0.0256 - val_loss: 5.4832 - val_accuracy: 0.0000e+00\n","Epoch 162/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3510 - accuracy: 0.0312\n","Epoch 162: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.3805 - accuracy: 0.0256 - val_loss: 5.5400 - val_accuracy: 0.0000e+00\n","Epoch 163/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3517 - accuracy: 0.0312\n","Epoch 163: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.3639 - accuracy: 0.0513 - val_loss: 5.4972 - val_accuracy: 0.0000e+00\n","Epoch 164/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3641 - accuracy: 0.0938\n","Epoch 164: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.4045 - accuracy: 0.0769 - val_loss: 5.3993 - val_accuracy: 0.0000e+00\n","Epoch 165/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4451 - accuracy: 0.0625\n","Epoch 165: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.3831 - accuracy: 0.0513 - val_loss: 5.3048 - val_accuracy: 0.0000e+00\n","Epoch 166/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4443 - accuracy: 0.0938\n","Epoch 166: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.4004 - accuracy: 0.0769 - val_loss: 5.4011 - val_accuracy: 0.0000e+00\n","Epoch 167/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4650 - accuracy: 0.0625\n","Epoch 167: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.4084 - accuracy: 0.0769 - val_loss: 5.5074 - val_accuracy: 0.0000e+00\n","Epoch 168/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3134 - accuracy: 0.0625\n","Epoch 168: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.2819 - accuracy: 0.0513 - val_loss: 5.6732 - val_accuracy: 0.0000e+00\n","Epoch 169/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3486 - accuracy: 0.0312\n","Epoch 169: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 3.3543 - accuracy: 0.0256 - val_loss: 5.7122 - val_accuracy: 0.0000e+00\n","Epoch 170/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2765 - accuracy: 0.0938\n","Epoch 170: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.2913 - accuracy: 0.0769 - val_loss: 5.6076 - val_accuracy: 0.0000e+00\n","Epoch 171/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3854 - accuracy: 0.0312\n","Epoch 171: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.3606 - accuracy: 0.0513 - val_loss: 5.4521 - val_accuracy: 0.0000e+00\n","Epoch 172/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3807 - accuracy: 0.0312\n","Epoch 172: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.3851 - accuracy: 0.0256 - val_loss: 5.4534 - val_accuracy: 0.0000e+00\n","Epoch 173/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2536 - accuracy: 0.0938\n","Epoch 173: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.2822 - accuracy: 0.0769 - val_loss: 5.5514 - val_accuracy: 0.0000e+00\n","Epoch 174/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3374 - accuracy: 0.0312\n","Epoch 174: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.3578 - accuracy: 0.0256 - val_loss: 5.7150 - val_accuracy: 0.0000e+00\n","Epoch 175/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2765 - accuracy: 0.0000e+00\n","Epoch 175: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.2626 - accuracy: 0.0256 - val_loss: 5.7038 - val_accuracy: 0.0000e+00\n","Epoch 176/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2534 - accuracy: 0.0625\n","Epoch 176: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.3189 - accuracy: 0.0513 - val_loss: 5.5961 - val_accuracy: 0.0000e+00\n","Epoch 177/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2385 - accuracy: 0.0625\n","Epoch 177: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.2739 - accuracy: 0.0513 - val_loss: 5.5301 - val_accuracy: 0.0000e+00\n","Epoch 178/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3468 - accuracy: 0.0312\n","Epoch 178: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.2984 - accuracy: 0.0513 - val_loss: 5.5691 - val_accuracy: 0.0000e+00\n","Epoch 179/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1961 - accuracy: 0.0000e+00\n","Epoch 179: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.2729 - accuracy: 0.0000e+00 - val_loss: 5.6592 - val_accuracy: 0.0000e+00\n","Epoch 180/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2944 - accuracy: 0.0312\n","Epoch 180: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.3489 - accuracy: 0.0256 - val_loss: 5.7932 - val_accuracy: 0.0000e+00\n","Epoch 181/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2856 - accuracy: 0.0938\n","Epoch 181: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.3236 - accuracy: 0.0769 - val_loss: 5.9056 - val_accuracy: 0.0000e+00\n","Epoch 182/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3249 - accuracy: 0.0312\n","Epoch 182: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.3390 - accuracy: 0.0513 - val_loss: 5.9370 - val_accuracy: 0.0000e+00\n","Epoch 183/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3648 - accuracy: 0.0312\n","Epoch 183: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.3680 - accuracy: 0.0256 - val_loss: 5.9622 - val_accuracy: 0.0000e+00\n","Epoch 184/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3101 - accuracy: 0.0312\n","Epoch 184: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.3320 - accuracy: 0.0256 - val_loss: 5.8151 - val_accuracy: 0.0000e+00\n","Epoch 185/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2427 - accuracy: 0.0312\n","Epoch 185: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.2513 - accuracy: 0.0513 - val_loss: 5.5802 - val_accuracy: 0.0000e+00\n","Epoch 186/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3465 - accuracy: 0.0312\n","Epoch 186: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.3268 - accuracy: 0.0256 - val_loss: 5.6013 - val_accuracy: 0.0000e+00\n","Epoch 187/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3037 - accuracy: 0.0938\n","Epoch 187: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.2819 - accuracy: 0.0769 - val_loss: 5.6577 - val_accuracy: 0.0000e+00\n","Epoch 188/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3303 - accuracy: 0.0625\n","Epoch 188: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.3060 - accuracy: 0.0513 - val_loss: 5.8961 - val_accuracy: 0.0000e+00\n","Epoch 189/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3254 - accuracy: 0.0625\n","Epoch 189: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.2979 - accuracy: 0.0513 - val_loss: 5.9556 - val_accuracy: 0.0000e+00\n","Epoch 190/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2225 - accuracy: 0.0938\n","Epoch 190: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 3.2464 - accuracy: 0.0769 - val_loss: 5.6509 - val_accuracy: 0.0000e+00\n","Epoch 191/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3180 - accuracy: 0.0625\n","Epoch 191: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.2627 - accuracy: 0.0513 - val_loss: 5.4720 - val_accuracy: 0.0000e+00\n","Epoch 192/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3841 - accuracy: 0.0625\n","Epoch 192: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.3390 - accuracy: 0.0513 - val_loss: 5.6615 - val_accuracy: 0.0000e+00\n","Epoch 193/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3355 - accuracy: 0.0625\n","Epoch 193: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.3206 - accuracy: 0.0513 - val_loss: 6.1974 - val_accuracy: 0.0000e+00\n","Epoch 194/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3097 - accuracy: 0.0625\n","Epoch 194: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.3347 - accuracy: 0.0513 - val_loss: 6.2636 - val_accuracy: 0.0000e+00\n","Epoch 195/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2967 - accuracy: 0.0312\n","Epoch 195: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.2917 - accuracy: 0.0256 - val_loss: 6.2840 - val_accuracy: 0.0000e+00\n","Epoch 196/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3246 - accuracy: 0.0938\n","Epoch 196: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.3087 - accuracy: 0.0769 - val_loss: 6.2389 - val_accuracy: 0.0000e+00\n","Epoch 197/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3567 - accuracy: 0.0938\n","Epoch 197: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.3441 - accuracy: 0.0769 - val_loss: 6.2157 - val_accuracy: 0.0000e+00\n","Epoch 198/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2796 - accuracy: 0.0312\n","Epoch 198: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.2794 - accuracy: 0.0256 - val_loss: 6.1985 - val_accuracy: 0.0000e+00\n","Epoch 199/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2943 - accuracy: 0.0625\n","Epoch 199: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.3484 - accuracy: 0.0513 - val_loss: 6.1247 - val_accuracy: 0.0000e+00\n","Epoch 200/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3659 - accuracy: 0.0312\n","Epoch 200: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 3.3327 - accuracy: 0.0513 - val_loss: 6.0039 - val_accuracy: 0.0000e+00\n","Epoch 201/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2660 - accuracy: 0.0000e+00\n","Epoch 201: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.2986 - accuracy: 0.0000e+00 - val_loss: 5.9815 - val_accuracy: 0.0000e+00\n","Epoch 202/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2539 - accuracy: 0.0312\n","Epoch 202: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.2460 - accuracy: 0.0513 - val_loss: 6.0338 - val_accuracy: 0.0000e+00\n","Epoch 203/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2444 - accuracy: 0.0312\n","Epoch 203: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.2602 - accuracy: 0.0256 - val_loss: 6.1979 - val_accuracy: 0.0000e+00\n","Epoch 204/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2070 - accuracy: 0.0938\n","Epoch 204: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.2662 - accuracy: 0.1026 - val_loss: 6.2897 - val_accuracy: 0.0000e+00\n","Epoch 205/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3083 - accuracy: 0.0312\n","Epoch 205: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.2769 - accuracy: 0.0256 - val_loss: 6.3266 - val_accuracy: 0.0000e+00\n","Epoch 206/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1488 - accuracy: 0.0625\n","Epoch 206: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.1736 - accuracy: 0.0769 - val_loss: 6.3309 - val_accuracy: 0.0000e+00\n","Epoch 207/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2128 - accuracy: 0.0625\n","Epoch 207: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.2240 - accuracy: 0.0513 - val_loss: 6.3393 - val_accuracy: 0.0000e+00\n","Epoch 208/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2012 - accuracy: 0.0938\n","Epoch 208: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.2577 - accuracy: 0.0769 - val_loss: 6.2804 - val_accuracy: 0.0000e+00\n","Epoch 209/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2745 - accuracy: 0.0312\n","Epoch 209: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.2501 - accuracy: 0.0513 - val_loss: 6.2230 - val_accuracy: 0.0000e+00\n","Epoch 210/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2510 - accuracy: 0.0625\n","Epoch 210: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.2371 - accuracy: 0.0769 - val_loss: 6.2063 - val_accuracy: 0.0000e+00\n","Epoch 211/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1645 - accuracy: 0.1250\n","Epoch 211: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.1440 - accuracy: 0.1282 - val_loss: 6.1835 - val_accuracy: 0.0000e+00\n","Epoch 212/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1920 - accuracy: 0.0938\n","Epoch 212: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.2201 - accuracy: 0.0769 - val_loss: 6.1852 - val_accuracy: 0.0000e+00\n","Epoch 213/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2971 - accuracy: 0.0312\n","Epoch 213: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.2618 - accuracy: 0.0256 - val_loss: 6.2059 - val_accuracy: 0.0000e+00\n","Epoch 214/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2627 - accuracy: 0.0625\n","Epoch 214: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.2647 - accuracy: 0.0513 - val_loss: 6.2319 - val_accuracy: 0.0000e+00\n","Epoch 215/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1407 - accuracy: 0.0625\n","Epoch 215: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.1874 - accuracy: 0.0513 - val_loss: 6.2547 - val_accuracy: 0.0000e+00\n","Epoch 216/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2070 - accuracy: 0.0938\n","Epoch 216: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.2208 - accuracy: 0.1026 - val_loss: 6.2690 - val_accuracy: 0.0000e+00\n","Epoch 217/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2675 - accuracy: 0.0938\n","Epoch 217: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.2077 - accuracy: 0.0769 - val_loss: 6.2874 - val_accuracy: 0.0000e+00\n","Epoch 218/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1886 - accuracy: 0.0000e+00\n","Epoch 218: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.2521 - accuracy: 0.0000e+00 - val_loss: 6.3013 - val_accuracy: 0.0000e+00\n","Epoch 219/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2344 - accuracy: 0.0000e+00\n","Epoch 219: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.2186 - accuracy: 0.0000e+00 - val_loss: 6.3094 - val_accuracy: 0.0000e+00\n","Epoch 220/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1852 - accuracy: 0.0000e+00\n","Epoch 220: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.1902 - accuracy: 0.0256 - val_loss: 6.3224 - val_accuracy: 0.0000e+00\n","Epoch 221/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1830 - accuracy: 0.1250\n","Epoch 221: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.1860 - accuracy: 0.1026 - val_loss: 6.3116 - val_accuracy: 0.0000e+00\n","Epoch 222/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1721 - accuracy: 0.0938\n","Epoch 222: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.1766 - accuracy: 0.1026 - val_loss: 6.1685 - val_accuracy: 0.0000e+00\n","Epoch 223/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2155 - accuracy: 0.0625\n","Epoch 223: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.1639 - accuracy: 0.1026 - val_loss: 6.1654 - val_accuracy: 0.0000e+00\n","Epoch 224/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2483 - accuracy: 0.0312\n","Epoch 224: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.2323 - accuracy: 0.0256 - val_loss: 6.2249 - val_accuracy: 0.0000e+00\n","Epoch 225/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1777 - accuracy: 0.1250\n","Epoch 225: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.1791 - accuracy: 0.1282 - val_loss: 6.3558 - val_accuracy: 0.0000e+00\n","Epoch 226/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1925 - accuracy: 0.0938\n","Epoch 226: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.1346 - accuracy: 0.0769 - val_loss: 6.4307 - val_accuracy: 0.0000e+00\n","Epoch 227/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1556 - accuracy: 0.0938\n","Epoch 227: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.1531 - accuracy: 0.0769 - val_loss: 6.3396 - val_accuracy: 0.0000e+00\n","Epoch 228/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2178 - accuracy: 0.0625\n","Epoch 228: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.2357 - accuracy: 0.0513 - val_loss: 6.3417 - val_accuracy: 0.0000e+00\n","Epoch 229/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1675 - accuracy: 0.0938\n","Epoch 229: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 3.1945 - accuracy: 0.0769 - val_loss: 6.5248 - val_accuracy: 0.0000e+00\n","Epoch 230/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2725 - accuracy: 0.0312\n","Epoch 230: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.2642 - accuracy: 0.0513 - val_loss: 6.4686 - val_accuracy: 0.0000e+00\n","Epoch 231/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2720 - accuracy: 0.0625\n","Epoch 231: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.2374 - accuracy: 0.0769 - val_loss: 6.4085 - val_accuracy: 0.0000e+00\n","Epoch 232/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1313 - accuracy: 0.0625\n","Epoch 232: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.1520 - accuracy: 0.0513 - val_loss: 6.4034 - val_accuracy: 0.0000e+00\n","Epoch 233/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0829 - accuracy: 0.1250\n","Epoch 233: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 3.0998 - accuracy: 0.1026 - val_loss: 6.3685 - val_accuracy: 0.0000e+00\n","Epoch 234/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1200 - accuracy: 0.0938\n","Epoch 234: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.1236 - accuracy: 0.0769 - val_loss: 6.4318 - val_accuracy: 0.0000e+00\n","Epoch 235/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1773 - accuracy: 0.0625\n","Epoch 235: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.1548 - accuracy: 0.0769 - val_loss: 6.4707 - val_accuracy: 0.0000e+00\n","Epoch 236/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1309 - accuracy: 0.1562\n","Epoch 236: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 3.1451 - accuracy: 0.1282 - val_loss: 6.4803 - val_accuracy: 0.0000e+00\n","Epoch 237/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2088 - accuracy: 0.0312\n","Epoch 237: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.1873 - accuracy: 0.0256 - val_loss: 6.4586 - val_accuracy: 0.0000e+00\n","Epoch 238/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0995 - accuracy: 0.0312\n","Epoch 238: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.1270 - accuracy: 0.0256 - val_loss: 6.4584 - val_accuracy: 0.0000e+00\n","Epoch 239/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2345 - accuracy: 0.0938\n","Epoch 239: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.1739 - accuracy: 0.0769 - val_loss: 6.4837 - val_accuracy: 0.0000e+00\n","Epoch 240/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1417 - accuracy: 0.1250\n","Epoch 240: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.1582 - accuracy: 0.1026 - val_loss: 6.5524 - val_accuracy: 0.0000e+00\n","Epoch 241/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0590 - accuracy: 0.0312\n","Epoch 241: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0477 - accuracy: 0.0513 - val_loss: 6.6010 - val_accuracy: 0.0000e+00\n","Epoch 242/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0884 - accuracy: 0.0938\n","Epoch 242: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.1049 - accuracy: 0.0769 - val_loss: 6.6197 - val_accuracy: 0.0000e+00\n","Epoch 243/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1330 - accuracy: 0.0312\n","Epoch 243: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.1299 - accuracy: 0.0513 - val_loss: 6.6044 - val_accuracy: 0.0000e+00\n","Epoch 244/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1678 - accuracy: 0.0312\n","Epoch 244: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.1453 - accuracy: 0.0513 - val_loss: 6.5314 - val_accuracy: 0.0000e+00\n","Epoch 245/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1825 - accuracy: 0.0625\n","Epoch 245: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.1413 - accuracy: 0.0513 - val_loss: 6.4940 - val_accuracy: 0.0000e+00\n","Epoch 246/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1117 - accuracy: 0.0938\n","Epoch 246: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.1055 - accuracy: 0.0769 - val_loss: 6.5058 - val_accuracy: 0.0000e+00\n","Epoch 247/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9739 - accuracy: 0.0625\n","Epoch 247: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.0105 - accuracy: 0.0513 - val_loss: 6.5217 - val_accuracy: 0.0000e+00\n","Epoch 248/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1464 - accuracy: 0.0625\n","Epoch 248: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.1548 - accuracy: 0.0513 - val_loss: 6.5636 - val_accuracy: 0.0000e+00\n","Epoch 249/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0977 - accuracy: 0.0938\n","Epoch 249: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.1308 - accuracy: 0.0769 - val_loss: 6.7012 - val_accuracy: 0.0000e+00\n","Epoch 250/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1463 - accuracy: 0.0312\n","Epoch 250: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.1492 - accuracy: 0.0513 - val_loss: 6.7153 - val_accuracy: 0.0000e+00\n","Epoch 251/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2051 - accuracy: 0.0625\n","Epoch 251: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.1607 - accuracy: 0.0513 - val_loss: 6.7339 - val_accuracy: 0.0000e+00\n","Epoch 252/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0454 - accuracy: 0.0938\n","Epoch 252: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 104ms/step - loss: 3.0789 - accuracy: 0.0769 - val_loss: 6.7533 - val_accuracy: 0.0000e+00\n","Epoch 253/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0793 - accuracy: 0.0938\n","Epoch 253: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.0424 - accuracy: 0.0769 - val_loss: 6.7418 - val_accuracy: 0.0000e+00\n","Epoch 254/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0786 - accuracy: 0.0312\n","Epoch 254: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.1235 - accuracy: 0.0256 - val_loss: 6.6290 - val_accuracy: 0.0000e+00\n","Epoch 255/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1657 - accuracy: 0.0312\n","Epoch 255: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.1571 - accuracy: 0.0256 - val_loss: 6.6171 - val_accuracy: 0.0000e+00\n","Epoch 256/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2763 - accuracy: 0.0625\n","Epoch 256: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.2145 - accuracy: 0.0769 - val_loss: 6.6239 - val_accuracy: 0.0000e+00\n","Epoch 257/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0658 - accuracy: 0.0938\n","Epoch 257: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.1373 - accuracy: 0.0769 - val_loss: 6.6318 - val_accuracy: 0.0000e+00\n","Epoch 258/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0419 - accuracy: 0.0938\n","Epoch 258: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.0805 - accuracy: 0.0769 - val_loss: 6.6442 - val_accuracy: 0.0000e+00\n","Epoch 259/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1372 - accuracy: 0.0625\n","Epoch 259: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.1427 - accuracy: 0.0769 - val_loss: 6.6985 - val_accuracy: 0.0000e+00\n","Epoch 260/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0796 - accuracy: 0.0625\n","Epoch 260: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.0591 - accuracy: 0.0513 - val_loss: 6.7392 - val_accuracy: 0.0000e+00\n","Epoch 261/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0871 - accuracy: 0.0312\n","Epoch 261: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.0729 - accuracy: 0.0256 - val_loss: 6.7320 - val_accuracy: 0.0000e+00\n","Epoch 262/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0705 - accuracy: 0.0625\n","Epoch 262: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.1260 - accuracy: 0.0513 - val_loss: 6.7882 - val_accuracy: 0.0000e+00\n","Epoch 263/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1631 - accuracy: 0.1250\n","Epoch 263: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.1317 - accuracy: 0.1282 - val_loss: 6.8850 - val_accuracy: 0.0000e+00\n","Epoch 264/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1294 - accuracy: 0.0938\n","Epoch 264: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.1184 - accuracy: 0.0769 - val_loss: 7.0082 - val_accuracy: 0.0000e+00\n","Epoch 265/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1084 - accuracy: 0.0312\n","Epoch 265: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.0734 - accuracy: 0.0513 - val_loss: 7.0003 - val_accuracy: 0.0000e+00\n","Epoch 266/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1373 - accuracy: 0.0625\n","Epoch 266: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.0974 - accuracy: 0.0769 - val_loss: 6.9269 - val_accuracy: 0.0000e+00\n","Epoch 267/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0057 - accuracy: 0.1562\n","Epoch 267: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.0623 - accuracy: 0.1282 - val_loss: 6.8997 - val_accuracy: 0.0000e+00\n","Epoch 268/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0482 - accuracy: 0.0938\n","Epoch 268: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.0562 - accuracy: 0.1026 - val_loss: 6.8937 - val_accuracy: 0.0000e+00\n","Epoch 269/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0304 - accuracy: 0.1562\n","Epoch 269: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.9933 - accuracy: 0.1538 - val_loss: 6.9124 - val_accuracy: 0.0000e+00\n","Epoch 270/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0387 - accuracy: 0.0938\n","Epoch 270: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.0587 - accuracy: 0.1026 - val_loss: 6.9515 - val_accuracy: 0.0000e+00\n","Epoch 271/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0239 - accuracy: 0.1250\n","Epoch 271: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.0499 - accuracy: 0.1282 - val_loss: 6.9905 - val_accuracy: 0.0000e+00\n","Epoch 272/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0309 - accuracy: 0.0312\n","Epoch 272: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0208 - accuracy: 0.0256 - val_loss: 7.0069 - val_accuracy: 0.0000e+00\n","Epoch 273/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0119 - accuracy: 0.0938\n","Epoch 273: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.0198 - accuracy: 0.0769 - val_loss: 7.0237 - val_accuracy: 0.0000e+00\n","Epoch 274/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0657 - accuracy: 0.1250\n","Epoch 274: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 3.1201 - accuracy: 0.1026 - val_loss: 7.0422 - val_accuracy: 0.0000e+00\n","Epoch 275/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9814 - accuracy: 0.0625\n","Epoch 275: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.0290 - accuracy: 0.0513 - val_loss: 7.0674 - val_accuracy: 0.0000e+00\n","Epoch 276/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9680 - accuracy: 0.1562\n","Epoch 276: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.9833 - accuracy: 0.1538 - val_loss: 7.1155 - val_accuracy: 0.0000e+00\n","Epoch 277/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0835 - accuracy: 0.1250\n","Epoch 277: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.1002 - accuracy: 0.1026 - val_loss: 7.1673 - val_accuracy: 0.0000e+00\n","Epoch 278/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0921 - accuracy: 0.0938\n","Epoch 278: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0612 - accuracy: 0.0769 - val_loss: 7.1918 - val_accuracy: 0.0000e+00\n","Epoch 279/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0034 - accuracy: 0.0625\n","Epoch 279: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0059 - accuracy: 0.0769 - val_loss: 7.2448 - val_accuracy: 0.0000e+00\n","Epoch 280/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0173 - accuracy: 0.0938\n","Epoch 280: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.0644 - accuracy: 0.0769 - val_loss: 7.2827 - val_accuracy: 0.0000e+00\n","Epoch 281/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0379 - accuracy: 0.0938\n","Epoch 281: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.0511 - accuracy: 0.1026 - val_loss: 7.2960 - val_accuracy: 0.0000e+00\n","Epoch 282/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9824 - accuracy: 0.1250\n","Epoch 282: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.9823 - accuracy: 0.1026 - val_loss: 7.0724 - val_accuracy: 0.0000e+00\n","Epoch 283/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9944 - accuracy: 0.0938\n","Epoch 283: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.9953 - accuracy: 0.1282 - val_loss: 7.0320 - val_accuracy: 0.0000e+00\n","Epoch 284/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0947 - accuracy: 0.0625\n","Epoch 284: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.0560 - accuracy: 0.0769 - val_loss: 7.0747 - val_accuracy: 0.0000e+00\n","Epoch 285/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9805 - accuracy: 0.0625\n","Epoch 285: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.0039 - accuracy: 0.0513 - val_loss: 7.2594 - val_accuracy: 0.0000e+00\n","Epoch 286/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1280 - accuracy: 0.0938\n","Epoch 286: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 3.1242 - accuracy: 0.0769 - val_loss: 7.3624 - val_accuracy: 0.0000e+00\n","Epoch 287/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9981 - accuracy: 0.1562\n","Epoch 287: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 3.0055 - accuracy: 0.1282 - val_loss: 7.3665 - val_accuracy: 0.0000e+00\n","Epoch 288/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9993 - accuracy: 0.0938\n","Epoch 288: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.9873 - accuracy: 0.1026 - val_loss: 7.3408 - val_accuracy: 0.0000e+00\n","Epoch 289/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1077 - accuracy: 0.0625\n","Epoch 289: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.0812 - accuracy: 0.1026 - val_loss: 7.3415 - val_accuracy: 0.0000e+00\n","Epoch 290/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0445 - accuracy: 0.0625\n","Epoch 290: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 3.0043 - accuracy: 0.0769 - val_loss: 7.3309 - val_accuracy: 0.0000e+00\n","Epoch 291/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1310 - accuracy: 0.1250\n","Epoch 291: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 3.0918 - accuracy: 0.1282 - val_loss: 7.2297 - val_accuracy: 0.0000e+00\n","Epoch 292/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9933 - accuracy: 0.0938\n","Epoch 292: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 2.9799 - accuracy: 0.0769 - val_loss: 7.2132 - val_accuracy: 0.0000e+00\n","Epoch 293/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1129 - accuracy: 0.0938\n","Epoch 293: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 3.0715 - accuracy: 0.1026 - val_loss: 7.2155 - val_accuracy: 0.0000e+00\n","Epoch 294/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1546 - accuracy: 0.0312\n","Epoch 294: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.1015 - accuracy: 0.0769 - val_loss: 7.2324 - val_accuracy: 0.0000e+00\n","Epoch 295/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0452 - accuracy: 0.0625\n","Epoch 295: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0565 - accuracy: 0.0513 - val_loss: 7.2702 - val_accuracy: 0.0000e+00\n","Epoch 296/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0091 - accuracy: 0.0938\n","Epoch 296: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.0036 - accuracy: 0.1026 - val_loss: 7.3315 - val_accuracy: 0.0000e+00\n","Epoch 297/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0583 - accuracy: 0.0938\n","Epoch 297: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.0240 - accuracy: 0.0769 - val_loss: 7.4123 - val_accuracy: 0.0000e+00\n","Epoch 298/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9747 - accuracy: 0.1250\n","Epoch 298: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.9887 - accuracy: 0.1026 - val_loss: 7.3790 - val_accuracy: 0.0000e+00\n","Epoch 299/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0182 - accuracy: 0.0312\n","Epoch 299: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.0350 - accuracy: 0.0256 - val_loss: 7.2494 - val_accuracy: 0.0000e+00\n","Epoch 300/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8884 - accuracy: 0.1562\n","Epoch 300: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.9115 - accuracy: 0.1282 - val_loss: 7.2504 - val_accuracy: 0.0000e+00\n","Epoch 301/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9844 - accuracy: 0.0938\n","Epoch 301: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.9826 - accuracy: 0.1026 - val_loss: 7.3087 - val_accuracy: 0.0000e+00\n","Epoch 302/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0900 - accuracy: 0.1250\n","Epoch 302: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.0649 - accuracy: 0.1026 - val_loss: 7.3145 - val_accuracy: 0.0000e+00\n","Epoch 303/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9823 - accuracy: 0.0625\n","Epoch 303: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.9907 - accuracy: 0.0769 - val_loss: 7.3383 - val_accuracy: 0.0000e+00\n","Epoch 304/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9975 - accuracy: 0.1250\n","Epoch 304: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.9767 - accuracy: 0.1282 - val_loss: 7.4118 - val_accuracy: 0.0000e+00\n","Epoch 305/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9400 - accuracy: 0.1250\n","Epoch 305: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 2.9221 - accuracy: 0.1026 - val_loss: 7.4639 - val_accuracy: 0.0000e+00\n","Epoch 306/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9952 - accuracy: 0.0938\n","Epoch 306: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.9739 - accuracy: 0.0769 - val_loss: 7.4731 - val_accuracy: 0.0000e+00\n","Epoch 307/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0057 - accuracy: 0.0938\n","Epoch 307: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0031 - accuracy: 0.0769 - val_loss: 7.5711 - val_accuracy: 0.0000e+00\n","Epoch 308/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9770 - accuracy: 0.0312\n","Epoch 308: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.0245 - accuracy: 0.0513 - val_loss: 7.4848 - val_accuracy: 0.0000e+00\n","Epoch 309/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0524 - accuracy: 0.0625\n","Epoch 309: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.0062 - accuracy: 0.0769 - val_loss: 7.4068 - val_accuracy: 0.0000e+00\n","Epoch 310/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0670 - accuracy: 0.0312\n","Epoch 310: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.0978 - accuracy: 0.0513 - val_loss: 7.4241 - val_accuracy: 0.0000e+00\n","Epoch 311/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9880 - accuracy: 0.0938\n","Epoch 311: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.9891 - accuracy: 0.0769 - val_loss: 7.6889 - val_accuracy: 0.0000e+00\n","Epoch 312/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0440 - accuracy: 0.0625\n","Epoch 312: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0349 - accuracy: 0.0769 - val_loss: 7.5669 - val_accuracy: 0.0000e+00\n","Epoch 313/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9019 - accuracy: 0.1250\n","Epoch 313: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.9485 - accuracy: 0.1026 - val_loss: 7.5471 - val_accuracy: 0.0000e+00\n","Epoch 314/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9672 - accuracy: 0.0625\n","Epoch 314: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.9851 - accuracy: 0.0769 - val_loss: 7.3551 - val_accuracy: 0.0000e+00\n","Epoch 315/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9919 - accuracy: 0.1250\n","Epoch 315: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 2.9962 - accuracy: 0.1282 - val_loss: 6.9862 - val_accuracy: 0.0000e+00\n","Epoch 316/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1371 - accuracy: 0.0938\n","Epoch 316: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 3.1438 - accuracy: 0.0769 - val_loss: 7.4806 - val_accuracy: 0.0000e+00\n","Epoch 317/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1057 - accuracy: 0.0938\n","Epoch 317: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.1393 - accuracy: 0.0769 - val_loss: 7.7720 - val_accuracy: 0.0000e+00\n","Epoch 318/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1037 - accuracy: 0.0312\n","Epoch 318: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.1017 - accuracy: 0.0256 - val_loss: 7.9105 - val_accuracy: 0.0000e+00\n","Epoch 319/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0072 - accuracy: 0.0938\n","Epoch 319: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.9960 - accuracy: 0.1026 - val_loss: 7.7106 - val_accuracy: 0.0000e+00\n","Epoch 320/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9386 - accuracy: 0.1250\n","Epoch 320: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.9765 - accuracy: 0.1026 - val_loss: 7.6315 - val_accuracy: 0.0000e+00\n","Epoch 321/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0378 - accuracy: 0.0938\n","Epoch 321: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.0434 - accuracy: 0.0769 - val_loss: 7.5743 - val_accuracy: 0.0000e+00\n","Epoch 322/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9971 - accuracy: 0.0938\n","Epoch 322: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.9663 - accuracy: 0.0769 - val_loss: 7.5042 - val_accuracy: 0.0000e+00\n","Epoch 323/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9870 - accuracy: 0.0625\n","Epoch 323: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 3.0163 - accuracy: 0.0769 - val_loss: 7.3841 - val_accuracy: 0.0000e+00\n","Epoch 324/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9970 - accuracy: 0.0625\n","Epoch 324: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.0016 - accuracy: 0.0513 - val_loss: 7.2532 - val_accuracy: 0.0000e+00\n","Epoch 325/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0907 - accuracy: 0.0625\n","Epoch 325: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0654 - accuracy: 0.0769 - val_loss: 7.4468 - val_accuracy: 0.0000e+00\n","Epoch 326/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0055 - accuracy: 0.0938\n","Epoch 326: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.9899 - accuracy: 0.1282 - val_loss: 7.5535 - val_accuracy: 0.0000e+00\n","Epoch 327/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9833 - accuracy: 0.0625\n","Epoch 327: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.9990 - accuracy: 0.0513 - val_loss: 7.5815 - val_accuracy: 0.0000e+00\n","Epoch 328/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9176 - accuracy: 0.0938\n","Epoch 328: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.9205 - accuracy: 0.1026 - val_loss: 7.5517 - val_accuracy: 0.0000e+00\n","Epoch 329/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9521 - accuracy: 0.0938\n","Epoch 329: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.9574 - accuracy: 0.1026 - val_loss: 7.6112 - val_accuracy: 0.0000e+00\n","Epoch 330/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0071 - accuracy: 0.1250\n","Epoch 330: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 3.0052 - accuracy: 0.1026 - val_loss: 7.6985 - val_accuracy: 0.0000e+00\n","Epoch 331/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0818 - accuracy: 0.0312\n","Epoch 331: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 3.0513 - accuracy: 0.0513 - val_loss: 7.7237 - val_accuracy: 0.0000e+00\n","Epoch 332/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9713 - accuracy: 0.1250\n","Epoch 332: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.9947 - accuracy: 0.1282 - val_loss: 7.6744 - val_accuracy: 0.0000e+00\n","Epoch 333/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9989 - accuracy: 0.1250\n","Epoch 333: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 3.0118 - accuracy: 0.1026 - val_loss: 7.6130 - val_accuracy: 0.0000e+00\n","Epoch 334/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8645 - accuracy: 0.1562\n","Epoch 334: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.8798 - accuracy: 0.1282 - val_loss: 7.5143 - val_accuracy: 0.0000e+00\n","Epoch 335/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9977 - accuracy: 0.1250\n","Epoch 335: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.0101 - accuracy: 0.1282 - val_loss: 7.2018 - val_accuracy: 0.0000e+00\n","Epoch 336/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9438 - accuracy: 0.1562\n","Epoch 336: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.9887 - accuracy: 0.1282 - val_loss: 7.6613 - val_accuracy: 0.0000e+00\n","Epoch 337/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9950 - accuracy: 0.0625\n","Epoch 337: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.9657 - accuracy: 0.0769 - val_loss: 8.1019 - val_accuracy: 0.0000e+00\n","Epoch 338/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2542 - accuracy: 0.0625\n","Epoch 338: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.2269 - accuracy: 0.0769 - val_loss: 7.5669 - val_accuracy: 0.0000e+00\n","Epoch 339/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4946 - accuracy: 0.1250\n","Epoch 339: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 3.4678 - accuracy: 0.1026 - val_loss: 7.5110 - val_accuracy: 0.0000e+00\n","Epoch 340/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2382 - accuracy: 0.0625\n","Epoch 340: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 3.3124 - accuracy: 0.0769 - val_loss: 7.8392 - val_accuracy: 0.0000e+00\n","Epoch 341/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4359 - accuracy: 0.0312\n","Epoch 341: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 3.3422 - accuracy: 0.0256 - val_loss: 8.1149 - val_accuracy: 0.0000e+00\n","Epoch 342/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1406 - accuracy: 0.0000e+00\n","Epoch 342: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 3.1010 - accuracy: 0.0513 - val_loss: 8.1057 - val_accuracy: 0.0000e+00\n","Epoch 343/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9986 - accuracy: 0.1250\n","Epoch 343: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.9800 - accuracy: 0.1026 - val_loss: 8.0752 - val_accuracy: 0.0000e+00\n","Epoch 344/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9872 - accuracy: 0.0625\n","Epoch 344: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 3.0132 - accuracy: 0.0513 - val_loss: 8.0434 - val_accuracy: 0.0000e+00\n","Epoch 345/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9124 - accuracy: 0.0938\n","Epoch 345: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.9540 - accuracy: 0.0769 - val_loss: 7.6746 - val_accuracy: 0.0000e+00\n","Epoch 346/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9810 - accuracy: 0.1250\n","Epoch 346: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.9153 - accuracy: 0.1282 - val_loss: 7.2832 - val_accuracy: 0.0000e+00\n","Epoch 347/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9338 - accuracy: 0.0312\n","Epoch 347: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.9523 - accuracy: 0.0256 - val_loss: 7.2248 - val_accuracy: 0.0000e+00\n","Epoch 348/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0168 - accuracy: 0.1250\n","Epoch 348: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.9974 - accuracy: 0.1282 - val_loss: 7.2856 - val_accuracy: 0.0000e+00\n","Epoch 349/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9002 - accuracy: 0.1562\n","Epoch 349: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.8929 - accuracy: 0.1538 - val_loss: 7.5016 - val_accuracy: 0.0000e+00\n","Epoch 350/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8953 - accuracy: 0.0312\n","Epoch 350: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.8929 - accuracy: 0.0769 - val_loss: 7.6856 - val_accuracy: 0.0000e+00\n","Epoch 351/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8696 - accuracy: 0.1250\n","Epoch 351: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.8893 - accuracy: 0.1026 - val_loss: 7.7646 - val_accuracy: 0.0000e+00\n","Epoch 352/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9642 - accuracy: 0.0625\n","Epoch 352: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.9898 - accuracy: 0.0513 - val_loss: 7.8481 - val_accuracy: 0.0000e+00\n","Epoch 353/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9703 - accuracy: 0.0625\n","Epoch 353: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.9486 - accuracy: 0.0769 - val_loss: 7.8734 - val_accuracy: 0.0000e+00\n","Epoch 354/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9638 - accuracy: 0.0625\n","Epoch 354: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.9530 - accuracy: 0.0513 - val_loss: 7.8367 - val_accuracy: 0.0000e+00\n","Epoch 355/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9800 - accuracy: 0.0000e+00\n","Epoch 355: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.9499 - accuracy: 0.0256 - val_loss: 7.8542 - val_accuracy: 0.0000e+00\n","Epoch 356/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9202 - accuracy: 0.0625\n","Epoch 356: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.9188 - accuracy: 0.0769 - val_loss: 7.9233 - val_accuracy: 0.0000e+00\n","Epoch 357/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8539 - accuracy: 0.0938\n","Epoch 357: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.8891 - accuracy: 0.1026 - val_loss: 8.1734 - val_accuracy: 0.0000e+00\n","Epoch 358/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9617 - accuracy: 0.0312\n","Epoch 358: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.9836 - accuracy: 0.0513 - val_loss: 8.2006 - val_accuracy: 0.0000e+00\n","Epoch 359/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8854 - accuracy: 0.0938\n","Epoch 359: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.9624 - accuracy: 0.0769 - val_loss: 8.2599 - val_accuracy: 0.0000e+00\n","Epoch 360/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9032 - accuracy: 0.1250\n","Epoch 360: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.9517 - accuracy: 0.1026 - val_loss: 7.7403 - val_accuracy: 0.0000e+00\n","Epoch 361/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0074 - accuracy: 0.1250\n","Epoch 361: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 3.0481 - accuracy: 0.1282 - val_loss: 7.8043 - val_accuracy: 0.0000e+00\n","Epoch 362/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8888 - accuracy: 0.0938\n","Epoch 362: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.8680 - accuracy: 0.1026 - val_loss: 8.2599 - val_accuracy: 0.0000e+00\n","Epoch 363/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9001 - accuracy: 0.0312\n","Epoch 363: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.9228 - accuracy: 0.0513 - val_loss: 8.1153 - val_accuracy: 0.0000e+00\n","Epoch 364/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1124 - accuracy: 0.0625\n","Epoch 364: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 3.1910 - accuracy: 0.0513 - val_loss: 8.1371 - val_accuracy: 0.0000e+00\n","Epoch 365/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1648 - accuracy: 0.0938\n","Epoch 365: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 3.1157 - accuracy: 0.0769 - val_loss: 8.2920 - val_accuracy: 0.0000e+00\n","Epoch 366/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8830 - accuracy: 0.1250\n","Epoch 366: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 2.8685 - accuracy: 0.1282 - val_loss: 7.8069 - val_accuracy: 0.0000e+00\n","Epoch 367/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9348 - accuracy: 0.1250\n","Epoch 367: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.9229 - accuracy: 0.1538 - val_loss: 7.8148 - val_accuracy: 0.0000e+00\n","Epoch 368/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8692 - accuracy: 0.1562\n","Epoch 368: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8894 - accuracy: 0.1282 - val_loss: 8.1052 - val_accuracy: 0.0000e+00\n","Epoch 369/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8882 - accuracy: 0.1250\n","Epoch 369: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 2.8784 - accuracy: 0.1026 - val_loss: 8.4465 - val_accuracy: 0.0000e+00\n","Epoch 370/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8730 - accuracy: 0.0625\n","Epoch 370: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8883 - accuracy: 0.0769 - val_loss: 8.4314 - val_accuracy: 0.0000e+00\n","Epoch 371/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9556 - accuracy: 0.0938\n","Epoch 371: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.9140 - accuracy: 0.0769 - val_loss: 8.4488 - val_accuracy: 0.0000e+00\n","Epoch 372/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8437 - accuracy: 0.1875\n","Epoch 372: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.8782 - accuracy: 0.1538 - val_loss: 8.5366 - val_accuracy: 0.0000e+00\n","Epoch 373/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7608 - accuracy: 0.2188\n","Epoch 373: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7836 - accuracy: 0.2051 - val_loss: 8.4058 - val_accuracy: 0.0000e+00\n","Epoch 374/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9796 - accuracy: 0.0625\n","Epoch 374: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 130ms/step - loss: 2.9331 - accuracy: 0.0769 - val_loss: 8.0111 - val_accuracy: 0.0000e+00\n","Epoch 375/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0233 - accuracy: 0.0938\n","Epoch 375: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.9793 - accuracy: 0.1026 - val_loss: 7.9493 - val_accuracy: 0.0000e+00\n","Epoch 376/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0057 - accuracy: 0.0312\n","Epoch 376: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.9912 - accuracy: 0.0513 - val_loss: 7.9494 - val_accuracy: 0.0000e+00\n","Epoch 377/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8914 - accuracy: 0.1250\n","Epoch 377: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.8847 - accuracy: 0.1282 - val_loss: 8.1573 - val_accuracy: 0.0000e+00\n","Epoch 378/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7788 - accuracy: 0.1875\n","Epoch 378: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.8128 - accuracy: 0.1538 - val_loss: 8.5601 - val_accuracy: 0.0000e+00\n","Epoch 379/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9291 - accuracy: 0.0938\n","Epoch 379: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.9535 - accuracy: 0.1026 - val_loss: 8.6245 - val_accuracy: 0.0000e+00\n","Epoch 380/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9467 - accuracy: 0.0938\n","Epoch 380: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 2.9194 - accuracy: 0.1282 - val_loss: 8.5979 - val_accuracy: 0.0000e+00\n","Epoch 381/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9481 - accuracy: 0.0938\n","Epoch 381: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.9448 - accuracy: 0.0769 - val_loss: 8.5711 - val_accuracy: 0.0000e+00\n","Epoch 382/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0187 - accuracy: 0.0625\n","Epoch 382: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 3.0004 - accuracy: 0.0769 - val_loss: 8.5543 - val_accuracy: 0.0000e+00\n","Epoch 383/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8636 - accuracy: 0.1250\n","Epoch 383: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8807 - accuracy: 0.1282 - val_loss: 8.3677 - val_accuracy: 0.0000e+00\n","Epoch 384/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7955 - accuracy: 0.1562\n","Epoch 384: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.8116 - accuracy: 0.1282 - val_loss: 8.2172 - val_accuracy: 0.0000e+00\n","Epoch 385/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8494 - accuracy: 0.1250\n","Epoch 385: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.8597 - accuracy: 0.1282 - val_loss: 8.1765 - val_accuracy: 0.0000e+00\n","Epoch 386/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9314 - accuracy: 0.0625\n","Epoch 386: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.8830 - accuracy: 0.0769 - val_loss: 8.4231 - val_accuracy: 0.0000e+00\n","Epoch 387/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8460 - accuracy: 0.2500\n","Epoch 387: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.8307 - accuracy: 0.2051 - val_loss: 8.5020 - val_accuracy: 0.0000e+00\n","Epoch 388/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8391 - accuracy: 0.0938\n","Epoch 388: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.8401 - accuracy: 0.1282 - val_loss: 8.5135 - val_accuracy: 0.0000e+00\n","Epoch 389/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7947 - accuracy: 0.1562\n","Epoch 389: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7909 - accuracy: 0.1282 - val_loss: 8.5437 - val_accuracy: 0.0000e+00\n","Epoch 390/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9363 - accuracy: 0.0000e+00\n","Epoch 390: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.9583 - accuracy: 0.0256 - val_loss: 8.5917 - val_accuracy: 0.0000e+00\n","Epoch 391/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9605 - accuracy: 0.0312\n","Epoch 391: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.9764 - accuracy: 0.0256 - val_loss: 8.6883 - val_accuracy: 0.0000e+00\n","Epoch 392/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9671 - accuracy: 0.0938\n","Epoch 392: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.9070 - accuracy: 0.1282 - val_loss: 8.6521 - val_accuracy: 0.0000e+00\n","Epoch 393/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8189 - accuracy: 0.1250\n","Epoch 393: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8269 - accuracy: 0.1282 - val_loss: 8.6566 - val_accuracy: 0.0000e+00\n","Epoch 394/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8476 - accuracy: 0.0625\n","Epoch 394: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.8184 - accuracy: 0.0769 - val_loss: 8.6603 - val_accuracy: 0.0000e+00\n","Epoch 395/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7773 - accuracy: 0.1250\n","Epoch 395: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.7815 - accuracy: 0.1538 - val_loss: 8.6610 - val_accuracy: 0.0000e+00\n","Epoch 396/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8919 - accuracy: 0.0312\n","Epoch 396: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.8913 - accuracy: 0.0256 - val_loss: 8.6409 - val_accuracy: 0.0000e+00\n","Epoch 397/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8366 - accuracy: 0.0625\n","Epoch 397: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.8299 - accuracy: 0.1026 - val_loss: 8.3968 - val_accuracy: 0.0000e+00\n","Epoch 398/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8472 - accuracy: 0.1562\n","Epoch 398: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.8748 - accuracy: 0.1282 - val_loss: 8.1791 - val_accuracy: 0.0000e+00\n","Epoch 399/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7849 - accuracy: 0.2812\n","Epoch 399: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7866 - accuracy: 0.2564 - val_loss: 8.0618 - val_accuracy: 0.0000e+00\n","Epoch 400/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8430 - accuracy: 0.0938\n","Epoch 400: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8721 - accuracy: 0.0769 - val_loss: 8.0378 - val_accuracy: 0.0000e+00\n","Epoch 401/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8141 - accuracy: 0.1562\n","Epoch 401: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.8144 - accuracy: 0.1538 - val_loss: 8.0482 - val_accuracy: 0.0000e+00\n","Epoch 402/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9586 - accuracy: 0.0625\n","Epoch 402: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.9123 - accuracy: 0.1026 - val_loss: 8.2001 - val_accuracy: 0.0000e+00\n","Epoch 403/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8453 - accuracy: 0.0938\n","Epoch 403: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8053 - accuracy: 0.1282 - val_loss: 8.4258 - val_accuracy: 0.0000e+00\n","Epoch 404/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8627 - accuracy: 0.1875\n","Epoch 404: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.8682 - accuracy: 0.1538 - val_loss: 8.4571 - val_accuracy: 0.0000e+00\n","Epoch 405/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9064 - accuracy: 0.0938\n","Epoch 405: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.9235 - accuracy: 0.0769 - val_loss: 8.4592 - val_accuracy: 0.0000e+00\n","Epoch 406/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9032 - accuracy: 0.0938\n","Epoch 406: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.8913 - accuracy: 0.1026 - val_loss: 8.4476 - val_accuracy: 0.0000e+00\n","Epoch 407/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7526 - accuracy: 0.0938\n","Epoch 407: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7777 - accuracy: 0.0769 - val_loss: 8.4820 - val_accuracy: 0.0000e+00\n","Epoch 408/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7946 - accuracy: 0.0938\n","Epoch 408: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.8138 - accuracy: 0.0769 - val_loss: 8.4950 - val_accuracy: 0.0000e+00\n","Epoch 409/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8534 - accuracy: 0.1250\n","Epoch 409: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.8379 - accuracy: 0.1538 - val_loss: 8.3935 - val_accuracy: 0.0000e+00\n","Epoch 410/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7419 - accuracy: 0.1562\n","Epoch 410: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7702 - accuracy: 0.1538 - val_loss: 8.1732 - val_accuracy: 0.0000e+00\n","Epoch 411/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8337 - accuracy: 0.0938\n","Epoch 411: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.8144 - accuracy: 0.0769 - val_loss: 8.2120 - val_accuracy: 0.0000e+00\n","Epoch 412/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8555 - accuracy: 0.1562\n","Epoch 412: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.8487 - accuracy: 0.1538 - val_loss: 8.2016 - val_accuracy: 0.0000e+00\n","Epoch 413/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8306 - accuracy: 0.0938\n","Epoch 413: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.8357 - accuracy: 0.0769 - val_loss: 8.4454 - val_accuracy: 0.0000e+00\n","Epoch 414/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7035 - accuracy: 0.1562\n","Epoch 414: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7713 - accuracy: 0.1538 - val_loss: 8.6329 - val_accuracy: 0.0000e+00\n","Epoch 415/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8522 - accuracy: 0.0938\n","Epoch 415: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.8651 - accuracy: 0.0769 - val_loss: 8.6925 - val_accuracy: 0.0000e+00\n","Epoch 416/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6958 - accuracy: 0.0938\n","Epoch 416: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.7456 - accuracy: 0.0769 - val_loss: 8.7427 - val_accuracy: 0.0000e+00\n","Epoch 417/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8494 - accuracy: 0.2188\n","Epoch 417: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.8153 - accuracy: 0.2051 - val_loss: 8.7994 - val_accuracy: 0.0000e+00\n","Epoch 418/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7199 - accuracy: 0.1562\n","Epoch 418: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7384 - accuracy: 0.1282 - val_loss: 8.8245 - val_accuracy: 0.0000e+00\n","Epoch 419/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8269 - accuracy: 0.1250\n","Epoch 419: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.8455 - accuracy: 0.1026 - val_loss: 8.8272 - val_accuracy: 0.0000e+00\n","Epoch 420/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8068 - accuracy: 0.0938\n","Epoch 420: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.8443 - accuracy: 0.1026 - val_loss: 8.8147 - val_accuracy: 0.0000e+00\n","Epoch 421/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8606 - accuracy: 0.0625\n","Epoch 421: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8187 - accuracy: 0.1026 - val_loss: 8.8016 - val_accuracy: 0.0000e+00\n","Epoch 422/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8093 - accuracy: 0.1250\n","Epoch 422: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8018 - accuracy: 0.1282 - val_loss: 8.7783 - val_accuracy: 0.0000e+00\n","Epoch 423/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7852 - accuracy: 0.1562\n","Epoch 423: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.7901 - accuracy: 0.1282 - val_loss: 8.7389 - val_accuracy: 0.0000e+00\n","Epoch 424/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8715 - accuracy: 0.0938\n","Epoch 424: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8642 - accuracy: 0.1026 - val_loss: 8.6729 - val_accuracy: 0.0000e+00\n","Epoch 425/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6823 - accuracy: 0.1562\n","Epoch 425: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7324 - accuracy: 0.1282 - val_loss: 8.6263 - val_accuracy: 0.0000e+00\n","Epoch 426/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8265 - accuracy: 0.0938\n","Epoch 426: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.7540 - accuracy: 0.1282 - val_loss: 8.6467 - val_accuracy: 0.0000e+00\n","Epoch 427/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7911 - accuracy: 0.0938\n","Epoch 427: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.8091 - accuracy: 0.0769 - val_loss: 8.6031 - val_accuracy: 0.0000e+00\n","Epoch 428/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8057 - accuracy: 0.0625\n","Epoch 428: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.7704 - accuracy: 0.1026 - val_loss: 8.5065 - val_accuracy: 0.0000e+00\n","Epoch 429/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7463 - accuracy: 0.1562\n","Epoch 429: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 105ms/step - loss: 2.7850 - accuracy: 0.1282 - val_loss: 8.4858 - val_accuracy: 0.0000e+00\n","Epoch 430/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7250 - accuracy: 0.0938\n","Epoch 430: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7717 - accuracy: 0.0769 - val_loss: 8.3888 - val_accuracy: 0.0000e+00\n","Epoch 431/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7595 - accuracy: 0.0625\n","Epoch 431: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7392 - accuracy: 0.1026 - val_loss: 8.3908 - val_accuracy: 0.0000e+00\n","Epoch 432/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9325 - accuracy: 0.0000e+00\n","Epoch 432: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.9438 - accuracy: 0.0000e+00 - val_loss: 8.4397 - val_accuracy: 0.0000e+00\n","Epoch 433/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7903 - accuracy: 0.0312\n","Epoch 433: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8194 - accuracy: 0.0513 - val_loss: 8.4382 - val_accuracy: 0.0000e+00\n","Epoch 434/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7378 - accuracy: 0.1875\n","Epoch 434: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7644 - accuracy: 0.1538 - val_loss: 8.4336 - val_accuracy: 0.0000e+00\n","Epoch 435/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8292 - accuracy: 0.0938\n","Epoch 435: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8384 - accuracy: 0.0769 - val_loss: 8.4585 - val_accuracy: 0.0000e+00\n","Epoch 436/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8302 - accuracy: 0.0938\n","Epoch 436: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7729 - accuracy: 0.1026 - val_loss: 8.5560 - val_accuracy: 0.0000e+00\n","Epoch 437/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6867 - accuracy: 0.1562\n","Epoch 437: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6934 - accuracy: 0.1282 - val_loss: 8.6270 - val_accuracy: 0.0000e+00\n","Epoch 438/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6804 - accuracy: 0.1875\n","Epoch 438: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6995 - accuracy: 0.2051 - val_loss: 8.6862 - val_accuracy: 0.0000e+00\n","Epoch 439/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7547 - accuracy: 0.0625\n","Epoch 439: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7975 - accuracy: 0.1026 - val_loss: 8.7850 - val_accuracy: 0.0000e+00\n","Epoch 440/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9293 - accuracy: 0.0312\n","Epoch 440: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.8855 - accuracy: 0.0256 - val_loss: 8.8462 - val_accuracy: 0.0000e+00\n","Epoch 441/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8966 - accuracy: 0.0312\n","Epoch 441: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.8056 - accuracy: 0.0513 - val_loss: 8.8885 - val_accuracy: 0.0000e+00\n","Epoch 442/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6425 - accuracy: 0.2188\n","Epoch 442: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.7102 - accuracy: 0.1795 - val_loss: 9.1413 - val_accuracy: 0.0000e+00\n","Epoch 443/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9523 - accuracy: 0.0312\n","Epoch 443: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.9236 - accuracy: 0.0256 - val_loss: 9.1844 - val_accuracy: 0.0000e+00\n","Epoch 444/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8714 - accuracy: 0.0938\n","Epoch 444: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.8736 - accuracy: 0.0769 - val_loss: 9.2685 - val_accuracy: 0.0000e+00\n","Epoch 445/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7917 - accuracy: 0.0625\n","Epoch 445: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.7983 - accuracy: 0.0769 - val_loss: 9.1706 - val_accuracy: 0.0000e+00\n","Epoch 446/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7372 - accuracy: 0.1250\n","Epoch 446: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.7662 - accuracy: 0.1026 - val_loss: 8.7789 - val_accuracy: 0.0000e+00\n","Epoch 447/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7622 - accuracy: 0.1562\n","Epoch 447: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7856 - accuracy: 0.1538 - val_loss: 8.6138 - val_accuracy: 0.0000e+00\n","Epoch 448/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6759 - accuracy: 0.2500\n","Epoch 448: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6938 - accuracy: 0.2051 - val_loss: 8.6261 - val_accuracy: 0.0000e+00\n","Epoch 449/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7812 - accuracy: 0.1250\n","Epoch 449: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.7854 - accuracy: 0.1026 - val_loss: 8.7848 - val_accuracy: 0.0000e+00\n","Epoch 450/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7140 - accuracy: 0.1562\n","Epoch 450: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.7572 - accuracy: 0.1538 - val_loss: 8.9246 - val_accuracy: 0.0000e+00\n","Epoch 451/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7537 - accuracy: 0.0312\n","Epoch 451: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7613 - accuracy: 0.0513 - val_loss: 8.9765 - val_accuracy: 0.0000e+00\n","Epoch 452/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7433 - accuracy: 0.1562\n","Epoch 452: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6908 - accuracy: 0.1538 - val_loss: 9.0045 - val_accuracy: 0.0000e+00\n","Epoch 453/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7098 - accuracy: 0.0938\n","Epoch 453: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7875 - accuracy: 0.0769 - val_loss: 9.0217 - val_accuracy: 0.0000e+00\n","Epoch 454/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7775 - accuracy: 0.1562\n","Epoch 454: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7742 - accuracy: 0.1538 - val_loss: 9.0329 - val_accuracy: 0.0000e+00\n","Epoch 455/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7777 - accuracy: 0.1250\n","Epoch 455: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.8041 - accuracy: 0.1026 - val_loss: 9.0166 - val_accuracy: 0.0000e+00\n","Epoch 456/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7844 - accuracy: 0.1562\n","Epoch 456: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7640 - accuracy: 0.1538 - val_loss: 8.9750 - val_accuracy: 0.0000e+00\n","Epoch 457/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7854 - accuracy: 0.0625\n","Epoch 457: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.7908 - accuracy: 0.0769 - val_loss: 8.9202 - val_accuracy: 0.0000e+00\n","Epoch 458/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6962 - accuracy: 0.1562\n","Epoch 458: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.7289 - accuracy: 0.1282 - val_loss: 8.8862 - val_accuracy: 0.0000e+00\n","Epoch 459/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8869 - accuracy: 0.1562\n","Epoch 459: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8651 - accuracy: 0.1282 - val_loss: 8.8373 - val_accuracy: 0.0000e+00\n","Epoch 460/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8977 - accuracy: 0.1562\n","Epoch 460: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.9155 - accuracy: 0.1538 - val_loss: 8.8348 - val_accuracy: 0.0000e+00\n","Epoch 461/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8297 - accuracy: 0.1250\n","Epoch 461: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7698 - accuracy: 0.1538 - val_loss: 8.9057 - val_accuracy: 0.0000e+00\n","Epoch 462/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8285 - accuracy: 0.1875\n","Epoch 462: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.8321 - accuracy: 0.2051 - val_loss: 8.9807 - val_accuracy: 0.0000e+00\n","Epoch 463/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7455 - accuracy: 0.1250\n","Epoch 463: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7007 - accuracy: 0.1538 - val_loss: 8.9641 - val_accuracy: 0.0000e+00\n","Epoch 464/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7124 - accuracy: 0.1562\n","Epoch 464: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7106 - accuracy: 0.1538 - val_loss: 8.9092 - val_accuracy: 0.0000e+00\n","Epoch 465/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7636 - accuracy: 0.0938\n","Epoch 465: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.7570 - accuracy: 0.1026 - val_loss: 8.8637 - val_accuracy: 0.0000e+00\n","Epoch 466/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6869 - accuracy: 0.2188\n","Epoch 466: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6693 - accuracy: 0.2051 - val_loss: 8.8885 - val_accuracy: 0.0000e+00\n","Epoch 467/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7504 - accuracy: 0.1250\n","Epoch 467: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7291 - accuracy: 0.1538 - val_loss: 8.9280 - val_accuracy: 0.0000e+00\n","Epoch 468/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7643 - accuracy: 0.0938\n","Epoch 468: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7651 - accuracy: 0.0769 - val_loss: 8.9330 - val_accuracy: 0.0000e+00\n","Epoch 469/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8133 - accuracy: 0.0625\n","Epoch 469: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.8066 - accuracy: 0.0769 - val_loss: 8.9742 - val_accuracy: 0.0000e+00\n","Epoch 470/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8491 - accuracy: 0.0625\n","Epoch 470: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.7868 - accuracy: 0.1026 - val_loss: 9.2443 - val_accuracy: 0.0000e+00\n","Epoch 471/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6703 - accuracy: 0.1562\n","Epoch 471: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.6949 - accuracy: 0.1282 - val_loss: 9.3130 - val_accuracy: 0.0000e+00\n","Epoch 472/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7718 - accuracy: 0.0312\n","Epoch 472: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7062 - accuracy: 0.0256 - val_loss: 9.2990 - val_accuracy: 0.0000e+00\n","Epoch 473/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6908 - accuracy: 0.1875\n","Epoch 473: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7300 - accuracy: 0.1538 - val_loss: 9.1511 - val_accuracy: 0.0000e+00\n","Epoch 474/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8211 - accuracy: 0.0938\n","Epoch 474: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7511 - accuracy: 0.0769 - val_loss: 8.9324 - val_accuracy: 0.0000e+00\n","Epoch 475/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7681 - accuracy: 0.0312\n","Epoch 475: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.8179 - accuracy: 0.0256 - val_loss: 8.9002 - val_accuracy: 0.0000e+00\n","Epoch 476/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9972 - accuracy: 0.0625\n","Epoch 476: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.9247 - accuracy: 0.0513 - val_loss: 8.8865 - val_accuracy: 0.0000e+00\n","Epoch 477/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8643 - accuracy: 0.0625\n","Epoch 477: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.7942 - accuracy: 0.0769 - val_loss: 8.9167 - val_accuracy: 0.0000e+00\n","Epoch 478/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6799 - accuracy: 0.0938\n","Epoch 478: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7446 - accuracy: 0.1026 - val_loss: 9.0618 - val_accuracy: 0.0000e+00\n","Epoch 479/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8185 - accuracy: 0.0938\n","Epoch 479: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7936 - accuracy: 0.1026 - val_loss: 9.1275 - val_accuracy: 0.0000e+00\n","Epoch 480/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7257 - accuracy: 0.0625\n","Epoch 480: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7268 - accuracy: 0.0769 - val_loss: 9.1316 - val_accuracy: 0.0000e+00\n","Epoch 481/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7141 - accuracy: 0.0938\n","Epoch 481: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7289 - accuracy: 0.1026 - val_loss: 9.1415 - val_accuracy: 0.0000e+00\n","Epoch 482/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9158 - accuracy: 0.0938\n","Epoch 482: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.8967 - accuracy: 0.1282 - val_loss: 9.1350 - val_accuracy: 0.0000e+00\n","Epoch 483/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7609 - accuracy: 0.0625\n","Epoch 483: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7716 - accuracy: 0.0513 - val_loss: 9.0079 - val_accuracy: 0.0000e+00\n","Epoch 484/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8316 - accuracy: 0.0312\n","Epoch 484: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.8048 - accuracy: 0.0513 - val_loss: 8.9461 - val_accuracy: 0.0000e+00\n","Epoch 485/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7584 - accuracy: 0.0625\n","Epoch 485: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7615 - accuracy: 0.1026 - val_loss: 8.8907 - val_accuracy: 0.0000e+00\n","Epoch 486/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7784 - accuracy: 0.0938\n","Epoch 486: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7524 - accuracy: 0.1026 - val_loss: 9.1498 - val_accuracy: 0.0000e+00\n","Epoch 487/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7501 - accuracy: 0.0938\n","Epoch 487: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7394 - accuracy: 0.1026 - val_loss: 9.2833 - val_accuracy: 0.0000e+00\n","Epoch 488/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8220 - accuracy: 0.0312\n","Epoch 488: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.8049 - accuracy: 0.0769 - val_loss: 9.2338 - val_accuracy: 0.0000e+00\n","Epoch 489/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7869 - accuracy: 0.0625\n","Epoch 489: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.7951 - accuracy: 0.0769 - val_loss: 9.4992 - val_accuracy: 0.0000e+00\n","Epoch 490/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7798 - accuracy: 0.1250\n","Epoch 490: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7554 - accuracy: 0.1282 - val_loss: 9.5783 - val_accuracy: 0.0000e+00\n","Epoch 491/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6478 - accuracy: 0.0938\n","Epoch 491: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6883 - accuracy: 0.1026 - val_loss: 9.5721 - val_accuracy: 0.0000e+00\n","Epoch 492/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5857 - accuracy: 0.2188\n","Epoch 492: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6090 - accuracy: 0.2051 - val_loss: 9.4655 - val_accuracy: 0.0000e+00\n","Epoch 493/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6943 - accuracy: 0.0938\n","Epoch 493: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7184 - accuracy: 0.1026 - val_loss: 9.1998 - val_accuracy: 0.0000e+00\n","Epoch 494/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6500 - accuracy: 0.1562\n","Epoch 494: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6679 - accuracy: 0.1538 - val_loss: 9.1599 - val_accuracy: 0.0000e+00\n","Epoch 495/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7963 - accuracy: 0.0312\n","Epoch 495: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.8140 - accuracy: 0.0256 - val_loss: 9.1771 - val_accuracy: 0.0000e+00\n","Epoch 496/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7148 - accuracy: 0.0625\n","Epoch 496: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.7623 - accuracy: 0.0513 - val_loss: 9.2233 - val_accuracy: 0.0000e+00\n","Epoch 497/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6445 - accuracy: 0.0938\n","Epoch 497: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6855 - accuracy: 0.1026 - val_loss: 9.2195 - val_accuracy: 0.0000e+00\n","Epoch 498/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6822 - accuracy: 0.1875\n","Epoch 498: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6695 - accuracy: 0.1538 - val_loss: 9.5927 - val_accuracy: 0.0000e+00\n","Epoch 499/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6447 - accuracy: 0.1562\n","Epoch 499: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6835 - accuracy: 0.1538 - val_loss: 9.6982 - val_accuracy: 0.0000e+00\n","Epoch 500/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6144 - accuracy: 0.1562\n","Epoch 500: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6892 - accuracy: 0.1282 - val_loss: 9.6363 - val_accuracy: 0.0000e+00\n","Epoch 501/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8195 - accuracy: 0.0625\n","Epoch 501: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7217 - accuracy: 0.0769 - val_loss: 9.7170 - val_accuracy: 0.0000e+00\n","Epoch 502/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7839 - accuracy: 0.0312\n","Epoch 502: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7270 - accuracy: 0.0513 - val_loss: 9.7258 - val_accuracy: 0.0000e+00\n","Epoch 503/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8279 - accuracy: 0.0312\n","Epoch 503: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7361 - accuracy: 0.0769 - val_loss: 9.6891 - val_accuracy: 0.0000e+00\n","Epoch 504/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8048 - accuracy: 0.0625\n","Epoch 504: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7910 - accuracy: 0.1026 - val_loss: 9.5412 - val_accuracy: 0.0000e+00\n","Epoch 505/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6898 - accuracy: 0.0938\n","Epoch 505: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6847 - accuracy: 0.1538 - val_loss: 9.4575 - val_accuracy: 0.0000e+00\n","Epoch 506/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7305 - accuracy: 0.0938\n","Epoch 506: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7100 - accuracy: 0.0769 - val_loss: 9.4027 - val_accuracy: 0.0000e+00\n","Epoch 507/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6300 - accuracy: 0.1250\n","Epoch 507: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.6160 - accuracy: 0.1538 - val_loss: 9.2876 - val_accuracy: 0.0000e+00\n","Epoch 508/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7296 - accuracy: 0.0625\n","Epoch 508: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6988 - accuracy: 0.0769 - val_loss: 9.2214 - val_accuracy: 0.0000e+00\n","Epoch 509/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6565 - accuracy: 0.0625\n","Epoch 509: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6533 - accuracy: 0.0769 - val_loss: 9.2598 - val_accuracy: 0.0000e+00\n","Epoch 510/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7487 - accuracy: 0.0312\n","Epoch 510: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.7271 - accuracy: 0.0513 - val_loss: 9.2578 - val_accuracy: 0.0000e+00\n","Epoch 511/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6249 - accuracy: 0.1562\n","Epoch 511: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6321 - accuracy: 0.1538 - val_loss: 9.2138 - val_accuracy: 0.0000e+00\n","Epoch 512/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7330 - accuracy: 0.0938\n","Epoch 512: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7924 - accuracy: 0.0769 - val_loss: 9.2554 - val_accuracy: 0.0000e+00\n","Epoch 513/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5836 - accuracy: 0.1875\n","Epoch 513: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6437 - accuracy: 0.1795 - val_loss: 9.3937 - val_accuracy: 0.0000e+00\n","Epoch 514/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7626 - accuracy: 0.0938\n","Epoch 514: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.7386 - accuracy: 0.1026 - val_loss: 9.4993 - val_accuracy: 0.0000e+00\n","Epoch 515/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7212 - accuracy: 0.1562\n","Epoch 515: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.7184 - accuracy: 0.1282 - val_loss: 9.5746 - val_accuracy: 0.0000e+00\n","Epoch 516/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7451 - accuracy: 0.0938\n","Epoch 516: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7368 - accuracy: 0.0769 - val_loss: 9.6410 - val_accuracy: 0.0000e+00\n","Epoch 517/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7130 - accuracy: 0.1562\n","Epoch 517: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6881 - accuracy: 0.1282 - val_loss: 9.6915 - val_accuracy: 0.0000e+00\n","Epoch 518/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7903 - accuracy: 0.0938\n","Epoch 518: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7343 - accuracy: 0.1282 - val_loss: 9.7369 - val_accuracy: 0.0000e+00\n","Epoch 519/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5576 - accuracy: 0.1562\n","Epoch 519: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6137 - accuracy: 0.1282 - val_loss: 9.7765 - val_accuracy: 0.0000e+00\n","Epoch 520/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5299 - accuracy: 0.1562\n","Epoch 520: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6069 - accuracy: 0.1282 - val_loss: 9.8066 - val_accuracy: 0.0000e+00\n","Epoch 521/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6442 - accuracy: 0.0938\n","Epoch 521: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.7062 - accuracy: 0.0769 - val_loss: 9.8322 - val_accuracy: 0.0000e+00\n","Epoch 522/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7473 - accuracy: 0.0938\n","Epoch 522: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7748 - accuracy: 0.1026 - val_loss: 9.8492 - val_accuracy: 0.0000e+00\n","Epoch 523/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6647 - accuracy: 0.0625\n","Epoch 523: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6475 - accuracy: 0.0769 - val_loss: 9.8567 - val_accuracy: 0.0000e+00\n","Epoch 524/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6895 - accuracy: 0.1250\n","Epoch 524: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6839 - accuracy: 0.1026 - val_loss: 9.8600 - val_accuracy: 0.0000e+00\n","Epoch 525/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7053 - accuracy: 0.0938\n","Epoch 525: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6709 - accuracy: 0.1026 - val_loss: 9.8508 - val_accuracy: 0.0000e+00\n","Epoch 526/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6951 - accuracy: 0.0312\n","Epoch 526: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6509 - accuracy: 0.0513 - val_loss: 9.8309 - val_accuracy: 0.0000e+00\n","Epoch 527/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6505 - accuracy: 0.1250\n","Epoch 527: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6648 - accuracy: 0.1282 - val_loss: 9.7906 - val_accuracy: 0.0000e+00\n","Epoch 528/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6534 - accuracy: 0.0938\n","Epoch 528: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6251 - accuracy: 0.1026 - val_loss: 9.7245 - val_accuracy: 0.0000e+00\n","Epoch 529/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7929 - accuracy: 0.1250\n","Epoch 529: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.7188 - accuracy: 0.1538 - val_loss: 9.6449 - val_accuracy: 0.0000e+00\n","Epoch 530/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7352 - accuracy: 0.0625\n","Epoch 530: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.7461 - accuracy: 0.0769 - val_loss: 9.5519 - val_accuracy: 0.0000e+00\n","Epoch 531/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7290 - accuracy: 0.1875\n","Epoch 531: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7310 - accuracy: 0.1538 - val_loss: 9.4936 - val_accuracy: 0.0000e+00\n","Epoch 532/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7441 - accuracy: 0.1562\n","Epoch 532: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.7558 - accuracy: 0.1282 - val_loss: 9.4557 - val_accuracy: 0.0000e+00\n","Epoch 533/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6930 - accuracy: 0.1250\n","Epoch 533: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7151 - accuracy: 0.1026 - val_loss: 9.4429 - val_accuracy: 0.0000e+00\n","Epoch 534/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5934 - accuracy: 0.0625\n","Epoch 534: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5789 - accuracy: 0.1026 - val_loss: 9.5448 - val_accuracy: 0.0000e+00\n","Epoch 535/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6953 - accuracy: 0.0938\n","Epoch 535: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6812 - accuracy: 0.1282 - val_loss: 9.6462 - val_accuracy: 0.0000e+00\n","Epoch 536/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7262 - accuracy: 0.0938\n","Epoch 536: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.7415 - accuracy: 0.0769 - val_loss: 9.6776 - val_accuracy: 0.0000e+00\n","Epoch 537/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6423 - accuracy: 0.2188\n","Epoch 537: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7017 - accuracy: 0.1795 - val_loss: 9.6804 - val_accuracy: 0.0000e+00\n","Epoch 538/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6013 - accuracy: 0.2188\n","Epoch 538: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6258 - accuracy: 0.2051 - val_loss: 9.6832 - val_accuracy: 0.0000e+00\n","Epoch 539/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6862 - accuracy: 0.1250\n","Epoch 539: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6920 - accuracy: 0.1538 - val_loss: 9.6867 - val_accuracy: 0.0000e+00\n","Epoch 540/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5866 - accuracy: 0.1250\n","Epoch 540: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6488 - accuracy: 0.1026 - val_loss: 9.6777 - val_accuracy: 0.0000e+00\n","Epoch 541/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6909 - accuracy: 0.0625\n","Epoch 541: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6612 - accuracy: 0.0769 - val_loss: 9.6598 - val_accuracy: 0.0000e+00\n","Epoch 542/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8282 - accuracy: 0.0625\n","Epoch 542: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7335 - accuracy: 0.1026 - val_loss: 9.6256 - val_accuracy: 0.0000e+00\n","Epoch 543/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7487 - accuracy: 0.0938\n","Epoch 543: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7311 - accuracy: 0.1026 - val_loss: 9.5870 - val_accuracy: 0.0000e+00\n","Epoch 544/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7150 - accuracy: 0.0938\n","Epoch 544: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6612 - accuracy: 0.1026 - val_loss: 9.5556 - val_accuracy: 0.0000e+00\n","Epoch 545/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5873 - accuracy: 0.1562\n","Epoch 545: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6104 - accuracy: 0.1538 - val_loss: 9.5171 - val_accuracy: 0.0000e+00\n","Epoch 546/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6435 - accuracy: 0.0625\n","Epoch 546: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6483 - accuracy: 0.1026 - val_loss: 9.4872 - val_accuracy: 0.0000e+00\n","Epoch 547/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7378 - accuracy: 0.0938\n","Epoch 547: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6964 - accuracy: 0.1026 - val_loss: 9.5499 - val_accuracy: 0.0000e+00\n","Epoch 548/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6446 - accuracy: 0.1562\n","Epoch 548: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6271 - accuracy: 0.1282 - val_loss: 9.7435 - val_accuracy: 0.0000e+00\n","Epoch 549/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5963 - accuracy: 0.1250\n","Epoch 549: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6254 - accuracy: 0.1282 - val_loss: 9.8495 - val_accuracy: 0.0000e+00\n","Epoch 550/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6569 - accuracy: 0.0938\n","Epoch 550: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6594 - accuracy: 0.0769 - val_loss: 9.8605 - val_accuracy: 0.0000e+00\n","Epoch 551/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6439 - accuracy: 0.1562\n","Epoch 551: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.6916 - accuracy: 0.1282 - val_loss: 9.8184 - val_accuracy: 0.0000e+00\n","Epoch 552/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6452 - accuracy: 0.1562\n","Epoch 552: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.6762 - accuracy: 0.1538 - val_loss: 9.8403 - val_accuracy: 0.0000e+00\n","Epoch 553/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7165 - accuracy: 0.0938\n","Epoch 553: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6601 - accuracy: 0.0769 - val_loss: 9.9365 - val_accuracy: 0.0000e+00\n","Epoch 554/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6367 - accuracy: 0.1562\n","Epoch 554: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6563 - accuracy: 0.1282 - val_loss: 9.9370 - val_accuracy: 0.0000e+00\n","Epoch 555/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6689 - accuracy: 0.1562\n","Epoch 555: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6320 - accuracy: 0.1538 - val_loss: 9.8684 - val_accuracy: 0.0000e+00\n","Epoch 556/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6412 - accuracy: 0.1562\n","Epoch 556: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6498 - accuracy: 0.1538 - val_loss: 9.8185 - val_accuracy: 0.0000e+00\n","Epoch 557/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6823 - accuracy: 0.0938\n","Epoch 557: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6488 - accuracy: 0.1026 - val_loss: 9.7386 - val_accuracy: 0.0000e+00\n","Epoch 558/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6866 - accuracy: 0.1250\n","Epoch 558: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6730 - accuracy: 0.1282 - val_loss: 9.6348 - val_accuracy: 0.0000e+00\n","Epoch 559/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6445 - accuracy: 0.0938\n","Epoch 559: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6642 - accuracy: 0.1026 - val_loss: 9.5426 - val_accuracy: 0.0000e+00\n","Epoch 560/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7242 - accuracy: 0.0625\n","Epoch 560: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7494 - accuracy: 0.0513 - val_loss: 9.7191 - val_accuracy: 0.0000e+00\n","Epoch 561/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5926 - accuracy: 0.1562\n","Epoch 561: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6475 - accuracy: 0.1282 - val_loss: 9.8953 - val_accuracy: 0.0000e+00\n","Epoch 562/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5744 - accuracy: 0.1875\n","Epoch 562: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.6165 - accuracy: 0.1538 - val_loss: 9.9256 - val_accuracy: 0.0000e+00\n","Epoch 563/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7701 - accuracy: 0.1250\n","Epoch 563: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.7145 - accuracy: 0.1538 - val_loss: 9.8898 - val_accuracy: 0.0000e+00\n","Epoch 564/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6256 - accuracy: 0.0938\n","Epoch 564: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6408 - accuracy: 0.1026 - val_loss: 9.8997 - val_accuracy: 0.0000e+00\n","Epoch 565/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5774 - accuracy: 0.1250\n","Epoch 565: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5975 - accuracy: 0.1026 - val_loss: 9.9397 - val_accuracy: 0.0000e+00\n","Epoch 566/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6375 - accuracy: 0.1562\n","Epoch 566: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.6393 - accuracy: 0.1538 - val_loss: 9.9400 - val_accuracy: 0.0000e+00\n","Epoch 567/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6658 - accuracy: 0.0938\n","Epoch 567: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.6850 - accuracy: 0.0769 - val_loss: 9.9108 - val_accuracy: 0.0000e+00\n","Epoch 568/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5168 - accuracy: 0.1562\n","Epoch 568: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5702 - accuracy: 0.1282 - val_loss: 9.8900 - val_accuracy: 0.0000e+00\n","Epoch 569/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8618 - accuracy: 0.0312\n","Epoch 569: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7999 - accuracy: 0.0769 - val_loss: 9.9140 - val_accuracy: 0.0000e+00\n","Epoch 570/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6776 - accuracy: 0.1875\n","Epoch 570: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6861 - accuracy: 0.1538 - val_loss: 9.9057 - val_accuracy: 0.0000e+00\n","Epoch 571/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6144 - accuracy: 0.0938\n","Epoch 571: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6531 - accuracy: 0.0769 - val_loss: 9.9497 - val_accuracy: 0.0000e+00\n","Epoch 572/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8789 - accuracy: 0.0312\n","Epoch 572: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7685 - accuracy: 0.0513 - val_loss: 9.9173 - val_accuracy: 0.0000e+00\n","Epoch 573/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7446 - accuracy: 0.0625\n","Epoch 573: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.7451 - accuracy: 0.0769 - val_loss: 9.8953 - val_accuracy: 0.0000e+00\n","Epoch 574/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6535 - accuracy: 0.1562\n","Epoch 574: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.6398 - accuracy: 0.1538 - val_loss: 9.9151 - val_accuracy: 0.0000e+00\n","Epoch 575/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7333 - accuracy: 0.0938\n","Epoch 575: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7475 - accuracy: 0.1026 - val_loss: 9.9520 - val_accuracy: 0.0000e+00\n","Epoch 576/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6360 - accuracy: 0.1562\n","Epoch 576: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6034 - accuracy: 0.1282 - val_loss: 10.1393 - val_accuracy: 0.0000e+00\n","Epoch 577/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6899 - accuracy: 0.0625\n","Epoch 577: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6219 - accuracy: 0.0513 - val_loss: 10.2209 - val_accuracy: 0.0000e+00\n","Epoch 578/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7292 - accuracy: 0.0625\n","Epoch 578: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.7809 - accuracy: 0.0513 - val_loss: 10.2210 - val_accuracy: 0.0000e+00\n","Epoch 579/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5686 - accuracy: 0.1562\n","Epoch 579: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5898 - accuracy: 0.1282 - val_loss: 9.9980 - val_accuracy: 0.0000e+00\n","Epoch 580/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7198 - accuracy: 0.0312\n","Epoch 580: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.7155 - accuracy: 0.0256 - val_loss: 9.9115 - val_accuracy: 0.0000e+00\n","Epoch 581/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6713 - accuracy: 0.1250\n","Epoch 581: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6720 - accuracy: 0.1282 - val_loss: 9.8991 - val_accuracy: 0.0000e+00\n","Epoch 582/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6896 - accuracy: 0.1250\n","Epoch 582: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6819 - accuracy: 0.1282 - val_loss: 10.0513 - val_accuracy: 0.0000e+00\n","Epoch 583/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6204 - accuracy: 0.0938\n","Epoch 583: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5807 - accuracy: 0.1538 - val_loss: 10.0478 - val_accuracy: 0.0000e+00\n","Epoch 584/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5662 - accuracy: 0.0625\n","Epoch 584: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6287 - accuracy: 0.0513 - val_loss: 10.0823 - val_accuracy: 0.0000e+00\n","Epoch 585/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7443 - accuracy: 0.0312\n","Epoch 585: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6637 - accuracy: 0.0513 - val_loss: 10.0606 - val_accuracy: 0.0000e+00\n","Epoch 586/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7842 - accuracy: 0.0938\n","Epoch 586: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7347 - accuracy: 0.1282 - val_loss: 10.0324 - val_accuracy: 0.0000e+00\n","Epoch 587/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5596 - accuracy: 0.2500\n","Epoch 587: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6162 - accuracy: 0.2051 - val_loss: 10.0220 - val_accuracy: 0.0000e+00\n","Epoch 588/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8128 - accuracy: 0.0625\n","Epoch 588: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.7587 - accuracy: 0.0769 - val_loss: 10.0293 - val_accuracy: 0.0000e+00\n","Epoch 589/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6324 - accuracy: 0.1250\n","Epoch 589: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 2.6655 - accuracy: 0.1282 - val_loss: 10.0815 - val_accuracy: 0.0000e+00\n","Epoch 590/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6719 - accuracy: 0.0312\n","Epoch 590: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.6743 - accuracy: 0.0256 - val_loss: 10.1016 - val_accuracy: 0.0000e+00\n","Epoch 591/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7082 - accuracy: 0.1250\n","Epoch 591: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.6745 - accuracy: 0.1282 - val_loss: 10.1189 - val_accuracy: 0.0000e+00\n","Epoch 592/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7529 - accuracy: 0.0625\n","Epoch 592: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7856 - accuracy: 0.0513 - val_loss: 10.1157 - val_accuracy: 0.0000e+00\n","Epoch 593/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6596 - accuracy: 0.1562\n","Epoch 593: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6746 - accuracy: 0.1538 - val_loss: 10.1005 - val_accuracy: 0.0000e+00\n","Epoch 594/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5284 - accuracy: 0.1250\n","Epoch 594: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5667 - accuracy: 0.1026 - val_loss: 10.0872 - val_accuracy: 0.0000e+00\n","Epoch 595/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6053 - accuracy: 0.0938\n","Epoch 595: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.6688 - accuracy: 0.1026 - val_loss: 10.0960 - val_accuracy: 0.0000e+00\n","Epoch 596/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7086 - accuracy: 0.0938\n","Epoch 596: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.7047 - accuracy: 0.1282 - val_loss: 10.1256 - val_accuracy: 0.0000e+00\n","Epoch 597/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6574 - accuracy: 0.0625\n","Epoch 597: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6545 - accuracy: 0.0513 - val_loss: 10.1492 - val_accuracy: 0.0000e+00\n","Epoch 598/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6184 - accuracy: 0.1875\n","Epoch 598: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6580 - accuracy: 0.2051 - val_loss: 10.1328 - val_accuracy: 0.0000e+00\n","Epoch 599/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6963 - accuracy: 0.0625\n","Epoch 599: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6697 - accuracy: 0.0513 - val_loss: 10.0578 - val_accuracy: 0.0000e+00\n","Epoch 600/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6873 - accuracy: 0.1562\n","Epoch 600: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6868 - accuracy: 0.1795 - val_loss: 9.9911 - val_accuracy: 0.0000e+00\n","Epoch 601/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6913 - accuracy: 0.1250\n","Epoch 601: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.7051 - accuracy: 0.1538 - val_loss: 9.9390 - val_accuracy: 0.0000e+00\n","Epoch 602/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5907 - accuracy: 0.1250\n","Epoch 602: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5745 - accuracy: 0.1538 - val_loss: 9.8925 - val_accuracy: 0.0000e+00\n","Epoch 603/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6249 - accuracy: 0.1562\n","Epoch 603: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6088 - accuracy: 0.1795 - val_loss: 9.9013 - val_accuracy: 0.0000e+00\n","Epoch 604/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6664 - accuracy: 0.1562\n","Epoch 604: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.6949 - accuracy: 0.1282 - val_loss: 9.9210 - val_accuracy: 0.0000e+00\n","Epoch 605/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6455 - accuracy: 0.0938\n","Epoch 605: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.6590 - accuracy: 0.0769 - val_loss: 10.0697 - val_accuracy: 0.0000e+00\n","Epoch 606/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7563 - accuracy: 0.1250\n","Epoch 606: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7100 - accuracy: 0.1538 - val_loss: 10.1144 - val_accuracy: 0.0000e+00\n","Epoch 607/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6134 - accuracy: 0.2812\n","Epoch 607: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6659 - accuracy: 0.2564 - val_loss: 10.1386 - val_accuracy: 0.0000e+00\n","Epoch 608/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5920 - accuracy: 0.0938\n","Epoch 608: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6172 - accuracy: 0.1026 - val_loss: 10.1413 - val_accuracy: 0.0000e+00\n","Epoch 609/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6823 - accuracy: 0.0312\n","Epoch 609: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6737 - accuracy: 0.0513 - val_loss: 10.1466 - val_accuracy: 0.0000e+00\n","Epoch 610/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7137 - accuracy: 0.1562\n","Epoch 610: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7336 - accuracy: 0.1538 - val_loss: 10.1514 - val_accuracy: 0.0000e+00\n","Epoch 611/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6312 - accuracy: 0.1875\n","Epoch 611: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6224 - accuracy: 0.2051 - val_loss: 10.1698 - val_accuracy: 0.0000e+00\n","Epoch 612/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5775 - accuracy: 0.1875\n","Epoch 612: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5932 - accuracy: 0.2051 - val_loss: 10.1991 - val_accuracy: 0.0000e+00\n","Epoch 613/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5859 - accuracy: 0.1250\n","Epoch 613: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6082 - accuracy: 0.1026 - val_loss: 10.2058 - val_accuracy: 0.0000e+00\n","Epoch 614/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6237 - accuracy: 0.1875\n","Epoch 614: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6691 - accuracy: 0.1538 - val_loss: 10.2294 - val_accuracy: 0.0000e+00\n","Epoch 615/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6540 - accuracy: 0.1250\n","Epoch 615: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6411 - accuracy: 0.1026 - val_loss: 10.2464 - val_accuracy: 0.0000e+00\n","Epoch 616/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6106 - accuracy: 0.0938\n","Epoch 616: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6317 - accuracy: 0.0769 - val_loss: 10.2033 - val_accuracy: 0.0000e+00\n","Epoch 617/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5551 - accuracy: 0.0625\n","Epoch 617: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6008 - accuracy: 0.0513 - val_loss: 10.0735 - val_accuracy: 0.0000e+00\n","Epoch 618/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6607 - accuracy: 0.2188\n","Epoch 618: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7126 - accuracy: 0.2051 - val_loss: 10.0787 - val_accuracy: 0.0000e+00\n","Epoch 619/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7183 - accuracy: 0.1250\n","Epoch 619: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.7211 - accuracy: 0.1026 - val_loss: 10.0925 - val_accuracy: 0.0000e+00\n","Epoch 620/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5590 - accuracy: 0.1875\n","Epoch 620: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6572 - accuracy: 0.1538 - val_loss: 10.1053 - val_accuracy: 0.0000e+00\n","Epoch 621/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6403 - accuracy: 0.0938\n","Epoch 621: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6434 - accuracy: 0.0769 - val_loss: 10.1220 - val_accuracy: 0.0000e+00\n","Epoch 622/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6056 - accuracy: 0.0938\n","Epoch 622: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6630 - accuracy: 0.1026 - val_loss: 10.1535 - val_accuracy: 0.0000e+00\n","Epoch 623/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6230 - accuracy: 0.1875\n","Epoch 623: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6402 - accuracy: 0.1795 - val_loss: 10.1242 - val_accuracy: 0.0000e+00\n","Epoch 624/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6587 - accuracy: 0.0938\n","Epoch 624: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7157 - accuracy: 0.0769 - val_loss: 10.0422 - val_accuracy: 0.0000e+00\n","Epoch 625/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5909 - accuracy: 0.1250\n","Epoch 625: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.5531 - accuracy: 0.1282 - val_loss: 10.0556 - val_accuracy: 0.0000e+00\n","Epoch 626/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7341 - accuracy: 0.0625\n","Epoch 626: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.7357 - accuracy: 0.0769 - val_loss: 10.0897 - val_accuracy: 0.0000e+00\n","Epoch 627/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8022 - accuracy: 0.0625\n","Epoch 627: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7598 - accuracy: 0.0769 - val_loss: 10.3549 - val_accuracy: 0.0000e+00\n","Epoch 628/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6678 - accuracy: 0.1250\n","Epoch 628: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6568 - accuracy: 0.1026 - val_loss: 10.2456 - val_accuracy: 0.0000e+00\n","Epoch 629/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7355 - accuracy: 0.0938\n","Epoch 629: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7568 - accuracy: 0.0769 - val_loss: 10.3238 - val_accuracy: 0.0000e+00\n","Epoch 630/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5523 - accuracy: 0.1562\n","Epoch 630: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.6014 - accuracy: 0.1282 - val_loss: 10.3268 - val_accuracy: 0.0000e+00\n","Epoch 631/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5733 - accuracy: 0.1562\n","Epoch 631: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.5505 - accuracy: 0.1538 - val_loss: 10.1204 - val_accuracy: 0.0000e+00\n","Epoch 632/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6533 - accuracy: 0.0938\n","Epoch 632: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6023 - accuracy: 0.1026 - val_loss: 10.1059 - val_accuracy: 0.0000e+00\n","Epoch 633/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7831 - accuracy: 0.0312\n","Epoch 633: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7855 - accuracy: 0.0256 - val_loss: 10.0588 - val_accuracy: 0.0000e+00\n","Epoch 634/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5756 - accuracy: 0.1875\n","Epoch 634: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6009 - accuracy: 0.1795 - val_loss: 10.3508 - val_accuracy: 0.0000e+00\n","Epoch 635/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6639 - accuracy: 0.0312\n","Epoch 635: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5845 - accuracy: 0.0513 - val_loss: 10.4475 - val_accuracy: 0.0000e+00\n","Epoch 636/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6065 - accuracy: 0.0938\n","Epoch 636: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6150 - accuracy: 0.1538 - val_loss: 10.4530 - val_accuracy: 0.0000e+00\n","Epoch 637/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6155 - accuracy: 0.2188\n","Epoch 637: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5996 - accuracy: 0.2308 - val_loss: 10.5075 - val_accuracy: 0.0000e+00\n","Epoch 638/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6058 - accuracy: 0.1562\n","Epoch 638: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5787 - accuracy: 0.1282 - val_loss: 10.7046 - val_accuracy: 0.0000e+00\n","Epoch 639/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6669 - accuracy: 0.1250\n","Epoch 639: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6596 - accuracy: 0.1282 - val_loss: 10.7541 - val_accuracy: 0.0000e+00\n","Epoch 640/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5743 - accuracy: 0.1250\n","Epoch 640: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5772 - accuracy: 0.1282 - val_loss: 10.7713 - val_accuracy: 0.0000e+00\n","Epoch 641/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6671 - accuracy: 0.1250\n","Epoch 641: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.7023 - accuracy: 0.1026 - val_loss: 10.6773 - val_accuracy: 0.0000e+00\n","Epoch 642/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6292 - accuracy: 0.2188\n","Epoch 642: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6698 - accuracy: 0.1795 - val_loss: 10.4941 - val_accuracy: 0.0000e+00\n","Epoch 643/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5966 - accuracy: 0.2188\n","Epoch 643: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6000 - accuracy: 0.2051 - val_loss: 10.3103 - val_accuracy: 0.0000e+00\n","Epoch 644/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6729 - accuracy: 0.0625\n","Epoch 644: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6722 - accuracy: 0.1026 - val_loss: 10.3132 - val_accuracy: 0.0000e+00\n","Epoch 645/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7154 - accuracy: 0.0625\n","Epoch 645: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.7446 - accuracy: 0.0513 - val_loss: 10.6248 - val_accuracy: 0.0000e+00\n","Epoch 646/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6217 - accuracy: 0.1562\n","Epoch 646: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6204 - accuracy: 0.1795 - val_loss: 10.7697 - val_accuracy: 0.0000e+00\n","Epoch 647/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6605 - accuracy: 0.1250\n","Epoch 647: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6648 - accuracy: 0.1538 - val_loss: 10.8043 - val_accuracy: 0.0000e+00\n","Epoch 648/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6014 - accuracy: 0.1562\n","Epoch 648: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5703 - accuracy: 0.1282 - val_loss: 10.8063 - val_accuracy: 0.0000e+00\n","Epoch 649/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5861 - accuracy: 0.1250\n","Epoch 649: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5956 - accuracy: 0.1026 - val_loss: 10.8081 - val_accuracy: 0.0000e+00\n","Epoch 650/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7115 - accuracy: 0.0625\n","Epoch 650: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6553 - accuracy: 0.0769 - val_loss: 10.7963 - val_accuracy: 0.0000e+00\n","Epoch 651/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5781 - accuracy: 0.1250\n","Epoch 651: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6181 - accuracy: 0.1282 - val_loss: 10.7857 - val_accuracy: 0.0000e+00\n","Epoch 652/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7002 - accuracy: 0.0938\n","Epoch 652: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6693 - accuracy: 0.1026 - val_loss: 10.7796 - val_accuracy: 0.0000e+00\n","Epoch 653/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5342 - accuracy: 0.1250\n","Epoch 653: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5849 - accuracy: 0.1026 - val_loss: 10.7774 - val_accuracy: 0.0000e+00\n","Epoch 654/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4910 - accuracy: 0.1250\n","Epoch 654: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5430 - accuracy: 0.1026 - val_loss: 10.7762 - val_accuracy: 0.0000e+00\n","Epoch 655/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5614 - accuracy: 0.1562\n","Epoch 655: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5591 - accuracy: 0.1282 - val_loss: 10.7621 - val_accuracy: 0.0000e+00\n","Epoch 656/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6355 - accuracy: 0.0625\n","Epoch 656: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6357 - accuracy: 0.0513 - val_loss: 10.7451 - val_accuracy: 0.0000e+00\n","Epoch 657/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6533 - accuracy: 0.1875\n","Epoch 657: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6738 - accuracy: 0.1795 - val_loss: 10.7321 - val_accuracy: 0.0000e+00\n","Epoch 658/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6288 - accuracy: 0.1250\n","Epoch 658: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.6419 - accuracy: 0.1538 - val_loss: 10.7179 - val_accuracy: 0.0000e+00\n","Epoch 659/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5513 - accuracy: 0.2812\n","Epoch 659: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5750 - accuracy: 0.2308 - val_loss: 10.7047 - val_accuracy: 0.0000e+00\n","Epoch 660/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5694 - accuracy: 0.0938\n","Epoch 660: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6546 - accuracy: 0.1026 - val_loss: 10.6962 - val_accuracy: 0.0000e+00\n","Epoch 661/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6175 - accuracy: 0.1250\n","Epoch 661: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5986 - accuracy: 0.1538 - val_loss: 10.6920 - val_accuracy: 0.0000e+00\n","Epoch 662/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6421 - accuracy: 0.2500\n","Epoch 662: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5605 - accuracy: 0.2564 - val_loss: 10.7079 - val_accuracy: 0.0000e+00\n","Epoch 663/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6883 - accuracy: 0.0938\n","Epoch 663: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6798 - accuracy: 0.1282 - val_loss: 10.7252 - val_accuracy: 0.0000e+00\n","Epoch 664/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5612 - accuracy: 0.1250\n","Epoch 664: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5957 - accuracy: 0.1282 - val_loss: 10.7343 - val_accuracy: 0.0000e+00\n","Epoch 665/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6073 - accuracy: 0.0938\n","Epoch 665: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5885 - accuracy: 0.0769 - val_loss: 10.7441 - val_accuracy: 0.0000e+00\n","Epoch 666/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6195 - accuracy: 0.1875\n","Epoch 666: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5971 - accuracy: 0.1538 - val_loss: 10.7536 - val_accuracy: 0.0000e+00\n","Epoch 667/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5613 - accuracy: 0.1562\n","Epoch 667: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6276 - accuracy: 0.1282 - val_loss: 10.7548 - val_accuracy: 0.0000e+00\n","Epoch 668/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6493 - accuracy: 0.1250\n","Epoch 668: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 2.6456 - accuracy: 0.1026 - val_loss: 10.7373 - val_accuracy: 0.0000e+00\n","Epoch 669/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6327 - accuracy: 0.1562\n","Epoch 669: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6725 - accuracy: 0.1538 - val_loss: 10.7073 - val_accuracy: 0.0000e+00\n","Epoch 670/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6019 - accuracy: 0.1562\n","Epoch 670: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5341 - accuracy: 0.1538 - val_loss: 10.6729 - val_accuracy: 0.0000e+00\n","Epoch 671/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4951 - accuracy: 0.1875\n","Epoch 671: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5304 - accuracy: 0.1538 - val_loss: 10.6581 - val_accuracy: 0.0000e+00\n","Epoch 672/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5699 - accuracy: 0.1562\n","Epoch 672: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5643 - accuracy: 0.1795 - val_loss: 10.6527 - val_accuracy: 0.0000e+00\n","Epoch 673/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6708 - accuracy: 0.1250\n","Epoch 673: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5764 - accuracy: 0.1282 - val_loss: 10.6545 - val_accuracy: 0.0000e+00\n","Epoch 674/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6834 - accuracy: 0.0938\n","Epoch 674: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6014 - accuracy: 0.1538 - val_loss: 10.6608 - val_accuracy: 0.0000e+00\n","Epoch 675/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4959 - accuracy: 0.1562\n","Epoch 675: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5648 - accuracy: 0.1795 - val_loss: 10.4035 - val_accuracy: 0.0000e+00\n","Epoch 676/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4810 - accuracy: 0.2188\n","Epoch 676: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4941 - accuracy: 0.1795 - val_loss: 10.3639 - val_accuracy: 0.0000e+00\n","Epoch 677/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6039 - accuracy: 0.2188\n","Epoch 677: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.5926 - accuracy: 0.1795 - val_loss: 10.3006 - val_accuracy: 0.0000e+00\n","Epoch 678/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6602 - accuracy: 0.1875\n","Epoch 678: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6676 - accuracy: 0.1795 - val_loss: 10.4612 - val_accuracy: 0.0000e+00\n","Epoch 679/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7017 - accuracy: 0.0000e+00\n","Epoch 679: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6399 - accuracy: 0.0513 - val_loss: 10.7021 - val_accuracy: 0.0000e+00\n","Epoch 680/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6813 - accuracy: 0.1250\n","Epoch 680: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6078 - accuracy: 0.1538 - val_loss: 10.7368 - val_accuracy: 0.0000e+00\n","Epoch 681/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6065 - accuracy: 0.2812\n","Epoch 681: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5352 - accuracy: 0.2564 - val_loss: 10.7429 - val_accuracy: 0.0000e+00\n","Epoch 682/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5431 - accuracy: 0.0938\n","Epoch 682: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6118 - accuracy: 0.1026 - val_loss: 10.7644 - val_accuracy: 0.0000e+00\n","Epoch 683/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5635 - accuracy: 0.1562\n","Epoch 683: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5729 - accuracy: 0.1538 - val_loss: 10.7960 - val_accuracy: 0.0000e+00\n","Epoch 684/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6153 - accuracy: 0.1250\n","Epoch 684: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 130ms/step - loss: 2.5884 - accuracy: 0.1282 - val_loss: 10.8227 - val_accuracy: 0.0000e+00\n","Epoch 685/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6840 - accuracy: 0.0625\n","Epoch 685: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.7122 - accuracy: 0.0513 - val_loss: 10.8450 - val_accuracy: 0.0000e+00\n","Epoch 686/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5804 - accuracy: 0.1562\n","Epoch 686: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5502 - accuracy: 0.1538 - val_loss: 10.8099 - val_accuracy: 0.0000e+00\n","Epoch 687/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5937 - accuracy: 0.1875\n","Epoch 687: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 2.5334 - accuracy: 0.1795 - val_loss: 10.7318 - val_accuracy: 0.0000e+00\n","Epoch 688/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6050 - accuracy: 0.0625\n","Epoch 688: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6042 - accuracy: 0.0769 - val_loss: 10.8223 - val_accuracy: 0.0000e+00\n","Epoch 689/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6023 - accuracy: 0.0625\n","Epoch 689: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5493 - accuracy: 0.0769 - val_loss: 10.8388 - val_accuracy: 0.0000e+00\n","Epoch 690/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6180 - accuracy: 0.1250\n","Epoch 690: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.5449 - accuracy: 0.1538 - val_loss: 10.8182 - val_accuracy: 0.0000e+00\n","Epoch 691/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6193 - accuracy: 0.1250\n","Epoch 691: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5778 - accuracy: 0.1282 - val_loss: 10.8189 - val_accuracy: 0.0000e+00\n","Epoch 692/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5966 - accuracy: 0.1875\n","Epoch 692: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6071 - accuracy: 0.1795 - val_loss: 10.8433 - val_accuracy: 0.0000e+00\n","Epoch 693/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7623 - accuracy: 0.0938\n","Epoch 693: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7280 - accuracy: 0.1026 - val_loss: 10.8909 - val_accuracy: 0.0000e+00\n","Epoch 694/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4758 - accuracy: 0.1875\n","Epoch 694: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5616 - accuracy: 0.1795 - val_loss: 10.9031 - val_accuracy: 0.0000e+00\n","Epoch 695/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5898 - accuracy: 0.1875\n","Epoch 695: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5775 - accuracy: 0.1795 - val_loss: 10.9077 - val_accuracy: 0.0000e+00\n","Epoch 696/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6557 - accuracy: 0.1562\n","Epoch 696: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7155 - accuracy: 0.1282 - val_loss: 10.8788 - val_accuracy: 0.0000e+00\n","Epoch 697/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6767 - accuracy: 0.1250\n","Epoch 697: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6350 - accuracy: 0.1538 - val_loss: 10.8366 - val_accuracy: 0.0000e+00\n","Epoch 698/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5729 - accuracy: 0.1250\n","Epoch 698: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5618 - accuracy: 0.1282 - val_loss: 10.8294 - val_accuracy: 0.0000e+00\n","Epoch 699/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6327 - accuracy: 0.1562\n","Epoch 699: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5862 - accuracy: 0.1795 - val_loss: 10.9074 - val_accuracy: 0.0000e+00\n","Epoch 700/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5974 - accuracy: 0.0625\n","Epoch 700: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 2.5529 - accuracy: 0.1026 - val_loss: 10.9799 - val_accuracy: 0.0000e+00\n","Epoch 701/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6211 - accuracy: 0.0938\n","Epoch 701: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6425 - accuracy: 0.1282 - val_loss: 10.9540 - val_accuracy: 0.0000e+00\n","Epoch 702/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5245 - accuracy: 0.2188\n","Epoch 702: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.6048 - accuracy: 0.1795 - val_loss: 10.8695 - val_accuracy: 0.0000e+00\n","Epoch 703/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5129 - accuracy: 0.1875\n","Epoch 703: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4910 - accuracy: 0.2051 - val_loss: 10.8998 - val_accuracy: 0.0000e+00\n","Epoch 704/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6279 - accuracy: 0.1250\n","Epoch 704: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5969 - accuracy: 0.1026 - val_loss: 10.8385 - val_accuracy: 0.0000e+00\n","Epoch 705/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4940 - accuracy: 0.0625\n","Epoch 705: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5562 - accuracy: 0.0513 - val_loss: 10.9613 - val_accuracy: 0.0000e+00\n","Epoch 706/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6300 - accuracy: 0.1250\n","Epoch 706: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6184 - accuracy: 0.1282 - val_loss: 11.0610 - val_accuracy: 0.0000e+00\n","Epoch 707/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5476 - accuracy: 0.0938\n","Epoch 707: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5945 - accuracy: 0.1026 - val_loss: 11.0902 - val_accuracy: 0.0000e+00\n","Epoch 708/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6128 - accuracy: 0.1250\n","Epoch 708: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5895 - accuracy: 0.1282 - val_loss: 11.0658 - val_accuracy: 0.0000e+00\n","Epoch 709/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5297 - accuracy: 0.0938\n","Epoch 709: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5520 - accuracy: 0.0769 - val_loss: 11.0314 - val_accuracy: 0.0000e+00\n","Epoch 710/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5725 - accuracy: 0.1250\n","Epoch 710: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6483 - accuracy: 0.1026 - val_loss: 11.0653 - val_accuracy: 0.0000e+00\n","Epoch 711/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6914 - accuracy: 0.0625\n","Epoch 711: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6574 - accuracy: 0.0769 - val_loss: 11.0972 - val_accuracy: 0.0000e+00\n","Epoch 712/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4782 - accuracy: 0.1875\n","Epoch 712: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5588 - accuracy: 0.1538 - val_loss: 11.0967 - val_accuracy: 0.0000e+00\n","Epoch 713/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5926 - accuracy: 0.1250\n","Epoch 713: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6359 - accuracy: 0.1282 - val_loss: 11.0653 - val_accuracy: 0.0000e+00\n","Epoch 714/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5456 - accuracy: 0.1250\n","Epoch 714: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.5624 - accuracy: 0.1538 - val_loss: 11.0409 - val_accuracy: 0.0000e+00\n","Epoch 715/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6477 - accuracy: 0.1250\n","Epoch 715: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6450 - accuracy: 0.1282 - val_loss: 10.9741 - val_accuracy: 0.0000e+00\n","Epoch 716/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5999 - accuracy: 0.2188\n","Epoch 716: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5120 - accuracy: 0.2308 - val_loss: 10.9072 - val_accuracy: 0.0000e+00\n","Epoch 717/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8190 - accuracy: 0.0938\n","Epoch 717: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.7475 - accuracy: 0.1282 - val_loss: 10.9655 - val_accuracy: 0.0000e+00\n","Epoch 718/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5852 - accuracy: 0.0938\n","Epoch 718: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5540 - accuracy: 0.1282 - val_loss: 10.9799 - val_accuracy: 0.0000e+00\n","Epoch 719/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6155 - accuracy: 0.0625\n","Epoch 719: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5558 - accuracy: 0.1026 - val_loss: 11.0264 - val_accuracy: 0.0000e+00\n","Epoch 720/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5365 - accuracy: 0.1562\n","Epoch 720: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5632 - accuracy: 0.2051 - val_loss: 11.0163 - val_accuracy: 0.0000e+00\n","Epoch 721/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7136 - accuracy: 0.0938\n","Epoch 721: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6387 - accuracy: 0.1282 - val_loss: 11.0269 - val_accuracy: 0.0000e+00\n","Epoch 722/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5448 - accuracy: 0.1875\n","Epoch 722: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.6102 - accuracy: 0.1538 - val_loss: 11.0882 - val_accuracy: 0.0000e+00\n","Epoch 723/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5721 - accuracy: 0.0312\n","Epoch 723: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5226 - accuracy: 0.0513 - val_loss: 11.1401 - val_accuracy: 0.0000e+00\n","Epoch 724/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5163 - accuracy: 0.1562\n","Epoch 724: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5194 - accuracy: 0.1538 - val_loss: 11.0899 - val_accuracy: 0.0000e+00\n","Epoch 725/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6522 - accuracy: 0.1562\n","Epoch 725: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6452 - accuracy: 0.1282 - val_loss: 11.0763 - val_accuracy: 0.0000e+00\n","Epoch 726/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5643 - accuracy: 0.0625\n","Epoch 726: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5426 - accuracy: 0.0769 - val_loss: 11.0545 - val_accuracy: 0.0000e+00\n","Epoch 727/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4756 - accuracy: 0.1250\n","Epoch 727: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4907 - accuracy: 0.1282 - val_loss: 11.0633 - val_accuracy: 0.0000e+00\n","Epoch 728/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5672 - accuracy: 0.0938\n","Epoch 728: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5761 - accuracy: 0.1026 - val_loss: 11.0932 - val_accuracy: 0.0000e+00\n","Epoch 729/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6116 - accuracy: 0.0625\n","Epoch 729: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6061 - accuracy: 0.0513 - val_loss: 11.2332 - val_accuracy: 0.0000e+00\n","Epoch 730/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4737 - accuracy: 0.2188\n","Epoch 730: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5133 - accuracy: 0.2308 - val_loss: 11.3693 - val_accuracy: 0.0000e+00\n","Epoch 731/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4447 - accuracy: 0.1875\n","Epoch 731: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4356 - accuracy: 0.1795 - val_loss: 11.4290 - val_accuracy: 0.0000e+00\n","Epoch 732/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6613 - accuracy: 0.0312\n","Epoch 732: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.7006 - accuracy: 0.0769 - val_loss: 11.4482 - val_accuracy: 0.0000e+00\n","Epoch 733/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6089 - accuracy: 0.0938\n","Epoch 733: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5983 - accuracy: 0.1282 - val_loss: 11.4490 - val_accuracy: 0.0000e+00\n","Epoch 734/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5972 - accuracy: 0.1875\n","Epoch 734: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5904 - accuracy: 0.1795 - val_loss: 11.4284 - val_accuracy: 0.0000e+00\n","Epoch 735/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5584 - accuracy: 0.1250\n","Epoch 735: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5598 - accuracy: 0.1026 - val_loss: 11.3677 - val_accuracy: 0.0000e+00\n","Epoch 736/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6616 - accuracy: 0.1562\n","Epoch 736: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.7038 - accuracy: 0.1282 - val_loss: 11.4276 - val_accuracy: 0.0000e+00\n","Epoch 737/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6277 - accuracy: 0.1562\n","Epoch 737: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6122 - accuracy: 0.1795 - val_loss: 11.4860 - val_accuracy: 0.0000e+00\n","Epoch 738/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6208 - accuracy: 0.1250\n","Epoch 738: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5563 - accuracy: 0.2051 - val_loss: 11.5244 - val_accuracy: 0.0000e+00\n","Epoch 739/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6151 - accuracy: 0.1250\n","Epoch 739: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5268 - accuracy: 0.1282 - val_loss: 11.5238 - val_accuracy: 0.0000e+00\n","Epoch 740/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5781 - accuracy: 0.2188\n","Epoch 740: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5922 - accuracy: 0.1795 - val_loss: 11.4903 - val_accuracy: 0.0000e+00\n","Epoch 741/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5717 - accuracy: 0.1562\n","Epoch 741: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6106 - accuracy: 0.1282 - val_loss: 11.4394 - val_accuracy: 0.0000e+00\n","Epoch 742/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5975 - accuracy: 0.1250\n","Epoch 742: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5700 - accuracy: 0.1282 - val_loss: 11.3426 - val_accuracy: 0.0000e+00\n","Epoch 743/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5161 - accuracy: 0.1875\n","Epoch 743: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5230 - accuracy: 0.1795 - val_loss: 11.2559 - val_accuracy: 0.0000e+00\n","Epoch 744/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5955 - accuracy: 0.2188\n","Epoch 744: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5522 - accuracy: 0.2308 - val_loss: 11.2854 - val_accuracy: 0.0000e+00\n","Epoch 745/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5226 - accuracy: 0.1562\n","Epoch 745: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4991 - accuracy: 0.2051 - val_loss: 11.2778 - val_accuracy: 0.0000e+00\n","Epoch 746/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4054 - accuracy: 0.2500\n","Epoch 746: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5116 - accuracy: 0.2051 - val_loss: 11.2707 - val_accuracy: 0.0000e+00\n","Epoch 747/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7582 - accuracy: 0.1250\n","Epoch 747: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7260 - accuracy: 0.1282 - val_loss: 11.2063 - val_accuracy: 0.0000e+00\n","Epoch 748/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5035 - accuracy: 0.0938\n","Epoch 748: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5077 - accuracy: 0.1026 - val_loss: 11.4028 - val_accuracy: 0.0000e+00\n","Epoch 749/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6044 - accuracy: 0.1250\n","Epoch 749: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5755 - accuracy: 0.1538 - val_loss: 11.4510 - val_accuracy: 0.0000e+00\n","Epoch 750/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5449 - accuracy: 0.1250\n","Epoch 750: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5805 - accuracy: 0.1282 - val_loss: 11.3927 - val_accuracy: 0.0000e+00\n","Epoch 751/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5726 - accuracy: 0.2188\n","Epoch 751: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5532 - accuracy: 0.2308 - val_loss: 11.3328 - val_accuracy: 0.0000e+00\n","Epoch 752/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7254 - accuracy: 0.0312\n","Epoch 752: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 130ms/step - loss: 2.6796 - accuracy: 0.1026 - val_loss: 11.3582 - val_accuracy: 0.0000e+00\n","Epoch 753/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5718 - accuracy: 0.1250\n","Epoch 753: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5758 - accuracy: 0.1538 - val_loss: 11.4320 - val_accuracy: 0.0000e+00\n","Epoch 754/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6550 - accuracy: 0.0938\n","Epoch 754: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6306 - accuracy: 0.1282 - val_loss: 11.4836 - val_accuracy: 0.0000e+00\n","Epoch 755/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5375 - accuracy: 0.1250\n","Epoch 755: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5397 - accuracy: 0.1282 - val_loss: 11.4989 - val_accuracy: 0.0000e+00\n","Epoch 756/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7027 - accuracy: 0.1562\n","Epoch 756: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.6519 - accuracy: 0.1538 - val_loss: 11.4799 - val_accuracy: 0.0000e+00\n","Epoch 757/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5448 - accuracy: 0.1562\n","Epoch 757: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.5596 - accuracy: 0.1282 - val_loss: 11.4356 - val_accuracy: 0.0000e+00\n","Epoch 758/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5927 - accuracy: 0.0938\n","Epoch 758: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5978 - accuracy: 0.0769 - val_loss: 11.3651 - val_accuracy: 0.0000e+00\n","Epoch 759/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5480 - accuracy: 0.1562\n","Epoch 759: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5320 - accuracy: 0.1538 - val_loss: 11.3377 - val_accuracy: 0.0000e+00\n","Epoch 760/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6535 - accuracy: 0.0938\n","Epoch 760: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5883 - accuracy: 0.1538 - val_loss: 11.3092 - val_accuracy: 0.0000e+00\n","Epoch 761/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5270 - accuracy: 0.2188\n","Epoch 761: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5714 - accuracy: 0.2051 - val_loss: 11.2854 - val_accuracy: 0.0000e+00\n","Epoch 762/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4656 - accuracy: 0.1250\n","Epoch 762: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4647 - accuracy: 0.1282 - val_loss: 11.2644 - val_accuracy: 0.0000e+00\n","Epoch 763/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5455 - accuracy: 0.2812\n","Epoch 763: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4982 - accuracy: 0.2308 - val_loss: 11.2529 - val_accuracy: 0.0000e+00\n","Epoch 764/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6049 - accuracy: 0.1875\n","Epoch 764: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6090 - accuracy: 0.2051 - val_loss: 11.2165 - val_accuracy: 0.0000e+00\n","Epoch 765/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3578 - accuracy: 0.2188\n","Epoch 765: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.4678 - accuracy: 0.2051 - val_loss: 11.2626 - val_accuracy: 0.0000e+00\n","Epoch 766/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4685 - accuracy: 0.1875\n","Epoch 766: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4295 - accuracy: 0.1795 - val_loss: 11.3872 - val_accuracy: 0.0000e+00\n","Epoch 767/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5351 - accuracy: 0.1562\n","Epoch 767: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5091 - accuracy: 0.1795 - val_loss: 11.5293 - val_accuracy: 0.0000e+00\n","Epoch 768/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5424 - accuracy: 0.1562\n","Epoch 768: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5828 - accuracy: 0.1795 - val_loss: 11.5514 - val_accuracy: 0.0000e+00\n","Epoch 769/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5849 - accuracy: 0.1875\n","Epoch 769: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 107ms/step - loss: 2.6649 - accuracy: 0.1538 - val_loss: 11.5546 - val_accuracy: 0.0000e+00\n","Epoch 770/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6483 - accuracy: 0.0312\n","Epoch 770: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.6646 - accuracy: 0.1026 - val_loss: 11.5698 - val_accuracy: 0.0000e+00\n","Epoch 771/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6047 - accuracy: 0.0938\n","Epoch 771: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.6224 - accuracy: 0.0769 - val_loss: 11.6548 - val_accuracy: 0.0000e+00\n","Epoch 772/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7159 - accuracy: 0.0625\n","Epoch 772: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.7893 - accuracy: 0.0513 - val_loss: 11.7138 - val_accuracy: 0.0000e+00\n","Epoch 773/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5612 - accuracy: 0.0938\n","Epoch 773: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5701 - accuracy: 0.0769 - val_loss: 11.7381 - val_accuracy: 0.0000e+00\n","Epoch 774/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6583 - accuracy: 0.1562\n","Epoch 774: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.6135 - accuracy: 0.1538 - val_loss: 11.7616 - val_accuracy: 0.0000e+00\n","Epoch 775/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5885 - accuracy: 0.1562\n","Epoch 775: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5822 - accuracy: 0.1282 - val_loss: 11.7839 - val_accuracy: 0.0000e+00\n","Epoch 776/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6726 - accuracy: 0.0312\n","Epoch 776: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6884 - accuracy: 0.0513 - val_loss: 11.7859 - val_accuracy: 0.0000e+00\n","Epoch 777/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5523 - accuracy: 0.1250\n","Epoch 777: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.6021 - accuracy: 0.1538 - val_loss: 11.7517 - val_accuracy: 0.0000e+00\n","Epoch 778/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4395 - accuracy: 0.1250\n","Epoch 778: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5349 - accuracy: 0.1026 - val_loss: 11.6660 - val_accuracy: 0.0000e+00\n","Epoch 779/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4579 - accuracy: 0.2188\n","Epoch 779: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4758 - accuracy: 0.2051 - val_loss: 11.6285 - val_accuracy: 0.0000e+00\n","Epoch 780/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5530 - accuracy: 0.0938\n","Epoch 780: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.5783 - accuracy: 0.1026 - val_loss: 11.5764 - val_accuracy: 0.0000e+00\n","Epoch 781/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5403 - accuracy: 0.1562\n","Epoch 781: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5334 - accuracy: 0.1282 - val_loss: 11.4749 - val_accuracy: 0.0000e+00\n","Epoch 782/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5476 - accuracy: 0.1250\n","Epoch 782: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5604 - accuracy: 0.1538 - val_loss: 11.3964 - val_accuracy: 0.0000e+00\n","Epoch 783/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5067 - accuracy: 0.2500\n","Epoch 783: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5145 - accuracy: 0.2308 - val_loss: 11.2437 - val_accuracy: 0.0000e+00\n","Epoch 784/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6282 - accuracy: 0.1875\n","Epoch 784: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 128ms/step - loss: 2.7030 - accuracy: 0.1538 - val_loss: 11.1971 - val_accuracy: 0.0000e+00\n","Epoch 785/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6500 - accuracy: 0.1250\n","Epoch 785: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.6516 - accuracy: 0.1282 - val_loss: 11.3004 - val_accuracy: 0.0000e+00\n","Epoch 786/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5851 - accuracy: 0.0938\n","Epoch 786: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5330 - accuracy: 0.1538 - val_loss: 11.0967 - val_accuracy: 0.0000e+00\n","Epoch 787/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4790 - accuracy: 0.2188\n","Epoch 787: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.4789 - accuracy: 0.1795 - val_loss: 10.9911 - val_accuracy: 0.0000e+00\n","Epoch 788/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4750 - accuracy: 0.1875\n","Epoch 788: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4679 - accuracy: 0.1795 - val_loss: 10.9904 - val_accuracy: 0.0000e+00\n","Epoch 789/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6095 - accuracy: 0.0938\n","Epoch 789: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5170 - accuracy: 0.1538 - val_loss: 10.9657 - val_accuracy: 0.0000e+00\n","Epoch 790/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5379 - accuracy: 0.1562\n","Epoch 790: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5739 - accuracy: 0.1538 - val_loss: 11.0095 - val_accuracy: 0.0000e+00\n","Epoch 791/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5712 - accuracy: 0.1562\n","Epoch 791: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6132 - accuracy: 0.1538 - val_loss: 11.0853 - val_accuracy: 0.0000e+00\n","Epoch 792/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5452 - accuracy: 0.1562\n","Epoch 792: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.5886 - accuracy: 0.1538 - val_loss: 11.2075 - val_accuracy: 0.0000e+00\n","Epoch 793/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6061 - accuracy: 0.0625\n","Epoch 793: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 2.5705 - accuracy: 0.0769 - val_loss: 11.2475 - val_accuracy: 0.0000e+00\n","Epoch 794/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5511 - accuracy: 0.1562\n","Epoch 794: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 2.6266 - accuracy: 0.1282 - val_loss: 11.2027 - val_accuracy: 0.0000e+00\n","Epoch 795/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5601 - accuracy: 0.1250\n","Epoch 795: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5724 - accuracy: 0.1282 - val_loss: 11.1062 - val_accuracy: 0.0000e+00\n","Epoch 796/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4683 - accuracy: 0.1250\n","Epoch 796: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 128ms/step - loss: 2.4761 - accuracy: 0.1026 - val_loss: 11.0974 - val_accuracy: 0.0000e+00\n","Epoch 797/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5349 - accuracy: 0.1250\n","Epoch 797: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5199 - accuracy: 0.1538 - val_loss: 11.0289 - val_accuracy: 0.0000e+00\n","Epoch 798/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6545 - accuracy: 0.1250\n","Epoch 798: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5855 - accuracy: 0.1538 - val_loss: 11.0463 - val_accuracy: 0.0000e+00\n","Epoch 799/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6634 - accuracy: 0.1250\n","Epoch 799: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.6492 - accuracy: 0.1282 - val_loss: 11.2422 - val_accuracy: 0.0000e+00\n","Epoch 800/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4582 - accuracy: 0.2500\n","Epoch 800: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5377 - accuracy: 0.2051 - val_loss: 11.3759 - val_accuracy: 0.0000e+00\n","Epoch 801/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6320 - accuracy: 0.2500\n","Epoch 801: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.6235 - accuracy: 0.2308 - val_loss: 11.5439 - val_accuracy: 0.0000e+00\n","Epoch 802/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4195 - accuracy: 0.1875\n","Epoch 802: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4924 - accuracy: 0.1538 - val_loss: 11.6389 - val_accuracy: 0.0000e+00\n","Epoch 803/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5343 - accuracy: 0.1562\n","Epoch 803: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.4662 - accuracy: 0.1282 - val_loss: 11.6837 - val_accuracy: 0.0000e+00\n","Epoch 804/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5624 - accuracy: 0.0938\n","Epoch 804: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 129ms/step - loss: 2.5242 - accuracy: 0.0769 - val_loss: 11.7129 - val_accuracy: 0.0000e+00\n","Epoch 805/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5824 - accuracy: 0.1562\n","Epoch 805: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.5775 - accuracy: 0.1282 - val_loss: 11.7106 - val_accuracy: 0.0000e+00\n","Epoch 806/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5698 - accuracy: 0.1562\n","Epoch 806: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5516 - accuracy: 0.1282 - val_loss: 11.6257 - val_accuracy: 0.0000e+00\n","Epoch 807/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6000 - accuracy: 0.1875\n","Epoch 807: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5532 - accuracy: 0.1795 - val_loss: 11.5497 - val_accuracy: 0.0000e+00\n","Epoch 808/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5243 - accuracy: 0.1875\n","Epoch 808: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5022 - accuracy: 0.1795 - val_loss: 11.5484 - val_accuracy: 0.0000e+00\n","Epoch 809/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4869 - accuracy: 0.1562\n","Epoch 809: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 129ms/step - loss: 2.4780 - accuracy: 0.1795 - val_loss: 11.5760 - val_accuracy: 0.0000e+00\n","Epoch 810/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6350 - accuracy: 0.1250\n","Epoch 810: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5065 - accuracy: 0.2051 - val_loss: 11.5599 - val_accuracy: 0.0000e+00\n","Epoch 811/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4823 - accuracy: 0.1250\n","Epoch 811: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 128ms/step - loss: 2.4503 - accuracy: 0.1538 - val_loss: 11.5415 - val_accuracy: 0.0000e+00\n","Epoch 812/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4653 - accuracy: 0.1250\n","Epoch 812: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.4974 - accuracy: 0.1538 - val_loss: 11.5449 - val_accuracy: 0.0000e+00\n","Epoch 813/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5267 - accuracy: 0.1875\n","Epoch 813: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4976 - accuracy: 0.1795 - val_loss: 11.5462 - val_accuracy: 0.0000e+00\n","Epoch 814/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6323 - accuracy: 0.1562\n","Epoch 814: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6114 - accuracy: 0.1282 - val_loss: 11.5447 - val_accuracy: 0.0000e+00\n","Epoch 815/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5190 - accuracy: 0.0312\n","Epoch 815: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5001 - accuracy: 0.0769 - val_loss: 11.5387 - val_accuracy: 0.0000e+00\n","Epoch 816/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6077 - accuracy: 0.1250\n","Epoch 816: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5834 - accuracy: 0.1538 - val_loss: 11.5318 - val_accuracy: 0.0000e+00\n","Epoch 817/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6154 - accuracy: 0.1562\n","Epoch 817: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6028 - accuracy: 0.1538 - val_loss: 11.5079 - val_accuracy: 0.0000e+00\n","Epoch 818/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4870 - accuracy: 0.0938\n","Epoch 818: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5210 - accuracy: 0.1026 - val_loss: 11.5088 - val_accuracy: 0.0000e+00\n","Epoch 819/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4755 - accuracy: 0.2188\n","Epoch 819: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5239 - accuracy: 0.1795 - val_loss: 11.5236 - val_accuracy: 0.0000e+00\n","Epoch 820/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4685 - accuracy: 0.1250\n","Epoch 820: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.4733 - accuracy: 0.1538 - val_loss: 11.5300 - val_accuracy: 0.0000e+00\n","Epoch 821/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5363 - accuracy: 0.1562\n","Epoch 821: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5461 - accuracy: 0.1538 - val_loss: 11.5212 - val_accuracy: 0.0000e+00\n","Epoch 822/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4551 - accuracy: 0.1250\n","Epoch 822: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4420 - accuracy: 0.1282 - val_loss: 11.5679 - val_accuracy: 0.0000e+00\n","Epoch 823/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4640 - accuracy: 0.2812\n","Epoch 823: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5374 - accuracy: 0.2308 - val_loss: 11.5552 - val_accuracy: 0.0000e+00\n","Epoch 824/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7531 - accuracy: 0.1250\n","Epoch 824: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.7344 - accuracy: 0.1282 - val_loss: 11.5231 - val_accuracy: 0.0000e+00\n","Epoch 825/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6062 - accuracy: 0.1875\n","Epoch 825: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5442 - accuracy: 0.1795 - val_loss: 11.4931 - val_accuracy: 0.0000e+00\n","Epoch 826/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5580 - accuracy: 0.2188\n","Epoch 826: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5705 - accuracy: 0.1795 - val_loss: 11.5399 - val_accuracy: 0.0000e+00\n","Epoch 827/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4162 - accuracy: 0.1875\n","Epoch 827: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4228 - accuracy: 0.1795 - val_loss: 11.5431 - val_accuracy: 0.0000e+00\n","Epoch 828/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4630 - accuracy: 0.0938\n","Epoch 828: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5083 - accuracy: 0.0769 - val_loss: 11.5572 - val_accuracy: 0.0000e+00\n","Epoch 829/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5461 - accuracy: 0.1562\n","Epoch 829: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5474 - accuracy: 0.1282 - val_loss: 11.5478 - val_accuracy: 0.0000e+00\n","Epoch 830/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4359 - accuracy: 0.1875\n","Epoch 830: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5253 - accuracy: 0.1795 - val_loss: 11.5515 - val_accuracy: 0.0000e+00\n","Epoch 831/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4964 - accuracy: 0.1562\n","Epoch 831: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5142 - accuracy: 0.1282 - val_loss: 11.6552 - val_accuracy: 0.0000e+00\n","Epoch 832/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5098 - accuracy: 0.0938\n","Epoch 832: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5481 - accuracy: 0.0769 - val_loss: 11.7797 - val_accuracy: 0.0000e+00\n","Epoch 833/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6274 - accuracy: 0.0625\n","Epoch 833: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6353 - accuracy: 0.0769 - val_loss: 11.8174 - val_accuracy: 0.0000e+00\n","Epoch 834/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4976 - accuracy: 0.1875\n","Epoch 834: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.4755 - accuracy: 0.1795 - val_loss: 11.8083 - val_accuracy: 0.0000e+00\n","Epoch 835/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5337 - accuracy: 0.1250\n","Epoch 835: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5228 - accuracy: 0.1026 - val_loss: 11.7805 - val_accuracy: 0.0000e+00\n","Epoch 836/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4340 - accuracy: 0.1875\n","Epoch 836: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4336 - accuracy: 0.2308 - val_loss: 11.7017 - val_accuracy: 0.0000e+00\n","Epoch 837/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4813 - accuracy: 0.0938\n","Epoch 837: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5191 - accuracy: 0.1026 - val_loss: 11.6085 - val_accuracy: 0.0000e+00\n","Epoch 838/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5049 - accuracy: 0.0625\n","Epoch 838: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.5180 - accuracy: 0.0513 - val_loss: 11.5507 - val_accuracy: 0.0000e+00\n","Epoch 839/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4665 - accuracy: 0.1875\n","Epoch 839: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4790 - accuracy: 0.1795 - val_loss: 11.5666 - val_accuracy: 0.0000e+00\n","Epoch 840/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5046 - accuracy: 0.1250\n","Epoch 840: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.4813 - accuracy: 0.1795 - val_loss: 11.5581 - val_accuracy: 0.0000e+00\n","Epoch 841/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4827 - accuracy: 0.1250\n","Epoch 841: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5449 - accuracy: 0.1282 - val_loss: 11.6249 - val_accuracy: 0.0000e+00\n","Epoch 842/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5791 - accuracy: 0.0625\n","Epoch 842: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6207 - accuracy: 0.0769 - val_loss: 11.6616 - val_accuracy: 0.0000e+00\n","Epoch 843/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6102 - accuracy: 0.0938\n","Epoch 843: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6018 - accuracy: 0.1026 - val_loss: 11.6395 - val_accuracy: 0.0000e+00\n","Epoch 844/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4245 - accuracy: 0.1250\n","Epoch 844: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4702 - accuracy: 0.1282 - val_loss: 11.5937 - val_accuracy: 0.0000e+00\n","Epoch 845/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3323 - accuracy: 0.0938\n","Epoch 845: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.3770 - accuracy: 0.1026 - val_loss: 11.5786 - val_accuracy: 0.0000e+00\n","Epoch 846/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4561 - accuracy: 0.1562\n","Epoch 846: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4788 - accuracy: 0.1538 - val_loss: 11.5718 - val_accuracy: 0.0000e+00\n","Epoch 847/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4155 - accuracy: 0.1250\n","Epoch 847: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4604 - accuracy: 0.1538 - val_loss: 11.5666 - val_accuracy: 0.0000e+00\n","Epoch 848/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5206 - accuracy: 0.1250\n","Epoch 848: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4869 - accuracy: 0.1282 - val_loss: 11.5649 - val_accuracy: 0.0000e+00\n","Epoch 849/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4216 - accuracy: 0.2500\n","Epoch 849: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4764 - accuracy: 0.2308 - val_loss: 11.5694 - val_accuracy: 0.0000e+00\n","Epoch 850/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5089 - accuracy: 0.1250\n","Epoch 850: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5021 - accuracy: 0.1538 - val_loss: 11.5845 - val_accuracy: 0.0000e+00\n","Epoch 851/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5609 - accuracy: 0.1562\n","Epoch 851: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5566 - accuracy: 0.1282 - val_loss: 11.6249 - val_accuracy: 0.0000e+00\n","Epoch 852/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5182 - accuracy: 0.1562\n","Epoch 852: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5080 - accuracy: 0.1538 - val_loss: 11.6428 - val_accuracy: 0.0000e+00\n","Epoch 853/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4794 - accuracy: 0.1562\n","Epoch 853: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.4849 - accuracy: 0.1538 - val_loss: 11.5853 - val_accuracy: 0.0000e+00\n","Epoch 854/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4515 - accuracy: 0.1250\n","Epoch 854: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4690 - accuracy: 0.1538 - val_loss: 11.5638 - val_accuracy: 0.0000e+00\n","Epoch 855/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5100 - accuracy: 0.1250\n","Epoch 855: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5356 - accuracy: 0.1026 - val_loss: 11.6273 - val_accuracy: 0.0000e+00\n","Epoch 856/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5117 - accuracy: 0.1562\n","Epoch 856: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4813 - accuracy: 0.1795 - val_loss: 11.6586 - val_accuracy: 0.0000e+00\n","Epoch 857/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5900 - accuracy: 0.0938\n","Epoch 857: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.5358 - accuracy: 0.1538 - val_loss: 11.6277 - val_accuracy: 0.0000e+00\n","Epoch 858/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5396 - accuracy: 0.1562\n","Epoch 858: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4958 - accuracy: 0.1282 - val_loss: 11.7127 - val_accuracy: 0.0000e+00\n","Epoch 859/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4902 - accuracy: 0.1562\n","Epoch 859: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4904 - accuracy: 0.1538 - val_loss: 11.8641 - val_accuracy: 0.0000e+00\n","Epoch 860/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5560 - accuracy: 0.1875\n","Epoch 860: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.5530 - accuracy: 0.1795 - val_loss: 11.9700 - val_accuracy: 0.0000e+00\n","Epoch 861/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6575 - accuracy: 0.2188\n","Epoch 861: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.6771 - accuracy: 0.2308 - val_loss: 12.0084 - val_accuracy: 0.0000e+00\n","Epoch 862/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5655 - accuracy: 0.0625\n","Epoch 862: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.5995 - accuracy: 0.0769 - val_loss: 12.0226 - val_accuracy: 0.0000e+00\n","Epoch 863/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5317 - accuracy: 0.1562\n","Epoch 863: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.6013 - accuracy: 0.1538 - val_loss: 12.0302 - val_accuracy: 0.0000e+00\n","Epoch 864/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4798 - accuracy: 0.1875\n","Epoch 864: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4996 - accuracy: 0.1538 - val_loss: 12.0305 - val_accuracy: 0.0000e+00\n","Epoch 865/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6176 - accuracy: 0.0625\n","Epoch 865: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 106ms/step - loss: 2.5659 - accuracy: 0.1026 - val_loss: 12.0056 - val_accuracy: 0.0000e+00\n","Epoch 866/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4618 - accuracy: 0.0625\n","Epoch 866: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4588 - accuracy: 0.1026 - val_loss: 11.9371 - val_accuracy: 0.0000e+00\n","Epoch 867/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4736 - accuracy: 0.2500\n","Epoch 867: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5068 - accuracy: 0.2564 - val_loss: 11.8304 - val_accuracy: 0.0000e+00\n","Epoch 868/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5477 - accuracy: 0.1562\n","Epoch 868: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4896 - accuracy: 0.2051 - val_loss: 11.8076 - val_accuracy: 0.0000e+00\n","Epoch 869/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5166 - accuracy: 0.0938\n","Epoch 869: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5122 - accuracy: 0.1026 - val_loss: 11.8286 - val_accuracy: 0.0000e+00\n","Epoch 870/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4347 - accuracy: 0.1250\n","Epoch 870: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.4875 - accuracy: 0.1282 - val_loss: 11.8409 - val_accuracy: 0.0000e+00\n","Epoch 871/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6945 - accuracy: 0.1562\n","Epoch 871: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.6318 - accuracy: 0.1795 - val_loss: 11.8751 - val_accuracy: 0.0000e+00\n","Epoch 872/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4979 - accuracy: 0.2500\n","Epoch 872: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.5029 - accuracy: 0.2051 - val_loss: 11.9280 - val_accuracy: 0.0000e+00\n","Epoch 873/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4438 - accuracy: 0.1562\n","Epoch 873: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4063 - accuracy: 0.1795 - val_loss: 11.9140 - val_accuracy: 0.0000e+00\n","Epoch 874/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5141 - accuracy: 0.1875\n","Epoch 874: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.5166 - accuracy: 0.1538 - val_loss: 11.9241 - val_accuracy: 0.0000e+00\n","Epoch 875/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6381 - accuracy: 0.0938\n","Epoch 875: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.6037 - accuracy: 0.0769 - val_loss: 11.9146 - val_accuracy: 0.0000e+00\n","Epoch 876/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4539 - accuracy: 0.1250\n","Epoch 876: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.4660 - accuracy: 0.1026 - val_loss: 11.8781 - val_accuracy: 0.0000e+00\n","Epoch 877/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4651 - accuracy: 0.1875\n","Epoch 877: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.4584 - accuracy: 0.1538 - val_loss: 11.8808 - val_accuracy: 0.0000e+00\n","Epoch 878/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4238 - accuracy: 0.1250\n","Epoch 878: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.4266 - accuracy: 0.1282 - val_loss: 11.9466 - val_accuracy: 0.0000e+00\n","Epoch 879/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5595 - accuracy: 0.1562\n","Epoch 879: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 109ms/step - loss: 2.5938 - accuracy: 0.1282 - val_loss: 11.9011 - val_accuracy: 0.0000e+00\n","Epoch 880/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4458 - accuracy: 0.1250\n","Epoch 880: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4481 - accuracy: 0.1795 - val_loss: 11.9104 - val_accuracy: 0.0000e+00\n","Epoch 881/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4744 - accuracy: 0.2812\n","Epoch 881: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 131ms/step - loss: 2.5289 - accuracy: 0.2564 - val_loss: 11.8790 - val_accuracy: 0.0000e+00\n","Epoch 882/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5832 - accuracy: 0.0938\n","Epoch 882: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 133ms/step - loss: 2.5971 - accuracy: 0.0769 - val_loss: 11.9191 - val_accuracy: 0.0000e+00\n","Epoch 883/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5179 - accuracy: 0.1562\n","Epoch 883: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 132ms/step - loss: 2.5177 - accuracy: 0.1795 - val_loss: 12.0989 - val_accuracy: 0.0000e+00\n","Epoch 884/1000\n","2/2 [==============================] - ETA: 0s - loss: 2.5670 - accuracy: 0.2051\n","Epoch 884: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 152ms/step - loss: 2.5670 - accuracy: 0.2051 - val_loss: 12.1728 - val_accuracy: 0.0000e+00\n","Epoch 885/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5782 - accuracy: 0.2188\n","Epoch 885: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5588 - accuracy: 0.1795 - val_loss: 12.2218 - val_accuracy: 0.0000e+00\n","Epoch 886/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5555 - accuracy: 0.0938\n","Epoch 886: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5776 - accuracy: 0.1026 - val_loss: 12.1434 - val_accuracy: 0.0000e+00\n","Epoch 887/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4745 - accuracy: 0.2500\n","Epoch 887: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 128ms/step - loss: 2.5045 - accuracy: 0.2308 - val_loss: 11.9184 - val_accuracy: 0.0000e+00\n","Epoch 888/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4475 - accuracy: 0.1250\n","Epoch 888: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.4483 - accuracy: 0.1026 - val_loss: 11.9340 - val_accuracy: 0.0000e+00\n","Epoch 889/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5331 - accuracy: 0.0625\n","Epoch 889: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5578 - accuracy: 0.0513 - val_loss: 11.8522 - val_accuracy: 0.0000e+00\n","Epoch 890/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4818 - accuracy: 0.1250\n","Epoch 890: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5173 - accuracy: 0.1026 - val_loss: 11.7827 - val_accuracy: 0.0000e+00\n","Epoch 891/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5168 - accuracy: 0.1562\n","Epoch 891: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.5116 - accuracy: 0.1538 - val_loss: 11.8595 - val_accuracy: 0.0000e+00\n","Epoch 892/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4486 - accuracy: 0.1875\n","Epoch 892: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4516 - accuracy: 0.1795 - val_loss: 11.8343 - val_accuracy: 0.0000e+00\n","Epoch 893/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5191 - accuracy: 0.1250\n","Epoch 893: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4693 - accuracy: 0.1026 - val_loss: 12.1018 - val_accuracy: 0.0000e+00\n","Epoch 894/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5458 - accuracy: 0.2500\n","Epoch 894: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5626 - accuracy: 0.2051 - val_loss: 12.1427 - val_accuracy: 0.0000e+00\n","Epoch 895/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5196 - accuracy: 0.1250\n","Epoch 895: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5166 - accuracy: 0.1026 - val_loss: 12.0237 - val_accuracy: 0.0000e+00\n","Epoch 896/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7348 - accuracy: 0.0938\n","Epoch 896: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.7458 - accuracy: 0.0769 - val_loss: 12.1877 - val_accuracy: 0.0000e+00\n","Epoch 897/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5268 - accuracy: 0.1875\n","Epoch 897: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5897 - accuracy: 0.1538 - val_loss: 12.2618 - val_accuracy: 0.0000e+00\n","Epoch 898/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6100 - accuracy: 0.0625\n","Epoch 898: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.5613 - accuracy: 0.0769 - val_loss: 12.0782 - val_accuracy: 0.0000e+00\n","Epoch 899/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6459 - accuracy: 0.1250\n","Epoch 899: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.6012 - accuracy: 0.1538 - val_loss: 12.0699 - val_accuracy: 0.0000e+00\n","Epoch 900/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5890 - accuracy: 0.1250\n","Epoch 900: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5018 - accuracy: 0.1795 - val_loss: 12.0339 - val_accuracy: 0.0000e+00\n","Epoch 901/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4697 - accuracy: 0.2188\n","Epoch 901: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4983 - accuracy: 0.1795 - val_loss: 12.0766 - val_accuracy: 0.0000e+00\n","Epoch 902/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3883 - accuracy: 0.1562\n","Epoch 902: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4340 - accuracy: 0.1538 - val_loss: 12.0557 - val_accuracy: 0.0000e+00\n","Epoch 903/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5070 - accuracy: 0.1250\n","Epoch 903: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4538 - accuracy: 0.1282 - val_loss: 12.1244 - val_accuracy: 0.0000e+00\n","Epoch 904/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4952 - accuracy: 0.1250\n","Epoch 904: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.4774 - accuracy: 0.1795 - val_loss: 11.9617 - val_accuracy: 0.0000e+00\n","Epoch 905/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6209 - accuracy: 0.1250\n","Epoch 905: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.5428 - accuracy: 0.1795 - val_loss: 11.7921 - val_accuracy: 0.0000e+00\n","Epoch 906/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6097 - accuracy: 0.1875\n","Epoch 906: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5981 - accuracy: 0.1795 - val_loss: 11.9554 - val_accuracy: 0.0000e+00\n","Epoch 907/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5029 - accuracy: 0.1562\n","Epoch 907: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5157 - accuracy: 0.1538 - val_loss: 12.2661 - val_accuracy: 0.0000e+00\n","Epoch 908/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5055 - accuracy: 0.1562\n","Epoch 908: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 2.5298 - accuracy: 0.1538 - val_loss: 12.1050 - val_accuracy: 0.0000e+00\n","Epoch 909/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4314 - accuracy: 0.1250\n","Epoch 909: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4701 - accuracy: 0.1538 - val_loss: 12.1056 - val_accuracy: 0.0000e+00\n","Epoch 910/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3893 - accuracy: 0.1250\n","Epoch 910: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.3823 - accuracy: 0.1282 - val_loss: 11.9837 - val_accuracy: 0.0000e+00\n","Epoch 911/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4721 - accuracy: 0.1875\n","Epoch 911: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5585 - accuracy: 0.1538 - val_loss: 11.8401 - val_accuracy: 0.0000e+00\n","Epoch 912/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5237 - accuracy: 0.1875\n","Epoch 912: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5435 - accuracy: 0.1795 - val_loss: 11.7780 - val_accuracy: 0.0000e+00\n","Epoch 913/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4388 - accuracy: 0.2500\n","Epoch 913: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4280 - accuracy: 0.2308 - val_loss: 11.6817 - val_accuracy: 0.0000e+00\n","Epoch 914/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5183 - accuracy: 0.1562\n","Epoch 914: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5056 - accuracy: 0.1538 - val_loss: 11.7069 - val_accuracy: 0.0000e+00\n","Epoch 915/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6641 - accuracy: 0.1562\n","Epoch 915: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.5750 - accuracy: 0.2308 - val_loss: 11.6811 - val_accuracy: 0.0000e+00\n","Epoch 916/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4953 - accuracy: 0.1250\n","Epoch 916: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.5325 - accuracy: 0.1538 - val_loss: 11.6884 - val_accuracy: 0.0000e+00\n","Epoch 917/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4108 - accuracy: 0.1875\n","Epoch 917: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4406 - accuracy: 0.2051 - val_loss: 11.8287 - val_accuracy: 0.0000e+00\n","Epoch 918/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4225 - accuracy: 0.1875\n","Epoch 918: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4253 - accuracy: 0.1795 - val_loss: 11.8912 - val_accuracy: 0.0000e+00\n","Epoch 919/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4347 - accuracy: 0.1562\n","Epoch 919: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4531 - accuracy: 0.1538 - val_loss: 11.8976 - val_accuracy: 0.0000e+00\n","Epoch 920/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4762 - accuracy: 0.0938\n","Epoch 920: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4871 - accuracy: 0.1282 - val_loss: 11.8532 - val_accuracy: 0.0000e+00\n","Epoch 921/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5274 - accuracy: 0.1875\n","Epoch 921: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5162 - accuracy: 0.1795 - val_loss: 11.8889 - val_accuracy: 0.0000e+00\n","Epoch 922/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4099 - accuracy: 0.1875\n","Epoch 922: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4372 - accuracy: 0.1795 - val_loss: 11.9603 - val_accuracy: 0.0000e+00\n","Epoch 923/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4777 - accuracy: 0.1562\n","Epoch 923: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4847 - accuracy: 0.1282 - val_loss: 11.9706 - val_accuracy: 0.0000e+00\n","Epoch 924/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3906 - accuracy: 0.2188\n","Epoch 924: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4353 - accuracy: 0.1795 - val_loss: 11.9702 - val_accuracy: 0.0000e+00\n","Epoch 925/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5276 - accuracy: 0.1875\n","Epoch 925: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5419 - accuracy: 0.1795 - val_loss: 11.9765 - val_accuracy: 0.0000e+00\n","Epoch 926/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4655 - accuracy: 0.1250\n","Epoch 926: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4357 - accuracy: 0.1282 - val_loss: 11.9925 - val_accuracy: 0.0000e+00\n","Epoch 927/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4844 - accuracy: 0.1562\n","Epoch 927: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4932 - accuracy: 0.1795 - val_loss: 12.0159 - val_accuracy: 0.0000e+00\n","Epoch 928/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4638 - accuracy: 0.1875\n","Epoch 928: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4990 - accuracy: 0.1538 - val_loss: 12.0918 - val_accuracy: 0.0000e+00\n","Epoch 929/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4896 - accuracy: 0.2188\n","Epoch 929: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5407 - accuracy: 0.2051 - val_loss: 12.1292 - val_accuracy: 0.0000e+00\n","Epoch 930/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5071 - accuracy: 0.1875\n","Epoch 930: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 121ms/step - loss: 2.5432 - accuracy: 0.1538 - val_loss: 12.1236 - val_accuracy: 0.0000e+00\n","Epoch 931/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3942 - accuracy: 0.0938\n","Epoch 931: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4383 - accuracy: 0.1026 - val_loss: 12.0476 - val_accuracy: 0.0000e+00\n","Epoch 932/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4884 - accuracy: 0.2188\n","Epoch 932: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.4552 - accuracy: 0.2051 - val_loss: 12.1083 - val_accuracy: 0.0000e+00\n","Epoch 933/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5475 - accuracy: 0.1562\n","Epoch 933: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5139 - accuracy: 0.1282 - val_loss: 12.1564 - val_accuracy: 0.0000e+00\n","Epoch 934/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6335 - accuracy: 0.0938\n","Epoch 934: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.6331 - accuracy: 0.1026 - val_loss: 12.0910 - val_accuracy: 0.0000e+00\n","Epoch 935/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3356 - accuracy: 0.1875\n","Epoch 935: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.3578 - accuracy: 0.2564 - val_loss: 11.9939 - val_accuracy: 0.0000e+00\n","Epoch 936/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4336 - accuracy: 0.0938\n","Epoch 936: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4203 - accuracy: 0.1282 - val_loss: 11.9777 - val_accuracy: 0.0000e+00\n","Epoch 937/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5329 - accuracy: 0.2188\n","Epoch 937: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4979 - accuracy: 0.2051 - val_loss: 11.9392 - val_accuracy: 0.0000e+00\n","Epoch 938/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4359 - accuracy: 0.0625\n","Epoch 938: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4367 - accuracy: 0.0769 - val_loss: 11.8495 - val_accuracy: 0.0000e+00\n","Epoch 939/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4247 - accuracy: 0.2188\n","Epoch 939: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.4343 - accuracy: 0.2051 - val_loss: 11.7839 - val_accuracy: 0.0000e+00\n","Epoch 940/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4954 - accuracy: 0.1250\n","Epoch 940: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4578 - accuracy: 0.1282 - val_loss: 11.9680 - val_accuracy: 0.0000e+00\n","Epoch 941/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4660 - accuracy: 0.0938\n","Epoch 941: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4898 - accuracy: 0.1282 - val_loss: 11.9955 - val_accuracy: 0.0000e+00\n","Epoch 942/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5308 - accuracy: 0.1250\n","Epoch 942: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5302 - accuracy: 0.1538 - val_loss: 12.0420 - val_accuracy: 0.0000e+00\n","Epoch 943/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3624 - accuracy: 0.2812\n","Epoch 943: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4221 - accuracy: 0.2821 - val_loss: 12.0756 - val_accuracy: 0.0000e+00\n","Epoch 944/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5759 - accuracy: 0.2500\n","Epoch 944: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.5720 - accuracy: 0.2564 - val_loss: 12.0650 - val_accuracy: 0.0000e+00\n","Epoch 945/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4452 - accuracy: 0.1562\n","Epoch 945: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4225 - accuracy: 0.1795 - val_loss: 12.0352 - val_accuracy: 0.0000e+00\n","Epoch 946/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5414 - accuracy: 0.1562\n","Epoch 946: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.5636 - accuracy: 0.1538 - val_loss: 12.0161 - val_accuracy: 0.0000e+00\n","Epoch 947/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4573 - accuracy: 0.1875\n","Epoch 947: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5060 - accuracy: 0.1538 - val_loss: 12.0473 - val_accuracy: 0.0000e+00\n","Epoch 948/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5132 - accuracy: 0.1250\n","Epoch 948: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4836 - accuracy: 0.1282 - val_loss: 12.0275 - val_accuracy: 0.0000e+00\n","Epoch 949/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4263 - accuracy: 0.2500\n","Epoch 949: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4480 - accuracy: 0.2051 - val_loss: 12.0111 - val_accuracy: 0.0000e+00\n","Epoch 950/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3729 - accuracy: 0.3125\n","Epoch 950: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 110ms/step - loss: 2.4131 - accuracy: 0.2564 - val_loss: 12.1591 - val_accuracy: 0.0000e+00\n","Epoch 951/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6314 - accuracy: 0.0938\n","Epoch 951: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.5781 - accuracy: 0.1282 - val_loss: 12.2002 - val_accuracy: 0.0000e+00\n","Epoch 952/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4979 - accuracy: 0.0938\n","Epoch 952: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4779 - accuracy: 0.1282 - val_loss: 12.1067 - val_accuracy: 0.0000e+00\n","Epoch 953/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5298 - accuracy: 0.1562\n","Epoch 953: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 122ms/step - loss: 2.5124 - accuracy: 0.1282 - val_loss: 12.0324 - val_accuracy: 0.0000e+00\n","Epoch 954/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6015 - accuracy: 0.0625\n","Epoch 954: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.5364 - accuracy: 0.0769 - val_loss: 12.0843 - val_accuracy: 0.0000e+00\n","Epoch 955/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3661 - accuracy: 0.2188\n","Epoch 955: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4512 - accuracy: 0.2308 - val_loss: 12.1002 - val_accuracy: 0.0000e+00\n","Epoch 956/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5098 - accuracy: 0.1250\n","Epoch 956: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4550 - accuracy: 0.1026 - val_loss: 12.1022 - val_accuracy: 0.0000e+00\n","Epoch 957/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3141 - accuracy: 0.1562\n","Epoch 957: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4042 - accuracy: 0.1282 - val_loss: 12.0935 - val_accuracy: 0.0000e+00\n","Epoch 958/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3611 - accuracy: 0.1875\n","Epoch 958: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4315 - accuracy: 0.2051 - val_loss: 12.0850 - val_accuracy: 0.0000e+00\n","Epoch 959/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4703 - accuracy: 0.0625\n","Epoch 959: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.5043 - accuracy: 0.0769 - val_loss: 12.0811 - val_accuracy: 0.0000e+00\n","Epoch 960/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3868 - accuracy: 0.2188\n","Epoch 960: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.3984 - accuracy: 0.2564 - val_loss: 12.1026 - val_accuracy: 0.0000e+00\n","Epoch 961/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4355 - accuracy: 0.1250\n","Epoch 961: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 124ms/step - loss: 2.4753 - accuracy: 0.1282 - val_loss: 12.1231 - val_accuracy: 0.0000e+00\n","Epoch 962/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3765 - accuracy: 0.1250\n","Epoch 962: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.4118 - accuracy: 0.1026 - val_loss: 12.1033 - val_accuracy: 0.0000e+00\n","Epoch 963/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3790 - accuracy: 0.3125\n","Epoch 963: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 120ms/step - loss: 2.4235 - accuracy: 0.3077 - val_loss: 12.0993 - val_accuracy: 0.0000e+00\n","Epoch 964/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3484 - accuracy: 0.2188\n","Epoch 964: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.3761 - accuracy: 0.1795 - val_loss: 12.0965 - val_accuracy: 0.0000e+00\n","Epoch 965/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4557 - accuracy: 0.1562\n","Epoch 965: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4535 - accuracy: 0.1795 - val_loss: 12.0978 - val_accuracy: 0.0000e+00\n","Epoch 966/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4778 - accuracy: 0.1562\n","Epoch 966: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 123ms/step - loss: 2.4590 - accuracy: 0.1538 - val_loss: 12.0905 - val_accuracy: 0.0000e+00\n","Epoch 967/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4990 - accuracy: 0.0625\n","Epoch 967: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4965 - accuracy: 0.1026 - val_loss: 12.0930 - val_accuracy: 0.0000e+00\n","Epoch 968/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4162 - accuracy: 0.0938\n","Epoch 968: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.3821 - accuracy: 0.1026 - val_loss: 12.1029 - val_accuracy: 0.0000e+00\n","Epoch 969/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4013 - accuracy: 0.2500\n","Epoch 969: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.3886 - accuracy: 0.2308 - val_loss: 12.1181 - val_accuracy: 0.0000e+00\n","Epoch 970/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5687 - accuracy: 0.0938\n","Epoch 970: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.5356 - accuracy: 0.0769 - val_loss: 12.1396 - val_accuracy: 0.0000e+00\n","Epoch 971/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3994 - accuracy: 0.1875\n","Epoch 971: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4216 - accuracy: 0.1538 - val_loss: 12.1837 - val_accuracy: 0.0000e+00\n","Epoch 972/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4976 - accuracy: 0.1250\n","Epoch 972: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5068 - accuracy: 0.1282 - val_loss: 12.2253 - val_accuracy: 0.0000e+00\n","Epoch 973/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5117 - accuracy: 0.2500\n","Epoch 973: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4180 - accuracy: 0.2564 - val_loss: 12.2220 - val_accuracy: 0.0000e+00\n","Epoch 974/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4449 - accuracy: 0.1250\n","Epoch 974: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4896 - accuracy: 0.1026 - val_loss: 12.2314 - val_accuracy: 0.0000e+00\n","Epoch 975/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4516 - accuracy: 0.1562\n","Epoch 975: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4201 - accuracy: 0.1795 - val_loss: 12.2421 - val_accuracy: 0.0000e+00\n","Epoch 976/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5001 - accuracy: 0.2188\n","Epoch 976: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.4454 - accuracy: 0.2308 - val_loss: 12.2322 - val_accuracy: 0.0000e+00\n","Epoch 977/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3542 - accuracy: 0.1250\n","Epoch 977: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 125ms/step - loss: 2.4295 - accuracy: 0.1282 - val_loss: 12.2462 - val_accuracy: 0.0000e+00\n","Epoch 978/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4407 - accuracy: 0.1562\n","Epoch 978: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4304 - accuracy: 0.1282 - val_loss: 12.2603 - val_accuracy: 0.0000e+00\n","Epoch 979/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4993 - accuracy: 0.1250\n","Epoch 979: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.3937 - accuracy: 0.1538 - val_loss: 12.2865 - val_accuracy: 0.0000e+00\n","Epoch 980/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4766 - accuracy: 0.0938\n","Epoch 980: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4749 - accuracy: 0.1282 - val_loss: 12.3066 - val_accuracy: 0.0000e+00\n","Epoch 981/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5308 - accuracy: 0.0938\n","Epoch 981: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.5182 - accuracy: 0.1026 - val_loss: 12.3101 - val_accuracy: 0.0000e+00\n","Epoch 982/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4595 - accuracy: 0.2188\n","Epoch 982: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 128ms/step - loss: 2.4388 - accuracy: 0.2308 - val_loss: 12.2839 - val_accuracy: 0.0000e+00\n","Epoch 983/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4286 - accuracy: 0.0938\n","Epoch 983: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4511 - accuracy: 0.1026 - val_loss: 12.2626 - val_accuracy: 0.0000e+00\n","Epoch 984/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.2291 - accuracy: 0.2812\n","Epoch 984: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.2842 - accuracy: 0.2308 - val_loss: 12.2586 - val_accuracy: 0.0000e+00\n","Epoch 985/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4425 - accuracy: 0.2188\n","Epoch 985: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.4092 - accuracy: 0.1795 - val_loss: 12.2578 - val_accuracy: 0.0000e+00\n","Epoch 986/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4559 - accuracy: 0.1250\n","Epoch 986: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4318 - accuracy: 0.1538 - val_loss: 12.2542 - val_accuracy: 0.0000e+00\n","Epoch 987/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4392 - accuracy: 0.0938\n","Epoch 987: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.3962 - accuracy: 0.1026 - val_loss: 12.2381 - val_accuracy: 0.0000e+00\n","Epoch 988/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4154 - accuracy: 0.2188\n","Epoch 988: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4015 - accuracy: 0.2308 - val_loss: 12.2237 - val_accuracy: 0.0000e+00\n","Epoch 989/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5137 - accuracy: 0.1562\n","Epoch 989: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 112ms/step - loss: 2.4987 - accuracy: 0.1795 - val_loss: 12.2089 - val_accuracy: 0.0000e+00\n","Epoch 990/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.2932 - accuracy: 0.2812\n","Epoch 990: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.3413 - accuracy: 0.2564 - val_loss: 12.2080 - val_accuracy: 0.0000e+00\n","Epoch 991/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4032 - accuracy: 0.1875\n","Epoch 991: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4749 - accuracy: 0.1538 - val_loss: 12.2277 - val_accuracy: 0.0000e+00\n","Epoch 992/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3709 - accuracy: 0.1562\n","Epoch 992: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 128ms/step - loss: 2.3844 - accuracy: 0.1538 - val_loss: 12.2467 - val_accuracy: 0.0000e+00\n","Epoch 993/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6295 - accuracy: 0.0938\n","Epoch 993: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 116ms/step - loss: 2.5196 - accuracy: 0.1282 - val_loss: 12.2512 - val_accuracy: 0.0000e+00\n","Epoch 994/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3557 - accuracy: 0.2500\n","Epoch 994: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 114ms/step - loss: 2.3754 - accuracy: 0.2308 - val_loss: 12.2515 - val_accuracy: 0.0000e+00\n","Epoch 995/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3986 - accuracy: 0.1562\n","Epoch 995: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 113ms/step - loss: 2.4320 - accuracy: 0.1538 - val_loss: 12.2627 - val_accuracy: 0.0000e+00\n","Epoch 996/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3732 - accuracy: 0.2188\n","Epoch 996: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.4156 - accuracy: 0.2051 - val_loss: 12.2941 - val_accuracy: 0.0000e+00\n","Epoch 997/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5029 - accuracy: 0.1562\n","Epoch 997: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 118ms/step - loss: 2.4717 - accuracy: 0.1538 - val_loss: 12.3339 - val_accuracy: 0.0000e+00\n","Epoch 998/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3114 - accuracy: 0.1562\n","Epoch 998: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 119ms/step - loss: 2.3829 - accuracy: 0.1282 - val_loss: 12.3407 - val_accuracy: 0.0000e+00\n","Epoch 999/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3850 - accuracy: 0.2812\n","Epoch 999: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 108ms/step - loss: 2.3973 - accuracy: 0.2308 - val_loss: 12.3130 - val_accuracy: 0.0000e+00\n","Epoch 1000/1000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3756 - accuracy: 0.2500\n","Epoch 1000: val_loss did not improve from 4.10310\n","2/2 [==============================] - 0s 111ms/step - loss: 2.4046 - accuracy: 0.2051 - val_loss: 12.2796 - val_accuracy: 0.0000e+00\n","1/1 [==============================] - 0s 48ms/step - loss: 4.1083 - accuracy: 0.0000e+00\n","Test accuracy: 0.0%\n"]}]},{"cell_type":"code","source":["def prepare_single_video(frames):\n","    frames = frames[None, ...]\n","    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n","    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n","\n","    for i, batch in enumerate(frames):\n","        video_length = batch.shape[0]\n","        length = min(MAX_SEQ_LENGTH, video_length)\n","        for j in range(length):\n","            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n","        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n","\n","    return frame_features, frame_mask\n","\n","\n","def sequence_prediction(path):\n","    class_vocab = label_processor.get_vocabulary()\n","\n","    frames = load_video(dirpath + path)\n","    frame_features, frame_mask = prepare_single_video(frames)\n","    print('frame_features.shape : ', frame_features.shape)\n","    print('frame_mask.shape : ', frame_mask.shape)\n","    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n","\n","    for i in np.argsort(probabilities)[::-1]:\n","        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n","    return frames\n","\n","\n","# This utility is for visualization.\n","# Referenced from:\n","# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n","def to_gif(images):\n","    converted_images = images.astype(np.uint8)\n","    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n","    return embed.embed_file(\"animation.gif\")\n","\n","\n","test_video = np.random.choice(train_df[\"video_name\"].values.tolist())\n","print(test_video)\n","# test_video = [  dirpath + path for path in test_video]\n","\n","print(f\"Test video path: {test_video}\")\n","test_frames = sequence_prediction(test_video)\n","to_gif(test_frames[:MAX_SEQ_LENGTH])"],"metadata":{"id":"Dl3b9WtlXA2C","executionInfo":{"status":"ok","timestamp":1653627455780,"user_tz":-540,"elapsed":16431,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10SW2FYWadw4YZVspfkrgHmqiWZgdSKjL"},"outputId":"c0d56334-e9ed-45e4-eeed-9f760995966a"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["test_video = np.random.choice(train_df[\"video_name\"].values.tolist())\n","print(f\"Test video path: {test_video}\")\n","test_frames = sequence_prediction(test_video)\n","to_gif(test_frames[:])"],"metadata":{"id":"GnF_SWmiXA4w","executionInfo":{"status":"ok","timestamp":1653627537498,"user_tz":-540,"elapsed":81735,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1h63IEoqVeHhzfr3bkGisLTuHcONbMGUE"},"outputId":"e64b23d6-5901-4ff5-aba1-276cbdddfe59"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["test_video = np.random.choice(train_df[\"video_name\"].values.tolist())\n","print(f\"Test video path: {test_video}\")\n","test_frames = sequence_prediction(test_video)\n","to_gif(test_frames[:MAX_SEQ_LENGTH])"],"metadata":{"id":"PlJwB-EmXA7L","executionInfo":{"status":"ok","timestamp":1653627611534,"user_tz":-540,"elapsed":74074,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1595c7KBwjjFphVKFNhvy-WPl5ObNuPcS"},"outputId":"1b9e3238-0781-452e-a5ae-39b997b42aea"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["test_video = np.random.choice(train_df[\"video_name\"].values.tolist())\n","print(f\"Test video path: {test_video}\")\n","test_frames = sequence_prediction(test_video)\n","to_gif(test_frames[:MAX_SEQ_LENGTH])"],"metadata":{"id":"ESkrqzD8XA9r","executionInfo":{"status":"ok","timestamp":1653627611536,"user_tz":-540,"elapsed":54,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"14aBuM7omK6YBIpkeLMWrBsQUJfMVbtW-"},"outputId":"515ac72a-d413-469c-ad0e-cf1175e1c116"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["test_video = np.random.choice(train_df[\"video_name\"].values.tolist())\n","print(f\"Test video path: {test_video}\")\n","test_frames = sequence_prediction(test_video)\n","to_gif(test_frames[:MAX_SEQ_LENGTH])"],"metadata":{"id":"wWnkczROXA_y","executionInfo":{"status":"ok","timestamp":1653627634357,"user_tz":-540,"elapsed":22831,"user":{"displayName":"정민수","userId":"04604353163343298236"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pcKSLru6MwdYeOfLodhmOnVnW_nJDLV2"},"outputId":"69481ab4-a6c8-4d61-ec83-5f88a4499ffa"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}