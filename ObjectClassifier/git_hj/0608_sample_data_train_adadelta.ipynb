{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c38e7b2",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81117f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  8 10:07:27 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    26W /  70W |   7471MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      6176      C   ...nvs/pytorch_16/bin/python     1415MiB |\r\n",
      "|    0   N/A  N/A      6688      C   ...nvs/pytorch_16/bin/python     6053MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c90d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import logging  # 로그 출력\n",
    "import easydict  # 속성으로 dict 값에 access할 수 있음\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # process bar\n",
    "from os.path import join as opj\n",
    "from ptflops import get_model_complexity_info\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, grad_scaler\n",
    "from torchvision import transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c90e8a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff47ae",
   "metadata": {},
   "source": [
    "Hyper-parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d4e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {'exp_num':'0',\n",
    "     \n",
    "     # Path settings\n",
    "     'data_path':'/home/lab16/jupyter_home/Data/',\n",
    "     'Kfold':1,\n",
    "     'model_path':'results/',\n",
    "\n",
    "     # Model parameter settings \n",
    "     'encoder_name':'regnety_160',\n",
    "     'drop_path_rate':0.2,\n",
    "     \n",
    "     # Training parameter settings\n",
    "     ## Base Parameter\n",
    "     'img_size':224,\n",
    "     'batch_size':16,\n",
    "     'epochs':100,\n",
    "#      'optimizer':'Lamb',\n",
    "     'optimizer':'Adadelta',\n",
    "     'initial_lr':5e-6,\n",
    "     'weight_decay':1e-3,\n",
    "\n",
    "     ## Augmentation\n",
    "     'aug_ver':2,\n",
    "\n",
    "     ## Scheduler (OnecycleLR)\n",
    "     'scheduler':'cycle',\n",
    "     'warm_epoch':5,\n",
    "     'max_lr':1e-3,\n",
    "\n",
    "     ### Cosine Annealing\n",
    "     'min_lr':5e-6,\n",
    "     'tmax':145,\n",
    "\n",
    "     ## etc.\n",
    "     'patience':20,\n",
    "     'clipping':None,\n",
    "\n",
    "     # Hardware settings\n",
    "     'amp':True,\n",
    "     'multi_gpu':False,\n",
    "     'logging':False,\n",
    "     'num_workers':4,\n",
    "     'seed':42\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf0e95",
   "metadata": {},
   "source": [
    "# Utils for training and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d74a4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimizer(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        \n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
    "\n",
    "# Logging\n",
    "def get_root_logger(logger_name='basicsr',\n",
    "                    log_level=logging.INFO,\n",
    "                    log_file=None):\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    # if the logger has been initialized, just return it\n",
    "    if logger.hasHandlers():\n",
    "        return logger\n",
    "\n",
    "    format_str = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(format=format_str, level=log_level)\n",
    "\n",
    "    if log_file is not None:\n",
    "        file_handler = logging.FileHandler(log_file, 'w')\n",
    "        file_handler.setFormatter(logging.Formatter(format_str))\n",
    "        file_handler.setLevel(log_level)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "class AvgMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.losses.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f420341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34eb9c5b",
   "metadata": {},
   "source": [
    "# Dataset & Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e8c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.datasets import ImageFolder\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29f8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f22fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bdf031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ae0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 레이블을 one-hot-vector로 변환\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# targets = le.fit_transform(y)\n",
    "# targets = torch.as_tensor(targets)\n",
    "# one_hot_y = F.one_hot(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1892dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation용 추가\n",
    "class Valid_Dataset(Dataset):\n",
    "    def __init__(self, transform=None): \n",
    "        total_images_path = glob('/home/lab16/jupyter_home/Data/sample/*.jpg')\n",
    "        file_names = []\n",
    "        for i in range(len(total_images_path)):\n",
    "            file_names.append(os.path.basename(total_images_path[i]))\n",
    "        file_names = np.array(file_names)\n",
    "        file_names.sort()\n",
    "\n",
    "        self.file_name = file_names\n",
    "        \n",
    "        each_label = []\n",
    "#         for i in range(len(total_images_path)):\n",
    "#             each_label.append(os.path.basename(total_images_path[i])[:5])\n",
    "            \n",
    "        for i in range(len(total_images_path)):\n",
    "            each_label.append(os.path.basename(total_images_path[i]))\n",
    "            \n",
    "        # 레이블을 one-hot-vector로 변환\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        targets = le.fit_transform(each_label)\n",
    "        targets = torch.as_tensor(targets)\n",
    "#         one_hot_y = F.one_hot(targets)\n",
    "            \n",
    "        self.target = np.array(targets) # 목표는 label\n",
    "#         self.target = one_hot_y\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Validation Dataset size:{len(self.file_name)}')\n",
    "\n",
    "    def __getitem__(self, idx):  # train 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "#         image = cv2.imread(opj('./data/train_256_new/', self.file_name[idx])).astype(np.float32)\n",
    "        image = cv2.imread(opj('/home/lab16/jupyter_home/Data/sample/', self.file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "\n",
    "        target = self.target[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "        # HWC => CHW-layout 변환\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ad6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "#     def __init__(self, df, transform=None):\n",
    "    def __init__(self, transform=None):\n",
    "#         self.file_name = df['file_name'].values      \n",
    "        \n",
    "        total_images_path = glob('/home/lab16/jupyter_home/Data/sample/*.jpg')\n",
    "        file_names = []\n",
    "        for i in range(len(total_images_path)):\n",
    "            file_names.append(os.path.basename(total_images_path[i]))\n",
    "            file_names.sort()\n",
    "        file_names = np.array(file_names)\n",
    "\n",
    "        self.file_name = file_names\n",
    "                \n",
    "        each_label = []\n",
    "#         for i in range(len(total_images_path)):\n",
    "#             each_label.append(os.path.basename(total_images_path[i])[:5])\n",
    "            \n",
    "        for i in range(len(total_images_path)):\n",
    "            each_label.append(os.path.basename(total_images_path[i]))\n",
    "\n",
    "        # 레이블을 one-hot-vector로 변환\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        targets = le.fit_transform(each_label)\n",
    "        targets = torch.as_tensor(targets)\n",
    "#         one_hot_y = F.one_hot(targets)\n",
    "            \n",
    "        self.target = np.array(targets) # 목표는 label\n",
    "#         self.target = one_hot_y\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Training Dataset size:{len(self.file_name)}')\n",
    "#         print(self.file_name)\n",
    "\n",
    "    def __getitem__(self, idx):  # train 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "#         image = cv2.imread(opj('./data/train_256_new/', self.file_name[idx])).astype(np.float32)\n",
    "        image = cv2.imread(opj('/home/lab16/jupyter_home/Data/sample/', self.file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "\n",
    "        target = self.target[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "        # HWC => CHW-layout 변환\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_name)\n",
    "\n",
    "class Test_dataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "#         total_images_path = glob(args.test_image_path + '*.jpg')\n",
    "        total_images_path = glob(path + '*.jpg')\n",
    "        file_names = []\n",
    "        for i in range(len(total_images_path)):\n",
    "            file_names.append(os.path.basename(total_images_path[i]))\n",
    "            file_names.sort()\n",
    "        file_names = np.array(file_names)\n",
    "\n",
    "        self.test_file_name = file_names\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Test Dataset size:{len(self.test_file_name)}')\n",
    "        print(self.test_file_name)\n",
    "\n",
    "    def __getitem__(self, idx): # test 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "#         image = cv2.imread(opj('./data/test_256_new/', self.test_file_name[idx])).astype(np.float32)\n",
    "#         image = cv2.imread(opj(args.test_image_path, self.test_file_name[idx])).astype(np.float32)\n",
    "        image = cv2.imread(opj(path, self.test_file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_file_name)\n",
    "\n",
    "# def get_loader(df, phase: str, batch_size, shuffle, num_workers, transform):\n",
    "def get_loader(phase: str, batch_size, shuffle, num_workers, transform):\n",
    "    if phase == 'test':\n",
    "#         dataset = Test_dataset(df, transform)  \n",
    "        dataset = Test_dataset(transform) \n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "        \n",
    "    # 임시로 추가\n",
    "    elif phase == 'validation':\n",
    "#         dataset = Train_Dataset(df, transform)\n",
    "        dataset = Valid_Dataset(transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "        \n",
    "    else:\n",
    "#         dataset = Train_Dataset(df, transform)\n",
    "        path = ''\n",
    "        dataset = Train_Dataset(transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True,\n",
    "                                 drop_last=False)\n",
    "        \n",
    "    return data_loader\n",
    "\n",
    "def get_train_augmentation(img_size, ver):\n",
    "    if ver == 1: # for validset\n",
    "        transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "#                 transforms.ToTensor()\n",
    "                ])\n",
    "\n",
    "    if ver == 2:\n",
    "        transform = transforms.Compose([\n",
    "#                 transforms.RandomHorizontalFlip(),\n",
    "#                 transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomPerspective(),\n",
    "                transforms.RandomAffine((20)),  # x, y축으로 이미지 늘림\n",
    "                transforms.RandomRotation(90),\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                transforms.ColorJitter(brightness=0.5)\n",
    "#                 transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ce401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "496a3605",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c73038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        # 사전 학습된 모델 사용하기\n",
    "        self.encoder = timm.create_model(args.encoder_name, pretrained=True,\n",
    "                                    drop_path_rate=args.drop_path_rate,\n",
    "                                    )\n",
    "        \n",
    "        if 'regnet' in args.encoder_name:        \n",
    "            num_head = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Linear(num_head, 311)\n",
    "        \n",
    "        elif 'efficient' in args.encoder_name:\n",
    "            num_head = self.encoder.classifier.in_features\n",
    "            self.encoder.classifier = nn.Linear(num_head, 311)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class Network_test(nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(encoder_name, pretrained=True,\n",
    "                                    drop_path_rate=0,\n",
    "                                    )\n",
    "        \n",
    "        if 'regnet' in encoder_name:        \n",
    "            num_head = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Linear(num_head, 311)\n",
    "        \n",
    "        elif 'efficient' in encoder_name:\n",
    "            num_head = self.encoder.classifier.in_features\n",
    "            self.encoder.classifier = nn.Linear(num_head, 311)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574592ec",
   "metadata": {},
   "source": [
    "# Trainer for Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3456802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, args, save_path):\n",
    "        '''\n",
    "        args: arguments\n",
    "        save_path: Model 가중치 저장 경로\n",
    "        '''\n",
    "        super(Trainer, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f'device:{self.device}')\n",
    "\n",
    "        # Logging\n",
    "        log_file = os.path.join(save_path, 'log_0608_adadelta.log')\n",
    "        self.logger = get_root_logger(logger_name='IR', log_level=logging.INFO, log_file=log_file)\n",
    "        self.logger.info(args)\n",
    "        # self.logger.info(args.tag)\n",
    "\n",
    "        # Train, Valid Set load\n",
    "        ############################################################################\n",
    "#         df_train = pd.read_csv(opj(args.data_path, 'train_df.csv'))\n",
    "#         print('Read train_df.csv')\n",
    "\n",
    "#         kf = StratifiedKFold(n_splits=args.Kfold, shuffle=True, random_state=args.seed)\n",
    "#         for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(df_train)), y=df_train['label'])):\n",
    "#             df_train.loc[val_idx, 'fold'] = fold\n",
    "#         val_idx = list(df_train[df_train['fold'] == int(args.fold)].index)\n",
    "\n",
    "#         df_val = df_train[df_train['fold'] == args.fold].reset_index(drop=True)\n",
    "#         df_train = df_train[df_train['fold'] != args.fold].reset_index(drop=True)\n",
    "\n",
    "        # Augmentation\n",
    "        self.train_transform = get_train_augmentation(img_size=args.img_size, ver=args.aug_ver)\n",
    "        self.test_transform = get_train_augmentation(img_size=args.img_size, ver=1)\n",
    "        \n",
    "        # 수정 - TrainLoader\n",
    "        self.train_loader = get_loader(phase='train', batch_size=args.batch_size, shuffle=True,\n",
    "                                       num_workers=args.num_workers, transform=self.train_transform)\n",
    "#         self.val_loader = get_loader(phase='validation', batch_size=args.batch_size, shuffle=False,\n",
    "#                                        num_workers=args.num_workers, transform=self.train_transform)\n",
    "        \n",
    "        # TrainLoader\n",
    "#         self.train_loader = get_loader(df_train, phase='train', batch_size=args.batch_size, shuffle=True,\n",
    "#                                        num_workers=args.num_workers, transform=self.train_transform)\n",
    "#         self.val_loader = get_loader(df_val, phase='train', batch_size=args.batch_size, shuffle=False,\n",
    "#                                        num_workers=args.num_workers, transform=self.test_transform)\n",
    "\n",
    "        # Network\n",
    "        self.model = Network(args).to(self.device)\n",
    "        macs, params = get_model_complexity_info(self.model, (3, args.img_size, args.img_size), as_strings=True,\n",
    "                                                 print_per_layer_stat=False, verbose=False)\n",
    "        self.logger.info('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "        self.logger.info('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer & Scheduler\n",
    "#         self.optimizer = optim.Lamb(self.model.parameters(), lr=args.initial_lr, weight_decay=args.weight_decay)\n",
    "        self.optimizer = torch.optim.Adadelta(self.model.parameters())\n",
    "        \n",
    "        iter_per_epoch = len(self.train_loader)\n",
    "        self.warmup_scheduler = WarmUpLR(self.optimizer, iter_per_epoch * args.warm_epoch)\n",
    "\n",
    "        if args.scheduler == 'step':\n",
    "            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=args.milestone, gamma=args.lr_factor, verbose=True)\n",
    "        elif args.scheduler == 'cos':\n",
    "            tmax = args.tmax # half-cycle \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max = tmax, eta_min=args.min_lr, verbose=True)\n",
    "        elif args.scheduler == 'cycle':\n",
    "#             self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=args.max_lr, steps_per_epoch=iter_per_epoch, epochs=args.epochs)\n",
    "            # adadelta 설정 시    \n",
    "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=args.max_lr, steps_per_epoch=iter_per_epoch, epochs=args.epochs, cycle_momentum=False)\n",
    "\n",
    "        if args.multi_gpu:\n",
    "            self.model = nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "        # Train / Validate\n",
    "        best_loss = np.inf\n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        early_stopping = 0\n",
    "        start = time.time()\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            if args.scheduler == 'cos':\n",
    "                if epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Training\n",
    "            train_loss, train_acc, train_f1 = self.training(args)\n",
    "\n",
    "            # Model weight in Multi_GPU or Single GPU\n",
    "            state_dict= self.model.module.state_dict() if args.multi_gpu else self.model.state_dict()\n",
    "\n",
    "            # Validation\n",
    "#             val_loss, val_acc, val_f1 = self.validate(args, phase='val')\n",
    "\n",
    "            # Save models\n",
    "#             if val_loss < best_loss:\n",
    "#                 early_stopping = 0\n",
    "#                 best_epoch = epoch\n",
    "#                 best_loss = val_loss\n",
    "#                 best_acc = val_acc\n",
    "#                 best_f1 = val_f1\n",
    "\n",
    "#                 torch.save({'epoch':epoch,\n",
    "#                             'state_dict':state_dict,\n",
    "#                             'optimizer': self.optimizer.state_dict(),\n",
    "#                             'scheduler': self.scheduler.state_dict(),\n",
    "#                     }, os.path.join(save_path, 'best_model_0608.pth'))\n",
    "#                 self.logger.info(f'-----------------SAVE:{best_epoch}epoch----------------')\n",
    "#             else:\n",
    "#                 early_stopping += 1\n",
    "\n",
    "#             # Early Stopping\n",
    "#             if early_stopping == args.patience:\n",
    "#                 break\n",
    "                \n",
    "#             print(f'\\nbest epoch:{best_epoch}/loss:{best_loss:.4f}/f1:{best_f1:.4f}')\n",
    "            \n",
    "            # val X\n",
    "            if train_loss < best_loss:\n",
    "                early_stopping = 0\n",
    "                best_epoch = epoch\n",
    "                best_loss = train_loss\n",
    "                best_acc = train_acc\n",
    "                best_f1 = train_f1\n",
    "\n",
    "                torch.save({'epoch':epoch,\n",
    "                            'state_dict':state_dict,\n",
    "                            'optimizer': self.optimizer.state_dict(),\n",
    "                            'scheduler': self.scheduler.state_dict(),\n",
    "                    }, os.path.join(save_path, 'best_model_0608_adadelta.pth'))\n",
    "                self.logger.info(f'-----------------SAVE:{best_epoch}epoch----------------')\n",
    "            else:\n",
    "                early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if early_stopping == args.patience:\n",
    "                break\n",
    "                \n",
    "            print(f'\\nbest epoch:{best_epoch}/loss:{best_loss:.4f}/f1:{best_f1:.4f}')\n",
    "            \n",
    "\n",
    "#         self.logger.info(f'\\nBest Val Epoch:{best_epoch} | Val Loss:{best_loss:.4f} | Val Acc:{best_acc:.4f} | Val F1:{best_f1:.4f}')\n",
    "        \n",
    "        self.logger.info(f'\\nBest Train Epoch:{best_epoch} | Train Loss:{best_loss:.4f} | Train Acc:{best_acc:.4f} | Train F1:{best_f1:.4f}')\n",
    "\n",
    "        end = time.time()\n",
    "        self.logger.info(f'Total Process time:{(end - start) / 60:.3f}Minute')\n",
    "\n",
    "    # Training\n",
    "    def training(self, args):\n",
    "        self.model.train()\n",
    "        train_loss = AvgMeter()\n",
    "        train_acc = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        scaler = grad_scaler.GradScaler()\n",
    "        for i, (images, targets) in enumerate(tqdm(self.train_loader)):\n",
    "            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "            targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            if self.epoch <= args.warm_epoch:\n",
    "                self.warmup_scheduler.step()\n",
    "\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "            if args.amp:\n",
    "                with autocast():\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, targets)\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Gradient Clipping\n",
    "                if args.clipping is not None:\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if args.scheduler == 'cycle':\n",
    "                if self.epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Metric\n",
    "            train_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "            targets_list.extend(targets.cpu().detach().numpy())\n",
    "            # log\n",
    "            train_loss.update(loss.item(), n=images.size(0))\n",
    "\n",
    "        train_acc /= len(self.train_loader.dataset)\n",
    "        train_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "        self.logger.info(f'Epoch:[{self.epoch:03d}/{args.epochs:03d}]')\n",
    "        self.logger.info(f'Train Loss:{train_loss.avg:.3f} | Acc:{train_acc:.4f} | F1:{train_f1:.4f}')\n",
    "        return train_loss.avg, train_acc, train_f1\n",
    "            \n",
    "    # Validation or Dev\n",
    "    def validate(self, args, phase='val'):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = AvgMeter()\n",
    "            val_acc = 0\n",
    "            preds_list = []\n",
    "            targets_list = []\n",
    "\n",
    "            for i, (images, targets) in enumerate(self.val_loader):\n",
    "                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "                targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "\n",
    "                # Metric\n",
    "                val_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "                preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "                targets_list.extend(targets.cpu().detach().numpy())\n",
    "\n",
    "                # log\n",
    "                val_loss.update(loss.item(), n=images.size(0))\n",
    "            val_acc /= len(self.val_loader.dataset)\n",
    "            val_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "            self.logger.info(f'{phase} Loss:{val_loss.avg:.3f} | Acc:{val_acc:.4f} | F1:{val_f1:.4f}')\n",
    "        return val_loss.avg, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66f503",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54d2a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print('<---- Training Params ---->')\n",
    "    \n",
    "    # Random Seed\n",
    "    seed = args.seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    save_path = os.path.join(args.model_path, (args.exp_num).zfill(3))\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    Trainer(args, save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5763bf",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0beb201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder_name, test_loader, device, model_path):\n",
    "    model = Network_test(encoder_name).to(device)\n",
    "    model.load_state_dict(torch.load(opj(model_path, 'best_model_0608_adadelta.pth'))['state_dict'])\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = torch.as_tensor(images, device=device, dtype=torch.float32)\n",
    "            preds = model(images)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            preds_list.extend(preds.cpu().tolist())\n",
    "\n",
    "    return np.array(preds_list)\n",
    "\n",
    "def ensemble_5fold(model_path_list, test_loader, device):\n",
    "    predict_list = []\n",
    "    for model_path in model_path_list:\n",
    "        prediction = predict(encoder_name= 'regnety_160', \n",
    "                             test_loader = test_loader, device = device, model_path = model_path)\n",
    "        predict_list.append(prediction)\n",
    "    ensemble = (predict_list[0] + predict_list[1] + predict_list[2] + predict_list[3] + predict_list[4])/len(predict_list)\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc682d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold X\n",
    "def result(model_path_list, test_loader, device):\n",
    "    predict_list = []\n",
    "    for model_path in model_path_list:\n",
    "        prediction = predict(encoder_name= 'regnety_160', \n",
    "                             test_loader = test_loader, device = device, model_path = model_path)\n",
    "        predict_list.append(prediction)\n",
    "    ensemble = predict_list[0]\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8c70a",
   "metadata": {},
   "source": [
    "# Train & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d602b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "866d58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv('./data/sample_submission.csv')\n",
    "# df_train = pd.read_csv('./data/train_df.csv')\n",
    "# df_test = pd.read_csv('./data/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cae8472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_transform = get_train_augmentation(img_size=img_size, ver=1)\n",
    "# test_dataset = Test_dataset(df_test, test_transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe785ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e377aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e77ed23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 10:07:28,902 INFO: {'exp_num': '0', 'data_path': '/home/lab16/jupyter_home/Data/', 'Kfold': 1, 'model_path': 'results/', 'encoder_name': 'regnety_160', 'drop_path_rate': 0.2, 'img_size': 224, 'batch_size': 16, 'epochs': 100, 'optimizer': 'Adadelta', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 20, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 4, 'seed': 42, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "device:cuda\n",
      "Training Dataset size:311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 10:07:30,112 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "2022-06-08 10:07:34,510 INFO: Computational complexity:       15.93 GMac\n",
      "2022-06-08 10:07:34,511 INFO: Number of parameters:           81.51 M \n",
      "100%|███████████████████████████████████████████| 20/20 [00:12<00:00,  1.56it/s]\n",
      "2022-06-08 10:07:47,300 INFO: Epoch:[001/100]\n",
      "2022-06-08 10:07:47,300 INFO: Train Loss:5.811 | Acc:0.0000 | F1:0.0000\n",
      "2022-06-08 10:07:48,965 INFO: -----------------SAVE:1epoch----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:1/loss:5.8114/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.37it/s]\n",
      "2022-06-08 10:07:57,423 INFO: Epoch:[002/100]\n",
      "2022-06-08 10:07:57,423 INFO: Train Loss:5.754 | Acc:0.0032 | F1:0.0009\n",
      "2022-06-08 10:08:01,406 INFO: -----------------SAVE:2epoch----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:2/loss:5.7543/f1:0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.37it/s]\n",
      "2022-06-08 10:08:09,841 INFO: Epoch:[003/100]\n",
      "2022-06-08 10:08:09,841 INFO: Train Loss:5.763 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:2/loss:5.7543/f1:0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.37it/s]\n",
      "2022-06-08 10:08:18,286 INFO: Epoch:[004/100]\n",
      "2022-06-08 10:08:18,286 INFO: Train Loss:5.775 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:2/loss:5.7543/f1:0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.36it/s]\n",
      "2022-06-08 10:08:26,789 INFO: Epoch:[005/100]\n",
      "2022-06-08 10:08:26,790 INFO: Train Loss:5.777 | Acc:0.0032 | F1:0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:2/loss:5.7543/f1:0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.39it/s]\n",
      "2022-06-08 10:08:35,173 INFO: Epoch:[006/100]\n",
      "2022-06-08 10:08:35,174 INFO: Train Loss:5.755 | Acc:0.0064 | F1:0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:2/loss:5.7543/f1:0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.40it/s]\n",
      "2022-06-08 10:08:43,513 INFO: Epoch:[007/100]\n",
      "2022-06-08 10:08:43,514 INFO: Train Loss:5.754 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:2/loss:5.7543/f1:0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.37it/s]\n",
      "2022-06-08 10:08:51,949 INFO: Epoch:[008/100]\n",
      "2022-06-08 10:08:51,949 INFO: Train Loss:5.745 | Acc:0.0096 | F1:0.0014\n",
      "2022-06-08 10:08:55,929 INFO: -----------------SAVE:8epoch----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.36it/s]\n",
      "2022-06-08 10:09:04,401 INFO: Epoch:[009/100]\n",
      "2022-06-08 10:09:04,402 INFO: Train Loss:5.756 | Acc:0.0096 | F1:0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.31it/s]\n",
      "2022-06-08 10:09:13,075 INFO: Epoch:[010/100]\n",
      "2022-06-08 10:09:13,075 INFO: Train Loss:5.753 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.36it/s]\n",
      "2022-06-08 10:09:21,551 INFO: Epoch:[011/100]\n",
      "2022-06-08 10:09:21,552 INFO: Train Loss:5.760 | Acc:0.0064 | F1:0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.38it/s]\n",
      "2022-06-08 10:09:29,980 INFO: Epoch:[012/100]\n",
      "2022-06-08 10:09:29,981 INFO: Train Loss:5.750 | Acc:0.0064 | F1:0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.35it/s]\n",
      "2022-06-08 10:09:38,489 INFO: Epoch:[013/100]\n",
      "2022-06-08 10:09:38,489 INFO: Train Loss:5.751 | Acc:0.0064 | F1:0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:09:47,082 INFO: Epoch:[014/100]\n",
      "2022-06-08 10:09:47,083 INFO: Train Loss:5.753 | Acc:0.0096 | F1:0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.34it/s]\n",
      "2022-06-08 10:09:55,631 INFO: Epoch:[015/100]\n",
      "2022-06-08 10:09:55,632 INFO: Train Loss:5.753 | Acc:0.0032 | F1:0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:10:04,212 INFO: Epoch:[016/100]\n",
      "2022-06-08 10:10:04,213 INFO: Train Loss:5.755 | Acc:0.0032 | F1:0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:10:12,794 INFO: Epoch:[017/100]\n",
      "2022-06-08 10:10:12,795 INFO: Train Loss:5.752 | Acc:0.0032 | F1:0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:8/loss:5.7454/f1:0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.35it/s]\n",
      "2022-06-08 10:10:21,308 INFO: Epoch:[018/100]\n",
      "2022-06-08 10:10:21,309 INFO: Train Loss:5.742 | Acc:0.0064 | F1:0.0010\n",
      "2022-06-08 10:10:25,292 INFO: -----------------SAVE:18epoch----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:18/loss:5.7418/f1:0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:10:33,868 INFO: Epoch:[019/100]\n",
      "2022-06-08 10:10:33,868 INFO: Train Loss:5.759 | Acc:0.0032 | F1:0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:18/loss:5.7418/f1:0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:10:42,467 INFO: Epoch:[020/100]\n",
      "2022-06-08 10:10:42,468 INFO: Train Loss:5.758 | Acc:0.0032 | F1:0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:18/loss:5.7418/f1:0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.36it/s]\n",
      "2022-06-08 10:10:50,958 INFO: Epoch:[021/100]\n",
      "2022-06-08 10:10:50,958 INFO: Train Loss:5.728 | Acc:0.0000 | F1:0.0000\n",
      "2022-06-08 10:10:54,966 INFO: -----------------SAVE:21epoch----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.29it/s]\n",
      "2022-06-08 10:11:03,692 INFO: Epoch:[022/100]\n",
      "2022-06-08 10:11:03,693 INFO: Train Loss:5.762 | Acc:0.0032 | F1:0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.37it/s]\n",
      "2022-06-08 10:11:12,140 INFO: Epoch:[023/100]\n",
      "2022-06-08 10:11:12,141 INFO: Train Loss:5.763 | Acc:0.0032 | F1:0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.32it/s]\n",
      "2022-06-08 10:11:20,764 INFO: Epoch:[024/100]\n",
      "2022-06-08 10:11:20,765 INFO: Train Loss:5.751 | Acc:0.0032 | F1:0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.31it/s]\n",
      "2022-06-08 10:11:29,444 INFO: Epoch:[025/100]\n",
      "2022-06-08 10:11:29,444 INFO: Train Loss:5.770 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:11:38,047 INFO: Epoch:[026/100]\n",
      "2022-06-08 10:11:38,048 INFO: Train Loss:5.745 | Acc:0.0032 | F1:0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.32it/s]\n",
      "2022-06-08 10:11:46,683 INFO: Epoch:[027/100]\n",
      "2022-06-08 10:11:46,684 INFO: Train Loss:5.750 | Acc:0.0064 | F1:0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.35it/s]\n",
      "2022-06-08 10:11:55,216 INFO: Epoch:[028/100]\n",
      "2022-06-08 10:11:55,217 INFO: Train Loss:5.743 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.26it/s]\n",
      "2022-06-08 10:12:04,063 INFO: Epoch:[029/100]\n",
      "2022-06-08 10:12:04,063 INFO: Train Loss:5.746 | Acc:0.0064 | F1:0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.28it/s]\n",
      "2022-06-08 10:12:12,856 INFO: Epoch:[030/100]\n",
      "2022-06-08 10:12:12,856 INFO: Train Loss:5.737 | Acc:0.0032 | F1:0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.32it/s]\n",
      "2022-06-08 10:12:21,505 INFO: Epoch:[031/100]\n",
      "2022-06-08 10:12:21,505 INFO: Train Loss:5.757 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:12:30,089 INFO: Epoch:[032/100]\n",
      "2022-06-08 10:12:30,089 INFO: Train Loss:5.751 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.29it/s]\n",
      "2022-06-08 10:12:38,832 INFO: Epoch:[033/100]\n",
      "2022-06-08 10:12:38,833 INFO: Train Loss:5.750 | Acc:0.0064 | F1:0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.35it/s]\n",
      "2022-06-08 10:12:47,358 INFO: Epoch:[034/100]\n",
      "2022-06-08 10:12:47,359 INFO: Train Loss:5.748 | Acc:0.0032 | F1:0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.28it/s]\n",
      "2022-06-08 10:12:56,160 INFO: Epoch:[035/100]\n",
      "2022-06-08 10:12:56,161 INFO: Train Loss:5.744 | Acc:0.0032 | F1:0.0006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.32it/s]\n",
      "2022-06-08 10:13:04,787 INFO: Epoch:[036/100]\n",
      "2022-06-08 10:13:04,788 INFO: Train Loss:5.758 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.33it/s]\n",
      "2022-06-08 10:13:13,367 INFO: Epoch:[037/100]\n",
      "2022-06-08 10:13:13,367 INFO: Train Loss:5.743 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.34it/s]\n",
      "2022-06-08 10:13:21,923 INFO: Epoch:[038/100]\n",
      "2022-06-08 10:13:21,924 INFO: Train Loss:5.759 | Acc:0.0032 | F1:0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.31it/s]\n",
      "2022-06-08 10:13:30,610 INFO: Epoch:[039/100]\n",
      "2022-06-08 10:13:30,611 INFO: Train Loss:5.741 | Acc:0.0000 | F1:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.29it/s]\n",
      "2022-06-08 10:13:39,356 INFO: Epoch:[040/100]\n",
      "2022-06-08 10:13:39,356 INFO: Train Loss:5.744 | Acc:0.0064 | F1:0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best epoch:21/loss:5.7283/f1:0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.31it/s]\n",
      "2022-06-08 10:13:48,010 INFO: Epoch:[041/100]\n",
      "2022-06-08 10:13:48,011 INFO: Train Loss:5.740 | Acc:0.0000 | F1:0.0000\n",
      "2022-06-08 10:13:48,017 INFO: \n",
      "Best Train Epoch:21 | Train Loss:5.7283 | Train Acc:0.0000 | Train F1:0.0000\n",
      "2022-06-08 10:13:48,018 INFO: Total Process time:6.225Minute\n"
     ]
    }
   ],
   "source": [
    "# fold 없이\n",
    "models_path = []\n",
    "args.fold = 0\n",
    "args.exp_num = str(0)\n",
    "save_path = main(args)\n",
    "models_path.append(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f626fb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/000']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a866b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fold X\n",
    "# result = result(models_path, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d34beddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 16\n",
      "epochs = 100\n",
      "img_size = 224\n",
      "patience = 20\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용한 모델의 batch_size, epoch, img_size, patience\n",
    "print('batch_size =', args.batch_size)\n",
    "print('epochs =', args.epochs)\n",
    "print('img_size =', args.img_size)\n",
    "print('patience =', args.patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1f5385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = regnety_160\n"
     ]
    }
   ],
   "source": [
    "print('model =', args.encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ee487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfece32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afb705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2aea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94a302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f81609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee60836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_16] *",
   "language": "python",
   "name": "conda-env-pytorch_16-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
