{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f7db62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Validation', 'Training']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "base_path = '/home/lab17/jupyter_home/Data/product_image'\n",
    "files = os.listdir(base_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f49c5d",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e2e61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 변수\n",
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device('cuda')\n",
    "batch_size = 8\n",
    "class_n = len(os.listdir('/home/lab17/jupyter_home/Data/product_image/Training/image'))\n",
    "# class_n = len(train_total['disease_code'].unique())\n",
    "learning_rate = 5e-5\n",
    "epochs = 300\n",
    "save_path = 'model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf142e9",
   "metadata": {},
   "source": [
    "# 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c3820b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label count 76\n",
      "valid_label count 76\n",
      "train_label length 8664\n",
      "valid_label length 1140\n"
     ]
    }
   ],
   "source": [
    "base_path = '/home/lab17/jupyter_home/Data/product_image'\n",
    "\n",
    "train_jpg = sorted(glob(os.path.join(base_path, 'Training/image/**/*.jpg')))\n",
    "valid_jpg = sorted(glob(os.path.join(base_path, 'Validation/image/**/*.jpg')))\n",
    "\n",
    "train_label = [int(t_img[len(base_path+'/Training/image/'):len(base_path+'/Training/image/')+5]) for t_img in train_jpg]\n",
    "valid_label = [int(v_img[len(base_path+'/Validation/image/'):len(base_path+'/Validation/image/')+5]) for v_img in valid_jpg]\n",
    "\n",
    "print('train_label count', len(set(train_label)))\n",
    "print('valid_label count', len(set(valid_label)))\n",
    "print('train_label length' , len(train_label))\n",
    "print('valid_label length' , len(valid_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df9249",
   "metadata": {},
   "source": [
    "# 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0cc0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Custom_dataset(Dataset):\n",
    "#     def __init__(self, img_paths, labels, mode='train'):\n",
    "#         self.img_paths = img_paths\n",
    "#         self.labels = labels\n",
    "#         self.mode=mode\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = self.img_paths[idx]\n",
    "#         img = img.resize((256,256))\n",
    "# #         if self.mode == 'train':\n",
    "# #             train_transform = transforms.Compose([\n",
    "# #                     transforms.ToTensor(),\n",
    "# #                     transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "# #                                         std = [0.181572, 0.174035, 0.163234]),\n",
    "# #                     transforms.RandomAffine((-45, 45)),\n",
    "\n",
    "# #                     transforms.RandomVerticalFlip(p=0.5),   # - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
    "# #                     transforms.RandomHorizontalFlip(p=0.5), # - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
    "# #                     transforms.RandomRotation((0,80))       #  이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "\n",
    "# #                 ])\n",
    "# #                 img = train_transform(img)\n",
    "# #         if self.mode == 'test':\n",
    "# #           test_transform = transforms.Compose([\n",
    "# #                 transforms.ToTensor(),\n",
    "# #                 transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "# #                                      std = [0.195055, 0.190053, 0.185323]),\n",
    "              \n",
    "# #             ])\n",
    "# #           img = test_transform(img)\n",
    "\n",
    "#         label = self.labels[idx]\n",
    "#         return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3121b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, files, labels=None, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.files = files\n",
    "        if mode == 'train':\n",
    "            self.labels = labels\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if self.mode == 'train':\n",
    "            img = cv2.imread(self.files[i])\n",
    "            img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
    "            img = img.astype(np.float32)/255\n",
    "            \n",
    "            # 0~3 사이의 임의의 정수 생성\n",
    "            rand = random.randrange(0,4)\n",
    "            \n",
    "#             if rand == 0:\n",
    "#               img = img\n",
    "#             elif rand == 1:\n",
    "#               img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE) # 시계방향으로 90도 회전\n",
    "#             elif rand == 2:\n",
    "#               img = cv2.rotate(img, cv2.ROTATE_180) # 180도 회전       \n",
    "#             elif rand == 3:\n",
    "#               img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) # 시계방향으로 270도 회전\n",
    "#             else:\n",
    "#               img=img\n",
    "       \n",
    "            img = np.transpose(img, (2,0,1))\n",
    "            return {\n",
    "                'img' : torch.tensor(img, dtype=torch.float32),\n",
    "                'label' : torch.tensor(self.labels[i], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            img = cv2.imread('test_imgs/'+self.files[i])\n",
    "            img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
    "            img = img.astype(np.float32)/255\n",
    "\n",
    "            img = np.transpose(img, (2,0,1))\n",
    "            return {\n",
    "                'img' : torch.tensor(img, dtype=torch.float32),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c23989fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_dataset = Custom_dataset(train_jpg, train_label, mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Val\n",
    "val_dataset = Custom_dataset(valid_jpg, valid_label, mode='test')\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "500c6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_function(real, pred):\n",
    "#     score = f1_score(real, pred, average=\"macro\")\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80cd8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b45e5",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0cdc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=class_n, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=class_n, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, class_n, rate=0.1):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        self.output_layer = nn.Linear(in_features=1000, out_features=class_n, bias=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.output_layer(self.dropout(self.model(inputs)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3ec5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model(class_n).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d4efe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613385e",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f87dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_item, epoch, batch, training):\n",
    "    img = batch_item['img'].to(device)\n",
    "    label = batch_item['label'].to(device)\n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66015239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:02, ?it/s]\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, batch_item \u001b[38;5;129;01min\u001b[39;00m tqdm_dataset:\n\u001b[0;32m----> 9\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m     12\u001b[0m     tqdm_dataset\u001b[38;5;241m.\u001b[39mset_postfix({\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:06f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_loss\u001b[38;5;241m.\u001b[39mitem()),\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Loss\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:06f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(total_loss\u001b[38;5;241m/\u001b[39m(batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     16\u001b[0m     })\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batch_item, epoch, batch, training)\u001b[0m\n\u001b[1;32m      8\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, label)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_17/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_17/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_loader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1))\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(val_loader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
    "        total_val_loss += batch_loss\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1))\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    \n",
    "    if val_loss_plot[-1]<0.04:\n",
    "        torch.save(model, 'models/model'+str(epoch+1)+str(val_loss_plot[-1])+'.pt')\n",
    "    if min(val_loss_plot) == val_loss_plot[-1]:\n",
    "        torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bae378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_17] *",
   "language": "python",
   "name": "conda-env-pytorch_17-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
