{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ffacd993",
      "metadata": {
        "id": "ffacd993"
      },
      "outputs": [],
      "source": [
        "# 실습에 필요한 라이브러리를 불러옵니다.\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9d144a14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d144a14",
        "outputId": "0ee2bc82-f0ef-4399-9f0e-f49584be4cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 296 (delta 6), reused 3 (delta 3), pack-reused 289\u001b[K\n",
            "Receiving objects: 100% (296/296), 64.38 MiB | 29.74 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ],
      "source": [
        "# MNIST DATASET 다운로드\n",
        "!git clone https://github.com/baek2sm/ml.git\n",
        "!tar -zxvf ./ml/datasets/MNIST.tar.gz\n",
        "\n",
        "# 현재 경로에 MNIST 학습 세트와 테스트 세트를 불러옵니다.\n",
        "path = './'\n",
        "train_dataset = datasets.MNIST(path, train=True, download=True)\n",
        "test_dataset = datasets.MNIST(path, train=False, download=True)\n",
        "\n",
        "# 학습 세트와 테스트 세트의 입력 데이터와 타깃을 준비합니다.\n",
        "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
        "X_test, y_test = test_dataset.data / 255, test_dataset.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1d76a492",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d76a492",
        "outputId": "4a4cf320-488b-4854-a410-0523b5b092fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 세트 입력 데이터: torch.Size([60000, 28, 28])\n",
            "학습 세트 타깃: torch.Size([60000])\n",
            "테스트 세트 입력 데이터: torch.Size([10000, 28, 28])\n",
            "테스트 세트 타깃: torch.Size([10000])\n"
          ]
        }
      ],
      "source": [
        "# 학습 세트와 테스트 세트의 데이터 형태를 확인합니다.\n",
        "print('학습 세트 입력 데이터:', X_train.shape)\n",
        "print('학습 세트 타깃:', y_train.shape)\n",
        "print('테스트 세트 입력 데이터:', X_test.shape)\n",
        "print('테스트 세트 타깃:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "deea7e7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deea7e7c",
        "outputId": "1ad44e42-e410-44e9-8a36-1821be44c372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 세트 입력 데이터: torch.Size([60000, 1, 28, 28])\n",
            "테스트 세트 입력 데이터: torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# 2차원(높이, 너비) 형태인 이미지 데이터를 3차원(채널, 높이, 너비) 형태로 변환합니다.\n",
        "X_train, X_test = X_train.unsqueeze(1), X_test.unsqueeze(1)\n",
        "\n",
        "# 학습 세트와 테스트 세트의 데이터 형태를 확인합니다.\n",
        "print('학습 세트 입력 데이터:', X_train.shape)\n",
        "print('테스트 세트 입력 데이터:', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "876e5d63",
      "metadata": {
        "id": "876e5d63"
      },
      "outputs": [],
      "source": [
        "# 입력 데이터와 타깃을 묶어 텐서 데이터세트를 생성합니다.\n",
        "train_dset = TensorDataset(X_train, y_train)\n",
        "test_dset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# 한 번에 128개의 데이터 샘플을 배치로 사용하는 데이터로더를 생성합니다.\n",
        "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1ed23ed5",
      "metadata": {
        "id": "1ed23ed5"
      },
      "outputs": [],
      "source": [
        "# CNN 모델 클래스를 정의합니다.\n",
        "class CNN(nn.Module):\n",
        "    # 생성자에서 모델의 구조를 정의합니다. \n",
        "    def __init__(self):\n",
        "        # 상속받아 생성한 객체이므로 부모(nn.Module)의 생성자를 호출합니다.\n",
        "        super().__init__()\n",
        "        # 첫 번째 은닉층을 정의합니다.\n",
        "        self.hidden_layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=(3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "            nn.Dropout(0.5)      \n",
        "        )        \n",
        "        # 두 번째 은닉층을 정의합니다.\n",
        "        self.hidden_layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2)),      \n",
        "            nn.Dropout(0.5)      \n",
        "        )\n",
        "        # 세 번째 은닉층을 정의합니다.\n",
        "        self.hidden_layer3 = nn.Linear(128*5*5, 128)\n",
        "        # 출력층을 정의합니다.\n",
        "        self.output_layer = nn.Linear(128, 10)        \n",
        "    # 모델의 순전파를 정의합니다.\n",
        "    def forward(self, X):\n",
        "        # 생성자에서 만든 은닉층과 출력층 노드로 타깃을 추론하고 반환합니다.\n",
        "        out = self.hidden_layer1(X)\n",
        "        out = self.hidden_layer2(out)                        \n",
        "        out = out.view(out.shape[0], -1)  # 전결합층을 사용하기 위해 1차원 배열 형태로 변환합니다.        \n",
        "        out = self.hidden_layer3(out)\n",
        "        out = self.output_layer(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c758d3e5",
      "metadata": {
        "id": "c758d3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9d7dfe-f193-4e94-d6f4-143d5fab03ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device :  cuda\n"
          ]
        }
      ],
      "source": [
        "# 그래픽카드 사용이 가능할 경우 그래픽카드로 연산하도록 설정합니다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device : \", device)\n",
        "# 합성곱 신경망 모델 객체를 생성합니다.\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 크로스 엔트로피(Cross Entropy) 손실 함수 객체를 생성합니다.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 확률적 경사 하강법 옵티마이저 객체를 생성합니다.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "be31014a",
      "metadata": {
        "id": "be31014a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 학습 함수를 정의합니다.\n",
        "def train(model, criterion, optimizer, loader):\n",
        "  # 현재 에포크의 오차와 정확도를 저장할 변수를 생성합니다.\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  # 모델을 학습 모드로 설정합니다.\n",
        "  model.train()\n",
        "  \n",
        "  # 배치 학습을 실행합니다.\n",
        "  for X_batch, y_batch in loader:\n",
        "    # 입력 데이터와 타깃의 배치를 그래픽 카드로 연산하도록 설정합니다.\n",
        "    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "    # 기울기를 초기화합니다.\n",
        "    optimizer.zero_grad()\n",
        "    # 모델을 사용해 타깃을 추론합니다.\n",
        "    hypothesis = model(X_batch)\n",
        "    # 손실 함수로 오차를 계산합니다.\n",
        "    loss = criterion(hypothesis, y_batch)        \n",
        "    # 기울기를 계산합니다.\n",
        "    loss.backward()\n",
        "    # 경사 하강법으로 가중치를 수정합니다.\n",
        "    optimizer.step()\n",
        "    # 정확도를 계산합니다.\n",
        "    y_predicted = torch.argmax(hypothesis, 1)\n",
        "    acc = (y_predicted == y_batch).float().mean()\n",
        "    # 현재 배치의 오차와 정확도를 저장합니다.\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "    \n",
        "\n",
        "  # 현재 에포크의 오차와 정확도를 반환합니다.\n",
        "  return epoch_loss / len(loader), epoch_acc / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c048b6a7",
      "metadata": {
        "id": "c048b6a7"
      },
      "outputs": [],
      "source": [
        "# 평가 함수를 정의합니다.\n",
        "def evaluate(model, criterion, loader):\n",
        "  # 현재 에포크의 오차와 정확도를 저장할 변수를 생성합니다.\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  # 모델을 평가 모드로 설정합니다.\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # 배치 단위로 추론을학습을 실행합니다.\n",
        "    for X_batch, y_batch in loader:\n",
        "      # 입력 데이터와 타깃의 배치를 그래픽 카드로 연산하도록 설정합니다.\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      # 모델을 사용해 타깃을 추론합니다.\n",
        "      hypothesis = model(X_batch)\n",
        "      # 손실 함수로 오차를 계산합니다.\n",
        "      loss = criterion(hypothesis, y_batch)\n",
        "      # 정확도를 계산합니다.\n",
        "      y_predicted = torch.argmax(hypothesis, 1)\n",
        "      acc = (y_predicted == y_batch).float().mean()\n",
        "      # 현재 배치의 오차와 정확도를 저장합니다.\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "    # 현재 에포크의 오차와 정확도를 반환합니다.\n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서보드 설치\n",
        "!pip install jupyter-tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUn2o6IlHFeM",
        "outputId": "22cb2dfb-4344-4081-c4cf-c809e8b6d843"
      },
      "id": "hUn2o6IlHFeM",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jupyter-tensorboard\n",
            "  Downloading jupyter_tensorboard-0.2.0.tar.gz (15 kB)\n",
            "Requirement already satisfied: notebook>=5.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-tensorboard) (5.3.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.1.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (4.10.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (4.10.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.4.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (23.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=5.0->jupyter-tensorboard) (0.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook>=5.0->jupyter-tensorboard) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=5.0->jupyter-tensorboard) (2.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (5.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=5.0->jupyter-tensorboard) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=5.0->jupyter-tensorboard) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (5.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (4.11.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (4.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (3.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=5.0->jupyter-tensorboard) (0.5.1)\n",
            "Building wheels for collected packages: jupyter-tensorboard\n",
            "  Building wheel for jupyter-tensorboard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jupyter-tensorboard: filename=jupyter_tensorboard-0.2.0-py2.py3-none-any.whl size=15258 sha256=85ff8397c25904d87c23c3a8658d3816c5388ef1257eb7ae37fa360f7d97fbb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/14/ab/6d0bce449039ebdcbf45c1aff8c19153a68bf3f0492a32620e\n",
            "Successfully built jupyter-tensorboard\n",
            "Installing collected packages: jupyter-tensorboard\n",
            "Successfully installed jupyter-tensorboard-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bcf43f76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcf43f76",
        "outputId": "5676e695-b66f-4519-b132-b0d2778bba84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 0.422, acc: 0.87, test_loss: 0.120, test_acc: 0.966\n",
            "epoch: 2, loss: 0.144, acc: 0.96, test_loss: 0.075, test_acc: 0.978\n",
            "epoch: 3, loss: 0.108, acc: 0.97, test_loss: 0.059, test_acc: 0.982\n",
            "epoch: 4, loss: 0.091, acc: 0.97, test_loss: 0.050, test_acc: 0.984\n",
            "epoch: 5, loss: 0.081, acc: 0.97, test_loss: 0.045, test_acc: 0.985\n",
            "epoch: 6, loss: 0.073, acc: 0.98, test_loss: 0.040, test_acc: 0.986\n"
          ]
        }
      ],
      "source": [
        "# train 결과  -> 텐서보드 \n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# 로그저장위치\n",
        "writer = SummaryWriter('/content/runs/mnist')\n",
        "\n",
        "# matplotlib 에서 사용할 list\n",
        "t_loss_list = []\n",
        "t_acc_list = []\n",
        "test_loss_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 20에 걸쳐 모델을 학습시킵니다.\n",
        "n_epochs = 6\n",
        "\n",
        "# matplotlib 에서 사용할 epoch_list\n",
        "epoch_list = [i for i in range(1, n_epochs+1, 1)]\n",
        "for epoch in range(1, n_epochs+1):\n",
        "  # 모델을 학습시킵니다.\n",
        "  loss, acc = train(model, criterion, optimizer, train_loader)\n",
        "\n",
        "  # 모델을 평가합니다.\n",
        "  test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
        "\n",
        "  # 현재 에포크의 학습 결과를 출력합니다.\n",
        "  print('epoch: {}, loss: {:.3f}, acc: {:.2f}, test_loss: {:.3f}, test_acc: {:.3f}'.format(\n",
        "       epoch, loss, acc, test_loss, test_acc))\n",
        "  \n",
        "  # matplotlib 에서 사용할 list 에 값 저장\n",
        "  t_loss_list.append(loss)\n",
        "  t_acc_list.append(acc)\n",
        "  test_loss_list.append(test_loss)\n",
        "  test_acc_list.append(test_acc)\n",
        "  # 텐서보드에서 사용할 값 저장\n",
        "  writer.add_scalar('train_loss', loss, epoch)\n",
        "  writer.add_scalar('train_acc', acc, epoch)\n",
        "  writer.add_scalar('test_loss', test_loss, epoch)\n",
        "  writer.add_scalar('test_acc', test_acc, epoch)\n",
        "# 텐서보드 writer flush, close\n",
        "writer.flush()\n",
        "writer.close()\n",
        "\n",
        "\n",
        "loss_frm = pd.DataFrame({\n",
        "    'epoch':epoch_list, \n",
        "    'train_lossA':t_loss_list,\n",
        "    'train_accA':t_acc_list,\n",
        "    'test_lossA':test_loss_list,\n",
        "    'test_accA':test_acc_list\n",
        "  },\n",
        "  #columns = ['epoch','train_loss','train_acc']\n",
        "  #columns = ['epoch','train_lossA','train_accA','test_lossA','test_accA']\n",
        "  columns = ['epoch','train_lossA']\n",
        ")\n",
        "loss_frm.to_csv(\"20220610_Mnist.csv\", header=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "loss_chart.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}