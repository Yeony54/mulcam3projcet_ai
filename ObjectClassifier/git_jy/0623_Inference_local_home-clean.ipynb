{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c3de41",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d30ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c81cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20bc0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_47224\\2738216029.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e643018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':256,\n",
    "    'EPOCHS':50,\n",
    "    'PATIENCE':10,\n",
    "#     'class':41 # quasi_drug\n",
    "    'class':126 # home_clean\n",
    "    # 'class':41 # HMR \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5d77fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RegNet_0.0001_rmsprop_CosineAnnealing_example.pth',\n",
       " 'RegNet_0.001_rmsprop_CosineAnnealing_example (2).pth',\n",
       " 'RegNet_1e-05_rmsprop_CosineAnnealing_example.pth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data/home_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb70e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_path = '/home/lab17/jupyter_home/Data/product_image/Training/'\n",
    "# Valid_path = '/home/lab17/jupyter_home/Data/product_image/Validation/'\n",
    "# Test_path = '/home/lab17/jupyter_home/git/test_img/'\n",
    "# save_graph_path = './result/'\n",
    "# save_model_path = '/home/lab17/jupyter_home/saved_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51431069",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_path = './data/home_clean_dataset'\n",
    "Test_path = 'C:/jupyter_home/GIT/mulcam3projcet_ai/test_img/home-clean'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c340a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca14fa",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caabde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(data_dir):\n",
    "#     img_path_list = []\n",
    "    label_list = []\n",
    "    label_name_list = []\n",
    "    \n",
    "#     image_path = os.path.join(data_dir, 'dessert')\n",
    "    image_path = data_dir\n",
    "    \n",
    "    for product_name in os.listdir(image_path):\n",
    "        product_path = os.path.join(image_path, product_name)\n",
    "        if os.path.isdir(product_path):\n",
    "#             get image path\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "            label = list(product_name.split('_')[0])\n",
    "            name = product_name[6:]\n",
    "            \n",
    "            # get label\n",
    "            label_list.append(''.join(label))\n",
    "            label_name_list.append(name)\n",
    "                \n",
    "#     return img_path_list, label_list\n",
    "    return label_list, label_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0c65a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_data(data_dir):\n",
    "#     img_path_list = []\n",
    "#     label_list = []\n",
    "    \n",
    "# #     image_path = os.path.join(data_dir, dir_name)\n",
    "#     image_path = data_dir\n",
    "    \n",
    "#     for product_name in os.listdir(image_path):\n",
    "#         product_path = os.path.join(image_path, product_name)\n",
    "#         if os.path.isdir(product_path):\n",
    "#             # get image path\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "# #             label = list(product_name[:5])\n",
    "            \n",
    "#             label = list(product_name.split('_')[0])\n",
    "            \n",
    "#             # get label\n",
    "#             label_list.append(''.join(label))\n",
    "                \n",
    "#     return img_path_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4b750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list, label_name_list = get_train_data(Train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7fc35cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--targets\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125]\n",
      "{'10182': 0, '10221': 1, '10222': 2, '15285': 3, '15344': 4, '15347': 5, '15351': 6, '15352': 7, '15353': 8, '15355': 9, '15358': 10, '15359': 11, '15361': 12, '15362': 13, '15363': 14, '15366': 15, '15369': 16, '15399': 17, '15854': 18, '15857': 19, '15860': 20, '15871': 21, '20192': 22, '20209': 23, '20215': 24, '20273': 25, '25016': 26, '25297': 27, '25351': 28, '25369': 29, '25371': 30, '25783': 31, '30146': 32, '30168': 33, '30182': 34, '30193': 35, '30225': 36, '30243': 37, '30250': 38, '35295': 39, '35303': 40, '35308': 41, '35309': 42, '35310': 43, '35315': 44, '35316': 45, '35318': 46, '35323': 47, '35327': 48, '35329': 49, '35330': 50, '35331': 51, '35332': 52, '35333': 53, '35336': 54, '35343': 55, '35345': 56, '35347': 57, '35545': 58, '35546': 59, '35757': 60, '40162': 61, '40168': 62, '40201': 63, '45023': 64, '45307': 65, '45309': 66, '45313': 67, '45314': 68, '45316': 69, '45318': 70, '45320': 71, '45321': 72, '45329': 73, '45330': 74, '45332': 75, '45334': 76, '45335': 77, '45472': 78, '45473': 79, '45474': 80, '45767': 81, '45859': 82, '50156': 83, '50170': 84, '50184': 85, '55437': 86, '55438': 87, '55439': 88, '55440': 89, '55441': 90, '55442': 91, '55443': 92, '60169': 93, '60173': 94, '60211': 95, '65113': 96, '65371': 97, '65378': 98, '65395': 99, '65396': 100, '65397': 101, '70148': 102, '70149': 103, '70152': 104, '70184': 105, '75040': 106, '75157': 107, '80077': 108, '80125': 109, '80141': 110, '80158': 111, '80199': 112, '80265': 113, '85043': 114, '90149': 115, '90151': 116, '90155': 117, '90156': 118, '90157': 119, '90190': 120, 'A10016': 121, 'A20011': 122, 'A20018': 123, 'A30020': 124, 'A40021': 125}\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(label_list)\n",
    "print('--targets\\n' , targets)\n",
    "\n",
    "label_encoder = {key:val for key, val in zip(label_list, targets)}\n",
    "print(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8bdf9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "label_decoder = {v: k for k, v in label_encoder.items()}\n",
    "label_name_decoder = {key : value for key, value in zip(label_list, label_name_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f7ecf",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0584b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_valid_data(data_dir):\n",
    "#     img_valid_list = []\n",
    "#     label_valid_list = []\n",
    "    \n",
    "#     image_path = os.path.join(data_dir, 'dessert')\n",
    "    \n",
    "#     for product_name in os.listdir(image_path):\n",
    "#         product_path = os.path.join(image_path, product_name)\n",
    "#         if os.path.isdir(product_path):\n",
    "#             # get image path\n",
    "#             img_valid_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "#             img_valid_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "#             label = list(product_name[:5])\n",
    "            \n",
    "#             # get label\n",
    "#             label_valid_list.append(''.join(label))\n",
    "                \n",
    "#     return img_valid_list, label_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c37a8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def valid_data_blanced(img, label):\n",
    "#     x = []\n",
    "#     y = []\n",
    "    \n",
    "#     for i in range(CFG['class']):\n",
    "#         _img = img[(i * 15): ((i + 1) * 15)]\n",
    "#         _label = label[i]\n",
    "        \n",
    "#         for img_product in _img:\n",
    "#             x.append(img_product)\n",
    "#             y.append(_label)\n",
    "            \n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72826760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_valid_list, label_valid_list = get_valid_data(Valid_path)\n",
    "# x_valid, y_valid = valid_data_blanced(img_valid_list, label_valid_list)\n",
    "# len(label_valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4795154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le2 = preprocessing.LabelEncoder()\n",
    "# targets_y = le2.fit_transform(y_valid)\n",
    "# targets_y_t = torch.as_tensor(targets_y)\n",
    "# one_hot_valid_y = F.one_hot(targets_y_t)\n",
    "# one_hot_valid_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ad3ff",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87f431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(data_dir):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    image_path = data_dir\n",
    "    \n",
    "#     for product in os.listdir(image_path):\n",
    "\n",
    "    # get image path\n",
    "    img_path_list.extend(glob(os.path.join(image_path, '*.jpg')))\n",
    "    img_path_list.extend(glob(os.path.join(image_path, '*.png')))\n",
    "    label_list = [ip[len(Test_path):].split('_')[0][1:] for ip in img_path_list]\n",
    "    # get label\n",
    "#     label_list.append(''.join(label))\n",
    "                \n",
    "    return img_path_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15f3cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path, test_label_list = get_test_data(Test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b74f986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(test_label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6076d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_x = test_img_path\n",
    "# 레이블을 one-hot-vector로 변환\n",
    "test_y = [label_encoder[key] for key in test_label_list]\n",
    "test_targets = torch.as_tensor(test_y)\n",
    "one_hot_test_y = F.one_hot(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9280e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10182, 0', '10182, 0', '10221, 1', '10222, 2', '10222, 2', '15285, 3', '15347, 5', '15347, 5', '15351, 6', '15351, 6', '15352, 7', '15353, 8', '15355, 9', '15355, 9', '15359, 11', '15359, 11', '15361, 12', '15361, 12', '15362, 13', '15363, 14', '15366, 15', '15369, 16', '15369, 16', '15399, 17', '15399, 17', '15854, 18', '15854, 18', '15860, 20', '15871, 21', '20192, 22', '20215, 24', '20273, 25', '25016, 26', '25297, 27', '25351, 28', '25371, 30', '30168, 33', '30182, 34', '30193, 35', '30225, 36', '30250, 38', '35295, 39', '35308, 41', '35309, 42', '35309, 42', '35310, 43', '35315, 44', '35316, 45', '35316, 45', '35318, 46', '35323, 47', '35323, 47', '35327, 48', '35329, 49', '35329, 49', '35331, 51', '35331, 51', '35332, 52', '35332, 52', '35336, 54', '35336, 54', '35343, 55', '35345, 56', '35347, 57', '35545, 58', '35545, 58', '35546, 59', '35546, 59', '35757, 60', '40168, 62', '45023, 64', '45307, 65', '45309, 66', '45313, 67', '45314, 68', '45318, 70', '45318, 70', '45318, 70', '45320, 71', '45320, 71', '45321, 72', '45329, 73', '45329, 73', '45330, 74', '45330, 74', '45332, 75', '45334, 76', '45335, 77', '45335, 77', '45473, 79', '45474, 80', '45767, 81', '45767, 81', '45767, 81', '45767, 81', '45859, 82', '45859, 82', '50156, 83', '50170, 84', '50170, 84', '50170, 84', '50184, 85', '55437, 86', '55438, 87', '55439, 88', '55441, 90', '55442, 91', '55443, 92', '60169, 93', '60173, 94', '60211, 95', '65113, 96', '65371, 97', '65371, 97', '65378, 98', '65395, 99', '65395, 99', '65396, 100', '65397, 101', '70148, 102', '70152, 104', '70184, 105', '75040, 106', '75157, 107', '80077, 108', '80125, 109', '80141, 110', '80141, 110', '80141, 110', '80158, 111', '80199, 112', '80199, 112', '80265, 113', '85043, 114', '90149, 115', '90151, 116', '90155, 117', '90156, 118', '90157, 119', '90190, 120', 'A10016, 121', 'A10016, 121', 'A10016, 121', 'A20011, 122', 'A20011, 122', 'A20011, 122', 'A20018, 123', 'A30020, 124', 'A30020, 124', 'A40021, 125']\n"
     ]
    }
   ],
   "source": [
    "print([f'{i}, {y}' for i, y in zip(test_label_list, test_y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fd5d0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6b00271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsCustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # By default OpenCV uses BGR color space for color images,\n",
    "        # so we need to convert the image to RGB color space.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.train_mode:\n",
    "#             image = image.astype(np.int16)\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "A_test_transform = albumentations.Compose([\n",
    "                                    A.Resize(256, 256),\n",
    "#                                     A.Normalize(mean=(0.744859, 0.735139, 0.711357), std=(0.100712, 0.120692, 0.167998)),  # dessert\n",
    "                                    A.Normalize(mean=(0.719834, 0.727319, 0.72394), std=(0.135879, 0.130642, 0.137573)),   # quasi_drug\n",
    "#                                     A.pytorch.transforms.ToTensor(),\n",
    "                                    A.pytorch.transforms.ToTensorV2(transpose_mask=True),\n",
    "                                ])\n",
    "\n",
    "# A_vali_dataset = AlbumentationsCustomDataset(x_valid, one_hot_valid_y, train_mode=True, transforms=A_test_transform)\n",
    "# A_vali_loader = DataLoader(A_vali_dataset, batch_size = 5, shuffle=False, num_workers=0, collate_fn=None)\n",
    "\n",
    "A_test_dataset = AlbumentationsCustomDataset(test_x, one_hot_test_y, train_mode=False, transforms=A_test_transform)\n",
    "A_test_loader = DataLoader(A_test_dataset, batch_size = 4, shuffle=False, num_workers=0, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dddfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(2048, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000,CFG['class'])\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # x = x.mean(dim=(-2, -1))\n",
    "        # (batch, 2048, 4, 4)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "#         out = self.softmax(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75c0cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetb4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetb4, self).__init__()\n",
    "        model = models.efficientnet_b4(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(1792, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000, CFG['class'])\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # (batch, 1792, 1, 1)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "#         out = self.softmax(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71e4f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegNet, self).__init__()\n",
    "        model = models.regnet_y_16gf(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(3024, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000, CFG['class'])\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # (batch, 3024, 1, 1)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "#         out = self.softmax(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf06d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = accuracy_score(real, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aea86d",
   "metadata": {},
   "source": [
    "# Inference2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "387f3ac9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # sorted(os.listdir('/home/lab17/jupyter_home/saved_models/'))\n",
    "# file_list = sorted(glob('/home/lab17/jupyter_home/saved_models/*.pth'))\n",
    "# print(len(file_list))\n",
    "# sorted(glob('/home/lab17/jupyter_home/saved_models/*.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e92b95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list=['/home/lab17/jupyter_home/saved_models/RegNet_0.001_rmsprop_CosineAnnealing_example.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21919430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = './data/quasi_drug/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e90cc794",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './data/home_clean/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54f62ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RegNet_0.0001_rmsprop_CosineAnnealing_example.pth',\n",
       " 'RegNet_0.001_rmsprop_CosineAnnealing_example (2).pth',\n",
       " 'RegNet_1e-05_rmsprop_CosineAnnealing_example.pth']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54a37111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/home_clean\\\\RegNet_0.0001_rmsprop_CosineAnnealing_example.pth',\n",
       " './data/home_clean\\\\RegNet_0.001_rmsprop_CosineAnnealing_example (2).pth',\n",
       " './data/home_clean\\\\RegNet_1e-05_rmsprop_CosineAnnealing_example.pth']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = sorted(glob(os.path.join(model_dir,'*.pth') ))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d024171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d37e594bf342fda60b9e729c159833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNet_0.0001_rmsprop_CosineAnnealing_example.pth\n",
      "test loss : 2.2906102000882753\n",
      "test acc : 0.5266666666666666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7261a4d603f1471b829445eecab6e79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNet_0.001_rmsprop_CosineAnnealing_example (2).pth\n",
      "test loss : 10.496223060708298\n",
      "test acc : 0.26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735f7411d83842b29d4e8864cec384d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNet_1e-05_rmsprop_CosineAnnealing_example.pth\n",
      "test loss : 1.5618299064471532\n",
      "test acc : 0.6533333333333333\n"
     ]
    }
   ],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 34\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "for m_path in file_list:\n",
    "    if 'ResNet50' in m_path:\n",
    "        model_test = ResNet50().to(device)\n",
    "    elif 'EfficientNetb4' in m_path:\n",
    "        model_test = EfficientNetb4().to(device)\n",
    "    elif 'RegNet' in m_path:\n",
    "        model_test = RegNet().to(device)    \n",
    "\n",
    "    model_test.load_state_dict(torch.load(m_path, map_location=device))\n",
    "    model_test.eval()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    test_loss = []\n",
    "    f_pred = []\n",
    "\n",
    "#     for img, label in tqdm(iter(A_vali_loader)):\n",
    "#         img, label = img.float().to(device), label.float().to(device)\n",
    "\n",
    "#         # Data -> Model -> Output\n",
    "#         logit = model_test(img)\n",
    "#         logit = torch.squeeze(logit)\n",
    "\n",
    "#         # Calc loss\n",
    "#         loss = criterion(logit, label)\n",
    "\n",
    "#         test_loss.append(loss.item())\n",
    "#         f_pred.extend(logit.argmax(1).detach().cpu().numpy().tolist())\n",
    "\n",
    "#     print('val loss :' ,np.mean(test_loss))\n",
    "#     print('val acc :', score_function(targets_y, f_pred))\n",
    "\n",
    "#     test_loss = []\n",
    "#     f_pred = []\n",
    "\n",
    "    for img, label in tqdm(iter(A_test_loader)):\n",
    "        img, label = img.float().to(device), label.float().to(device)\n",
    "\n",
    "        # Data -> Model -> Output\n",
    "        logit = model_test(img)\n",
    "        logit = torch.squeeze(logit)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = criterion(logit, label)\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "        f_pred.extend(logit.argmax(1).detach().cpu().numpy().tolist())\n",
    "        \n",
    "        \n",
    "    print(m_path[len(model_dir)+2:])\n",
    "\n",
    "    print('test loss :' ,np.mean(test_loss))\n",
    "    print('test acc :', score_function(test_y, f_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c54fb4b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o/x | onehot test, pred num | img_num : pred_img_name\n",
      "\n",
      "o | 0, 0 | \n",
      "o | 0, 0 | \n",
      "o | 1, 1 | \n",
      "x | 2, 50 | 10222, 슈가버블친환경주방세제470ML : 슈가버블)친환경주방세제리치레몬\n",
      "o | 2, 2 | \n",
      "x | 3, 74 | 15285, 엘지베비언스핑크퐁세탁세제2.2L : 유한양행)유한락스도마행주용\n",
      "o | 5, 5 | \n",
      "o | 5, 5 | \n",
      "o | 6, 6 | \n",
      "o | 6, 6 | \n",
      "o | 7, 7 | \n",
      "x | 8, 27 | 15353, 유한양행유한젠1.4KG : 무궁화왕표백450G\n",
      "o | 9, 9 | \n",
      "x | 9, 107 | 15355, 유한양행암앤해머베이킹소다2.1KG : 하수구냄새차단트랩\n",
      "o | 11, 11 | \n",
      "x | 11, 56 | 15359, 애경트리오곡물설거지우리쌀겨1.2L : 피죤)피죤옐로미모사\n",
      "o | 12, 12 | \n",
      "o | 12, 12 | \n",
      "o | 13, 13 | \n",
      "o | 14, 14 | \n",
      "o | 15, 15 | \n",
      "x | 16, 71 | 15369, 유한양행유한락스흰옷표백용1L : 헨켈)고농축버넬아몬드블러섬\n",
      "o | 16, 16 | \n",
      "x | 17, 85 | 15399, 피죤무균무때주방용 : LG퐁퐁친환경주방세제오렌지\n",
      "x | 17, 67 | 15399, 피죤무균무때주방용 : LG생활건강)테크울드라이오리지널\n",
      "o | 18, 18 | \n",
      "o | 18, 18 | \n",
      "x | 20, 61 | 15860, 슈가버블식기세척기용헹굼보조제1L : 자연미인로즈비누\n",
      "o | 21, 21 | \n",
      "o | 22, 22 | \n",
      "o | 24, 24 | \n",
      "x | 25, 67 | 20273, 불스원퍼스트클래스컴파운드 : LG생활건강)테크울드라이오리지널\n",
      "x | 26, 27 | 25016, 무균무때욕실그린허브500ML : 무궁화왕표백450G\n",
      "x | 27, 105 | 25297, 무궁화왕표백450G : 애경)스파크1KG\n",
      "o | 28, 28 | \n",
      "o | 30, 30 | \n",
      "x | 33, 104 | 30168, 요리지)크린종이호일원형 : 크린랩)크린지퍼백(이중지퍼백)18cmX20cm\n",
      "o | 34, 34 | \n",
      "o | 35, 35 | \n",
      "x | 36, 46 | 30225, 르샤트라고농축섬유유연제1L라벤더부케 : 유한양행)아름다운주방세제흑미배아\n",
      "o | 38, 38 | \n",
      "o | 39, 39 | \n",
      "x | 41, 88 | 35308, 유한양행)유한락스변기세정제 : 불스원레자왁스\n",
      "o | 42, 42 | \n",
      "o | 42, 42 | \n",
      "x | 43, 62 | 35310, 신희)홈워시마루청소 : 크린랩)뽑아쓰는크린백17cmX25cm\n",
      "o | 44, 44 | \n",
      "o | 45, 45 | \n",
      "x | 45, 101 | 35316, 유한양행)암앤해머내츄럴쉐이커 : 유한양행유한크로락스세정살균티슈시트러스블렌드\n",
      "o | 46, 46 | \n",
      "x | 47, 79 | 35323, 슈가버블)뿌리는과일야채세정제 : 한국쓰리엠)스카치브라이트원데이수세미소프트\n",
      "x | 47, 77 | 35323, 슈가버블)뿌리는과일야채세정제 : 애경)르샤트라섬유유연제피오니부케\n",
      "x | 48, 92 | 35327, 유한양행)유한락스세탁조세정제 : 유한킴벌리스카트화장실청소티슈\n",
      "x | 49, 91 | 35329, 피죤)무균무때곰팡이용 : 3M스카치브라이트항균망사수세미\n",
      "x | 49, 66 | 35329, 피죤)무균무때곰팡이용 : LG생활건강)자연퐁솔잎\n",
      "x | 51, 67 | 35331, 헨켈)프릴맑은식초산뜻한자몽향 : LG생활건강)테크울드라이오리지널\n",
      "x | 51, 67 | 35331, 헨켈)프릴맑은식초산뜻한자몽향 : LG생활건강)테크울드라이오리지널\n",
      "x | 52, 85 | 35332, 헨켈)프릴맑은식초상큼한라임향 : LG퐁퐁친환경주방세제오렌지\n",
      "x | 52, 104 | 35332, 헨켈)프릴맑은식초상큼한라임향 : 크린랩)크린지퍼백(이중지퍼백)18cmX20cm\n",
      "x | 54, 56 | 35336, 유한양행)유한락스도마행주용 : 피죤)피죤옐로미모사\n",
      "x | 54, 74 | 35336, 유한양행)유한락스도마행주용 : 유한양행)유한락스도마행주용\n",
      "o | 55, 55 | \n",
      "o | 56, 56 | \n",
      "o | 57, 57 | \n",
      "o | 58, 58 | \n",
      "x | 58, 104 | 35545, 애경)홈즈탈취탄냉동실용 : 크린랩)크린지퍼백(이중지퍼백)18cmX20cm\n",
      "x | 59, 60 | 35546, 애경)홈즈탈취탄냉장고용 : 피죤)피죤건조기용\n",
      "x | 59, 104 | 35546, 애경)홈즈탈취탄냉장고용 : 크린랩)크린지퍼백(이중지퍼백)18cmX20cm\n",
      "o | 60, 60 | \n",
      "o | 62, 62 | \n",
      "o | 64, 64 | \n",
      "o | 65, 65 | \n",
      "o | 66, 66 | \n",
      "x | 67, 10 | 45313, LG생활건강)테크울드라이오리지널 : 애경트리오곡물설거지우리밀1.2L\n",
      "x | 68, 69 | 45314, 페브리즈맨데오드란트파워 : 페브리즈맨시원한멘솔향\n",
      "o | 70, 70 | \n",
      "x | 70, 107 | 45318, 유한양행)유한락스플러스세제 : 하수구냄새차단트랩\n",
      "o | 70, 70 | \n",
      "o | 71, 71 | \n",
      "o | 71, 71 | \n",
      "x | 72, 7 | 45321, 헨켈)고농축버넬프레쉬모닝 : 유한양행유한젠가드니아향1.4KG\n",
      "o | 73, 73 | \n",
      "x | 73, 67 | 45329, 애경)랩신홈백신세탁조클리너 : LG생활건강)테크울드라이오리지널\n",
      "o | 74, 74 | \n",
      "x | 74, 20 | 45330, 유한양행)유한락스도마행주용 : 슈가버블식기세척기용헹굼보조제1L\n",
      "o | 75, 75 | \n",
      "o | 76, 76 | \n",
      "o | 77, 77 | \n",
      "o | 77, 77 | \n",
      "x | 79, 91 | 45473, 한국쓰리엠)스카치브라이트원데이수세미소프트 : 3M스카치브라이트항균망사수세미\n",
      "o | 80, 80 | \n",
      "o | 81, 81 | \n",
      "o | 81, 81 | \n",
      "o | 81, 81 | \n",
      "o | 81, 81 | \n",
      "o | 82, 82 | \n",
      "o | 82, 82 | \n",
      "x | 83, 64 | 50156, 아모레퍼시픽미장센에이징케어샴푸 : LG생활건강_샤프란아로마시트후레쉬드림향_50매\n",
      "x | 84, 12 | 50170, P_G)다우니퍼퓸핫핑크블룸1L : 라이온비트오투크린플러스1.4KG\n",
      "o | 84, 84 | \n",
      "o | 84, 84 | \n",
      "o | 85, 85 | \n",
      "o | 86, 86 | \n",
      "o | 87, 87 | \n",
      "x | 88, 122 | 55439, 불스원레자왁스 : _LG생활건강)홈스타맥스렌지후드클리너\n",
      "x | 90, 105 | 55441, 불스원물왁스 : 애경)스파크1KG\n",
      "o | 91, 91 | \n",
      "x | 92, 103 | 55443, 유한킴벌리스카트화장실청소티슈 : 무궁화하얀비누\n",
      "o | 93, 93 | \n",
      "o | 94, 94 | \n",
      "o | 95, 95 | \n",
      "o | 96, 96 | \n",
      "o | 97, 97 | \n",
      "o | 97, 97 | \n",
      "x | 98, 85 | 65378, 라이온참그린매실청정설거지 : LG퐁퐁친환경주방세제오렌지\n",
      "o | 99, 99 | \n",
      "x | 99, 12 | 65395, 유한양행유한락스렌지후드세정제 : 라이온비트오투크린플러스1.4KG\n",
      "x | 100, 26 | 65396, 피죤무균무때욕실용 : 무균무때욕실그린허브500ML\n",
      "o | 101, 101 | \n",
      "o | 102, 102 | \n",
      "o | 104, 104 | \n",
      "o | 105, 105 | \n",
      "o | 106, 106 | \n",
      "o | 107, 107 | \n",
      "o | 108, 108 | \n",
      "o | 109, 109 | \n",
      "o | 110, 110 | \n",
      "x | 110, 91 | 80141, 크린랲크린장갑 : 3M스카치브라이트항균망사수세미\n",
      "o | 110, 110 | \n",
      "o | 111, 111 | \n",
      "x | 112, 97 | 80199, 르샤트라고농축섬유유연제1L뮤게부케향 : 르샤트라섬유유연제뮤게부케\n",
      "o | 112, 112 | \n",
      "x | 113, 122 | 80265, 불스원다목적실내세정제 : _LG생활건강)홈스타맥스렌지후드클리너\n",
      "o | 114, 114 | \n",
      "o | 115, 115 | \n",
      "o | 116, 116 | \n",
      "o | 117, 117 | \n",
      "o | 118, 118 | \n",
      "x | 119, 91 | 90157, 엘지)알뜨랑오리지널(옐로우)140G : 3M스카치브라이트항균망사수세미\n",
      "o | 120, 120 | \n",
      "o | 121, 121 | \n",
      "o | 121, 121 | \n",
      "o | 121, 121 | \n",
      "o | 122, 122 | \n",
      "o | 122, 122 | \n",
      "o | 122, 122 | \n",
      "o | 123, 123 | \n",
      "x | 124, 79 | A30020, _참그린순수발효곡물 : 한국쓰리엠)스카치브라이트원데이수세미소프트\n",
      "x | 124, 109 | A30020, _참그린순수발효곡물 : 무궁화향비누230G\n",
      "o | 125, 125 | \n"
     ]
    }
   ],
   "source": [
    "def print_ox(test_y,f_pred):\n",
    "    return 'o' if test_y==f_pred else 'x'\n",
    "def print_name(test_y, f_pred):\n",
    "    return f'{label_decoder[y]}, {label_name_decoder[label_decoder[y]]} : {label_name_decoder[label_decoder[p]]}' if test_y!=f_pred else ''\n",
    "print('o/x | onehot test, pred num | img_num : pred_img_name\\n')\n",
    "for y, p in zip(test_y, f_pred):\n",
    "    print(f'{print_ox(y,p)} | {y}, {p} | {print_name(y,p)}')\n",
    "    \n",
    "    \n",
    "# print(f'{print_ox(y,p)} | {y}, {p} | {label_decoder[y]} : {label_name_decoder[label_decoder[p]]}')    \n",
    "#     print(f'{print_ox(y,p)} {y} : {p} {label_name_decoder[y]}, {label_name_decoder[p]}')\n",
    "# print(f'{test_y}, {f_pred}')\n",
    "# print(f'{print_ox(test_y,f_pred)} {test_y} : {f_pred} {label_name_decoder[test_y]}, {label_name_decoder[f_pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ffd5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44483b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
