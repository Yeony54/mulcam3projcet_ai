{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c3de41",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d30ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c81cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20bc0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_64224\\2738216029.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e643018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':256,\n",
    "    'EPOCHS':50,\n",
    "    'PATIENCE':10,\n",
    "    'class':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5d77fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RegNet_0.0001_rmsprop_CosineAnnealing_example.pth',\n",
       " 'RegNet_0.001_rmsprop_CosineAnnealing_example.pth',\n",
       " 'RegNet_1e-05_rmsprop_CosineAnnealing_example.pth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data/quasi_drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb70e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_path = '/home/lab17/jupyter_home/Data/product_image/Training/'\n",
    "# Valid_path = '/home/lab17/jupyter_home/Data/product_image/Validation/'\n",
    "# Test_path = '/home/lab17/jupyter_home/git/test_img/'\n",
    "# save_graph_path = './result/'\n",
    "# save_model_path = '/home/lab17/jupyter_home/saved_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51431069",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_path = './data/quasi_drug_dataset'\n",
    "Test_path = 'C:/jupyter_home/GIT/mulcam3projcet_ai/test_img/quasi-drugs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c340a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca14fa",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caabde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(data_dir):\n",
    "#     img_path_list = []\n",
    "    label_list = []\n",
    "    label_name_list = []\n",
    "    \n",
    "#     image_path = os.path.join(data_dir, 'dessert')\n",
    "    image_path = data_dir\n",
    "    \n",
    "    for product_name in os.listdir(image_path):\n",
    "        product_path = os.path.join(image_path, product_name)\n",
    "        if os.path.isdir(product_path):\n",
    "#             get image path\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "            label = list(product_name[:5])\n",
    "            name = product_name[6:]\n",
    "            \n",
    "            # get label\n",
    "            label_list.append(''.join(label))\n",
    "            label_name_list.append(name)\n",
    "                \n",
    "#     return img_path_list, label_list\n",
    "    return label_list, label_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list, label_name_list = get_train_data(Train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fc35cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--targets\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40]\n",
      "{'10096': 0, '10097': 1, '10106': 2, '10213': 3, '10214': 4, '10215': 5, '10266': 6, '10320': 7, '10321': 8, '15258': 9, '15458': 10, '15664': 11, '15804': 12, '15896': 13, '20196': 14, '20260': 15, '30081': 16, '30163': 17, '30164': 18, '30181': 19, '30289': 20, '40182': 21, '40191': 22, '40303': 23, '45707': 24, '50139': 25, '55734': 26, '66380': 27, '70162': 28, '70163': 29, '70180': 30, '70181': 31, '70182': 32, '80140': 33, '80146': 34, '80147': 35, '80249': 36, '80250': 37, '90174': 38, '90176': 39, '90245': 40}\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(label_list)\n",
    "print('--targets\\n' , targets)\n",
    "\n",
    "label_encoder = {key:val for key, val in zip(label_list, targets)}\n",
    "print(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8bdf9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "label_decoder = {v: k for k, v in label_encoder.items()}\n",
    "label_name_decoder = {key : value for key, value in zip(label_list, label_name_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f7ecf",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0584b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_valid_data(data_dir):\n",
    "#     img_valid_list = []\n",
    "#     label_valid_list = []\n",
    "    \n",
    "#     image_path = os.path.join(data_dir, 'dessert')\n",
    "    \n",
    "#     for product_name in os.listdir(image_path):\n",
    "#         product_path = os.path.join(image_path, product_name)\n",
    "#         if os.path.isdir(product_path):\n",
    "#             # get image path\n",
    "#             img_valid_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "#             img_valid_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "#             label = list(product_name[:5])\n",
    "            \n",
    "#             # get label\n",
    "#             label_valid_list.append(''.join(label))\n",
    "                \n",
    "#     return img_valid_list, label_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c37a8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def valid_data_blanced(img, label):\n",
    "#     x = []\n",
    "#     y = []\n",
    "    \n",
    "#     for i in range(CFG['class']):\n",
    "#         _img = img[(i * 15): ((i + 1) * 15)]\n",
    "#         _label = label[i]\n",
    "        \n",
    "#         for img_product in _img:\n",
    "#             x.append(img_product)\n",
    "#             y.append(_label)\n",
    "            \n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72826760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_valid_list, label_valid_list = get_valid_data(Valid_path)\n",
    "# x_valid, y_valid = valid_data_blanced(img_valid_list, label_valid_list)\n",
    "# len(label_valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4795154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le2 = preprocessing.LabelEncoder()\n",
    "# targets_y = le2.fit_transform(y_valid)\n",
    "# targets_y_t = torch.as_tensor(targets_y)\n",
    "# one_hot_valid_y = F.one_hot(targets_y_t)\n",
    "# one_hot_valid_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ad3ff",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f87f431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(data_dir):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    image_path = data_dir\n",
    "    \n",
    "#     for product in os.listdir(image_path):\n",
    "\n",
    "    # get image path\n",
    "    img_path_list.extend(glob(os.path.join(image_path, '*.jpg')))\n",
    "    img_path_list.extend(glob(os.path.join(image_path, '*.png')))\n",
    "    label_list = [ip[len(Test_path):].split('_')[0][1:] for ip in img_path_list]\n",
    "    # get label\n",
    "#     label_list.append(''.join(label))\n",
    "                \n",
    "    return img_path_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f3cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path, test_label_list = get_test_data(Test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b74f986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "print(len(test_label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6076d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_x = test_img_path\n",
    "# 레이블을 one-hot-vector로 변환\n",
    "test_y = [label_encoder[key] for key in test_label_list]\n",
    "test_targets = torch.as_tensor(test_y)\n",
    "one_hot_test_y = F.one_hot(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9280e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10097, 1', '10097, 1', '10213, 3', '10213, 3', '10214, 4', '10214, 4', '10215, 5', '10215, 5', '10215, 5', '10266, 6', '10320, 7', '10320, 7', '10321, 8', '15258, 9', '15258, 9', '15458, 10', '15664, 11', '15664, 11', '15804, 12', '15804, 12', '15804, 12', '15896, 13', '15896, 13', '20260, 15', '20260, 15', '20260, 15', '30081, 16', '30163, 17', '30163, 17', '30163, 17', '30164, 18', '30164, 18', '30181, 19', '30181, 19', '30289, 20', '30289, 20', '40182, 21', '40191, 22', '40303, 23', '45707, 24', '50139, 25', '55734, 26', '55734, 26', '55734, 26', '66380, 27', '66380, 27', '66380, 27', '70162, 28', '70162, 28', '70162, 28', '70163, 29', '70180, 30', '70180, 30', '70181, 31', '70181, 31', '70182, 32', '70182, 32', '80140, 33', '80140, 33', '80140, 33', '80146, 34', '80146, 34', '80147, 35', '80147, 35', '80249, 36', '80249, 36', '80250, 37', '80250, 37', '80250, 37', '90174, 38', '90174, 38', '90174, 38', '90176, 39', '90176, 39', '90176, 39', '90245, 40', '90245, 40', '90245, 40', '10096, 0', '55734, 26', '70181, 31', '80146, 34']\n"
     ]
    }
   ],
   "source": [
    "print([f'{i}, {y}' for i, y in zip(test_label_list, test_y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fd5d0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6b00271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsCustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # By default OpenCV uses BGR color space for color images,\n",
    "        # so we need to convert the image to RGB color space.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.train_mode:\n",
    "#             image = image.astype(np.int16)\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "A_test_transform = albumentations.Compose([\n",
    "                                    A.Resize(256, 256),\n",
    "#                                     A.Normalize(mean=(0.744859, 0.735139, 0.711357), std=(0.100712, 0.120692, 0.167998)),  # dessert\n",
    "                                    A.Normalize(mean=(0.719834, 0.727319, 0.72394), std=(0.135879, 0.130642, 0.137573)),   # quasi_drug\n",
    "#                                     A.pytorch.transforms.ToTensor(),\n",
    "                                    A.pytorch.transforms.ToTensorV2(transpose_mask=True),\n",
    "                                ])\n",
    "\n",
    "# A_vali_dataset = AlbumentationsCustomDataset(x_valid, one_hot_valid_y, train_mode=True, transforms=A_test_transform)\n",
    "# A_vali_loader = DataLoader(A_vali_dataset, batch_size = 5, shuffle=False, num_workers=0, collate_fn=None)\n",
    "\n",
    "A_test_dataset = AlbumentationsCustomDataset(test_x, one_hot_test_y, train_mode=False, transforms=A_test_transform)\n",
    "A_test_loader = DataLoader(A_test_dataset, batch_size = 4, shuffle=False, num_workers=0, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dddfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(2048, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000,CFG['class'])\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # x = x.mean(dim=(-2, -1))\n",
    "        # (batch, 2048, 4, 4)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "#         out = self.softmax(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75c0cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetb4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetb4, self).__init__()\n",
    "        model = models.efficientnet_b4(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(1792, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000, CFG['class'])\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # (batch, 1792, 1, 1)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "#         out = self.softmax(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71e4f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegNet, self).__init__()\n",
    "        model = models.regnet_y_16gf(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(3024, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000, CFG['class'])\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # (batch, 3024, 1, 1)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "#         out = self.softmax(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf06d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = accuracy_score(real, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aea86d",
   "metadata": {},
   "source": [
    "# Inference2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f3ac9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # sorted(os.listdir('/home/lab17/jupyter_home/saved_models/'))\n",
    "# file_list = sorted(glob('/home/lab17/jupyter_home/saved_models/*.pth'))\n",
    "# print(len(file_list))\n",
    "# sorted(glob('/home/lab17/jupyter_home/saved_models/*.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list=['/home/lab17/jupyter_home/saved_models/RegNet_0.001_rmsprop_CosineAnnealing_example.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21919430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './data/quasi_drug/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54f62ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RegNet_0.0001_rmsprop_CosineAnnealing_example.pth',\n",
       " 'RegNet_0.001_rmsprop_CosineAnnealing_example.pth',\n",
       " 'RegNet_1e-05_rmsprop_CosineAnnealing_example.pth']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54a37111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/quasi_drug\\\\RegNet_0.0001_rmsprop_CosineAnnealing_example.pth',\n",
       " './data/quasi_drug\\\\RegNet_0.001_rmsprop_CosineAnnealing_example.pth',\n",
       " './data/quasi_drug\\\\RegNet_1e-05_rmsprop_CosineAnnealing_example.pth']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = sorted(glob(os.path.join(model_dir,'*.pth') ))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d024171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4f61f660474eaeae6b9674d35dc1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNet_0.0001_rmsprop_CosineAnnealing_example.pth\n",
      "test loss : 2.284422179417951\n",
      "test acc : 0.4878048780487805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255c9983e96c46288d59877bb11bc2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNet_0.001_rmsprop_CosineAnnealing_example.pth\n",
      "test loss : 7.407537414914086\n",
      "test acc : 0.14634146341463414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc77994dc78420f90e7e4ad6932b567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNet_1e-05_rmsprop_CosineAnnealing_example.pth\n",
      "test loss : 1.7821240786108232\n",
      "test acc : 0.6463414634146342\n"
     ]
    }
   ],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 34\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "for m_path in file_list:\n",
    "    if 'ResNet50' in m_path:\n",
    "        model_test = ResNet50().to(device)\n",
    "    elif 'EfficientNetb4' in m_path:\n",
    "        model_test = EfficientNetb4().to(device)\n",
    "    elif 'RegNet' in m_path:\n",
    "        model_test = RegNet().to(device)    \n",
    "\n",
    "    model_test.load_state_dict(torch.load(m_path, map_location=device))\n",
    "    model_test.eval()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    test_loss = []\n",
    "    f_pred = []\n",
    "\n",
    "#     for img, label in tqdm(iter(A_vali_loader)):\n",
    "#         img, label = img.float().to(device), label.float().to(device)\n",
    "\n",
    "#         # Data -> Model -> Output\n",
    "#         logit = model_test(img)\n",
    "#         logit = torch.squeeze(logit)\n",
    "\n",
    "#         # Calc loss\n",
    "#         loss = criterion(logit, label)\n",
    "\n",
    "#         test_loss.append(loss.item())\n",
    "#         f_pred.extend(logit.argmax(1).detach().cpu().numpy().tolist())\n",
    "\n",
    "#     print('val loss :' ,np.mean(test_loss))\n",
    "#     print('val acc :', score_function(targets_y, f_pred))\n",
    "\n",
    "#     test_loss = []\n",
    "#     f_pred = []\n",
    "\n",
    "    for img, label in tqdm(iter(A_test_loader)):\n",
    "        img, label = img.float().to(device), label.float().to(device)\n",
    "\n",
    "        # Data -> Model -> Output\n",
    "        logit = model_test(img)\n",
    "        logit = torch.squeeze(logit)\n",
    "\n",
    "        # Calc loss\n",
    "        loss = criterion(logit, label)\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "        f_pred.extend(logit.argmax(1).detach().cpu().numpy().tolist())\n",
    "        \n",
    "        \n",
    "    print(m_path[len(model_dir)+2:])\n",
    "\n",
    "    print('test loss :' ,np.mean(test_loss))\n",
    "    print('test acc :', score_function(test_y, f_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c54fb4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o/x | onehot test, pred num | img_num : pred_img_name\n",
      "\n",
      "x | 1, 27 | 10097, 동아제약)가그린후레쉬라임100ML : 광동제약위생천75ML\n",
      "x | 1, 7 | 10097, 동아제약)가그린후레쉬라임100ML : 동아제약)가그린어린이용사과\n",
      "x | 3, 39 | 10213, 클링스스케일링케어스트롱민트치약100G : 유한)좋은느낌대형14맥시슬림\n",
      "x | 3, 11 | 10213, 클링스스케일링케어스트롱민트치약100G : 고려은단쏠라C구미복숭아맛50G\n",
      "x | 4, 16 | 10214, 클링스스케일링케어쿨링민트치약100G : 아모레퍼시픽)메디안치석오리지널치약120G\n",
      "x | 4, 16 | 10214, 클링스스케일링케어쿨링민트치약100G : 아모레퍼시픽)메디안치석오리지널치약120G\n",
      "o | 5, 5 | \n",
      "o | 5, 5 | \n",
      "o | 5, 5 | \n",
      "o | 6, 6 | \n",
      "o | 7, 7 | \n",
      "o | 7, 7 | \n",
      "x | 8, 24 | 10321, 동국제약)마데카솔 : 유한양행)안티푸라민연고\n",
      "o | 9, 9 | \n",
      "o | 9, 9 | \n",
      "o | 10, 10 | \n",
      "o | 11, 11 | \n",
      "o | 11, 11 | \n",
      "o | 12, 12 | \n",
      "o | 12, 12 | \n",
      "x | 12, 6 | 15804, 동국제약덴트릭스150G : 유한해피홈멸균밴드표준형\n",
      "o | 13, 13 | \n",
      "o | 13, 13 | \n",
      "o | 15, 15 | \n",
      "o | 15, 15 | \n",
      "o | 15, 15 | \n",
      "x | 16, 14 | 30081, 아모레퍼시픽)메디안치석오리지널치약120G : 메디안치석케어93_120G\n",
      "o | 17, 17 | \n",
      "x | 17, 23 | 30163, 페리오토탈7스트롱어드밴스치약140G : 애경)2080진지발리스K허벌민트\n",
      "x | 17, 23 | 30163, 페리오토탈7스트롱어드밴스치약140G : 애경)2080진지발리스K허벌민트\n",
      "x | 18, 28 | 30164, 부광약품시린메드에프치약 : 부광안티프라그치약\n",
      "o | 18, 18 | \n",
      "x | 19, 39 | 30181, 매직팬티컴포트 : 유한)좋은느낌대형14맥시슬림\n",
      "o | 19, 19 | \n",
      "x | 20, 36 | 30289, 동아제약)가그린어린이용딸기 : 리스테린내추럴시트러스750ML\n",
      "x | 20, 7 | 30289, 동아제약)가그린어린이용딸기 : 동아제약)가그린어린이용사과\n",
      "o | 21, 21 | \n",
      "o | 22, 22 | \n",
      "o | 23, 23 | \n",
      "o | 24, 24 | \n",
      "x | 25, 23 | 50139, 덴탈크리닉2080시그니처토탈그린 : 애경)2080진지발리스K허벌민트\n",
      "x | 26, 6 | 55734, 현대약품)미에로화이바 : 유한해피홈멸균밴드표준형\n",
      "o | 26, 26 | \n",
      "o | 26, 26 | \n",
      "x | 27, 15 | 66380, 광동제약위생천75ML : 바른생각익스트림에어핏\n",
      "o | 27, 27 | \n",
      "o | 27, 27 | \n",
      "o | 28, 28 | \n",
      "o | 28, 28 | \n",
      "o | 28, 28 | \n",
      "o | 29, 29 | \n",
      "o | 30, 30 | \n",
      "o | 30, 30 | \n",
      "x | 31, 32 | 70181, 유한)좋은느낌중형18울트라슬림 : 좋은느낌소형18울트라슬림\n",
      "x | 31, 39 | 70181, 유한)좋은느낌중형18울트라슬림 : 유한)좋은느낌대형14맥시슬림\n",
      "o | 32, 32 | \n",
      "x | 32, 39 | 70182, 좋은느낌소형18울트라슬림 : 유한)좋은느낌대형14맥시슬림\n",
      "o | 33, 33 | \n",
      "o | 33, 33 | \n",
      "o | 33, 33 | \n",
      "x | 34, 25 | 80146, 페리오브레쓰케어알파치약160G : 덴탈크리닉2080시그니처토탈그린\n",
      "x | 34, 21 | 80146, 페리오브레쓰케어알파치약160G : 페리오캐비티케어알파치약160G\n",
      "x | 35, 34 | 80147, 페리오토탈7오리지널어드밴스치약140G : 페리오브레쓰케어알파치약160G\n",
      "x | 35, 21 | 80147, 페리오토탈7오리지널어드밴스치약140G : 페리오캐비티케어알파치약160G\n",
      "o | 36, 36 | \n",
      "x | 36, 22 | 80249, 리스테린내추럴시트러스750ML : 애경2080진지발리스120G\n",
      "o | 37, 37 | \n",
      "o | 37, 37 | \n",
      "o | 37, 37 | \n",
      "o | 38, 38 | \n",
      "o | 38, 38 | \n",
      "o | 38, 38 | \n",
      "o | 39, 39 | \n",
      "x | 39, 32 | 90176, 유한)좋은느낌대형14맥시슬림 : 좋은느낌소형18울트라슬림\n",
      "o | 39, 39 | \n",
      "o | 40, 40 | \n",
      "o | 40, 40 | \n",
      "o | 40, 40 | \n",
      "o | 0, 0 | \n",
      "o | 26, 26 | \n",
      "x | 31, 39 | 70181, 유한)좋은느낌중형18울트라슬림 : 유한)좋은느낌대형14맥시슬림\n",
      "x | 34, 35 | 80146, 페리오브레쓰케어알파치약160G : 페리오토탈7오리지널어드밴스치약140G\n"
     ]
    }
   ],
   "source": [
    "def print_ox(test_y,f_pred):\n",
    "    return 'o' if test_y==f_pred else 'x'\n",
    "def print_name(test_y, f_pred):\n",
    "    return f'{label_decoder[y]}, {label_name_decoder[label_decoder[y]]} : {label_name_decoder[label_decoder[p]]}' if test_y!=f_pred else ''\n",
    "print('o/x | onehot test, pred num | img_num : pred_img_name\\n')\n",
    "for y, p in zip(test_y, f_pred):\n",
    "    print(f'{print_ox(y,p)} | {y}, {p} | {print_name(y,p)}')\n",
    "    \n",
    "    \n",
    "# print(f'{print_ox(y,p)} | {y}, {p} | {label_decoder[y]} : {label_name_decoder[label_decoder[p]]}')    \n",
    "#     print(f'{print_ox(y,p)} {y} : {p} {label_name_decoder[y]}, {label_name_decoder[p]}')\n",
    "# print(f'{test_y}, {f_pred}')\n",
    "# print(f'{print_ox(test_y,f_pred)} {test_y} : {f_pred} {label_name_decoder[test_y]}, {label_name_decoder[f_pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ffd5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44483b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
